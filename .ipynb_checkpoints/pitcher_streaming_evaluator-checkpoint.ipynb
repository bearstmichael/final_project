{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4313aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-18 17:29:03.420327: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import requests\n",
    "import urllib.request\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "from datetime import date, datetime, timedelta\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import sklearn as skl\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder,LabelBinarizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "\n",
    "start_time = time.time()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b5a36a",
   "metadata": {},
   "source": [
    "# Select your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44260d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How much do you want to scale back this run? Pick a number between 0 (none) and 1 (all)\n",
    "t = 1\n",
    "\n",
    "# Do you want to scrape new data (y/n)? If so, it'll take approx t*30 minutes\n",
    "pit_update = 'n'\n",
    "\n",
    "# Do you want to scrape new data (y/n)? If so, it'll take approx 3 minutes\n",
    "opp_update = 'n'\n",
    "\n",
    "# How wide do you want the predicted performance buckets to be?\n",
    "bucket_width = 12\n",
    "\n",
    "# How many games do you want to include in a pitcher's \"recent performance\" (think, rolling avg)\n",
    "N=5\n",
    "\n",
    "# How many games do you want to include in an opposing team's \"recent performance\" (think, rolling avg)\n",
    "M=30\n",
    "\n",
    "# Which PITCHER stats do you want inlcluded\n",
    "# This is in addition to required stats, which have already been selected\n",
    "# 1 for yes, 0 for no\n",
    "\n",
    "stat_selector = {\n",
    " 'index': 0,\n",
    " 'Rk': 0,\n",
    " 'Gcar': 0,\n",
    " 'Gtm': 0,\n",
    " 'Tm': 0,\n",
    " 'Rslt': 0,\n",
    " 'Inngs': 0,\n",
    " 'R': 0,\n",
    " 'ERA': 0,\n",
    " 'FIP': 1,\n",
    " 'BF': 0,\n",
    " 'Pit': 0,\n",
    " 'Str': 0,\n",
    " 'StL': 0,\n",
    " 'StS': 0,\n",
    " 'GB': 0,\n",
    " 'FB': 0,\n",
    " 'LD': 0,\n",
    " 'PU': 0,\n",
    " 'Unk': 0,\n",
    " 'GSc': 1,\n",
    " 'IR': 0,\n",
    " 'IS': 0,\n",
    " 'SB': 0,\n",
    " 'CS': 0,\n",
    " 'PO': 0,\n",
    " 'AB': 0,\n",
    " '2B': 1,\n",
    " '3B': 0,\n",
    " 'IBB': 0,\n",
    " 'GDP': 0,\n",
    " 'SF': 0,\n",
    " 'ROE': 0,\n",
    " 'aLI': 0,\n",
    " 'WPA': 0,\n",
    " 'acLI': 0,\n",
    " 'cWPA': 0,\n",
    " 'RE24': 0,\n",
    " 'DFS(DK)': 0,\n",
    " 'DFS(FD)': 0,\n",
    " 'Entered': 0,\n",
    " 'Exited': 0,\n",
    " 'Outs': 0}\n",
    "\n",
    "# Which OPPOSING TEAM stats do you want?\n",
    "opp_stat_selector = {'Rk': 0,\n",
    " 'Gtm': 0,\n",
    " 'Opp': 0,\n",
    " 'Rslt': 0,\n",
    " 'AB': 0,\n",
    " 'R': 1,\n",
    " 'H': 1,\n",
    " '2B': 0,\n",
    " '3B': 0,\n",
    " 'HR': 1,\n",
    " 'RBI': 0,\n",
    " 'BB': 1,\n",
    " 'IBB': 0,\n",
    " 'SO': 1,\n",
    " 'HBP': 0,\n",
    " 'SH': 0,\n",
    " 'SF': 0,\n",
    " 'ROE': 0,\n",
    " 'GDP': 0,\n",
    " 'SB': 0,\n",
    " 'CS': 0,\n",
    " 'BA': 0,\n",
    " 'OBP': 1,\n",
    " 'SLG': 1,\n",
    " 'OPS': 0,\n",
    " 'LOB': 1,\n",
    " '#': 0,\n",
    " 'Thr': 0,\n",
    " 'Opp. Starter (GmeSc)': 0}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5898b976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need a full list of datatypes for all potential data selections, so we can assign dtype appropriately\n",
    "pitcher_data_cols_dtypes = {\n",
    " 'index': 'int',\n",
    " 'Rk': 'int',\n",
    " 'Gcar': 'int',\n",
    " 'Gtm': 'int',\n",
    "#  'Date': 'datetime64[ns]', taking out this one b/c dates are weird. Handling elsewhere.\n",
    " 'Tm': 'object',\n",
    " 'Unnamed: 5': 'object',\n",
    " 'Opp': 'object',\n",
    " 'Rslt': 'object',\n",
    " 'Inngs': 'object',\n",
    " 'Dec': 'int',\n",
    " 'DR': 'int',\n",
    " 'H': 'int',\n",
    " 'R': 'int',\n",
    " 'ER': 'int',\n",
    " 'BB': 'int',\n",
    " 'SO': 'int',\n",
    " 'HR': 'int',\n",
    " 'HBP': 'int',\n",
    " 'ERA': 'float',\n",
    " 'FIP': 'float',\n",
    " 'BF': 'int',\n",
    " 'Pit': 'int',\n",
    " 'Str': 'int',\n",
    " 'StL': 'int',\n",
    " 'StS': 'int',\n",
    " 'GB': 'int',\n",
    " 'FB': 'int',\n",
    " 'LD': 'int',\n",
    " 'PU': 'int',\n",
    " 'Unk': 'int',\n",
    " 'GSc': 'int',\n",
    " 'IR': 'int',\n",
    " 'IS': 'int',\n",
    " 'SB': 'int',\n",
    " 'CS': 'int',\n",
    " 'PO': 'int',\n",
    " 'AB': 'int',\n",
    " '2B': 'int',\n",
    " '3B': 'int',\n",
    " 'IBB': 'int',\n",
    " 'GDP': 'int',\n",
    " 'SF': 'int',\n",
    " 'ROE': 'int',\n",
    " 'aLI': 'float',\n",
    " 'WPA': 'float',\n",
    " 'acLI': 'float',\n",
    " 'cWPA': 'float',\n",
    " 'RE24': 'float',\n",
    " 'DFS(DK)': 'float',\n",
    " 'DFS(FD)': 'float',\n",
    " 'Entered': 'object',\n",
    " 'Exited': 'object',\n",
    " 'Outs': 'int'}\n",
    "\n",
    "opp_data_cols_dtypes ={\n",
    " 'Rk': 'int',\n",
    " 'Gtm': 'int',\n",
    "#  'Date': 'int', commenting this out b/c we take care of it later\n",
    " 'Unnamed: 3': 'object',\n",
    " 'Opp': 'object',\n",
    " 'Rslt': 'object',\n",
    " 'PA': 'int',\n",
    " 'AB': 'int',\n",
    " 'R': 'int',\n",
    " 'H': 'int',\n",
    " '2B': 'int',\n",
    " '3B': 'int',\n",
    " 'HR': 'int',\n",
    " 'RBI': 'int',\n",
    " 'BB': 'int',\n",
    " 'IBB': 'int',\n",
    " 'SO': 'int',\n",
    " 'HBP': 'int',\n",
    " 'SH': 'int',\n",
    " 'SF': 'int',\n",
    " 'ROE': 'int',\n",
    " 'GDP': 'int',\n",
    " 'SB': 'int',\n",
    " 'CS': 'int',\n",
    " 'BA': 'float',\n",
    " 'OBP': 'float',\n",
    " 'SLG': 'float',\n",
    " 'OPS': 'float',\n",
    " 'LOB': 'int',\n",
    " '#': 'int',\n",
    " 'Thr': 'object',\n",
    " 'Opp. Starter (GmeSc)': 'object',\n",
    " 'Team': 'object'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8538fd29",
   "metadata": {},
   "source": [
    "### This is the section where I scrape individual starting pitchers' individual game performance\n",
    "\n",
    "#### Things to consider:\n",
    "Add a counter that shows the total number of pitchers logged, compared to the total number fed in, so I can see how much loss there was when we triggered the except/pass code\\\n",
    "\\\n",
    "How valuable is the information we are getting from the guys who are towards the end of the list? The list of pitchers is sorted by number of starts, so cutting the bottom 20% of the list will take away 20% of the run time, but only ~10% of the data. But maybe it's important to have representation for those pitchers with only a few starts? Much of the time, it's those rando pitchers that we're needing to judge the most, b/c they're the most available.\\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7a2cbe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done adding Miles Mikolas 0/357\n",
      "Done adding Chris Bassitt 1/357\n",
      "Done adding Dylan Cease 2/357\n",
      "Done adding Gerrit Cole 3/357\n",
      "Done adding Zac Gallen 4/357\n",
      "Done adding Logan Webb 5/357\n",
      "Done adding Sandy Alcantara 6/357\n",
      "Done adding José Berríos 7/357\n",
      "Done adding Corbin Burnes 8/357\n",
      "Done adding Luis Castillo 9/357\n",
      "Done adding Patrick Corbin 10/357\n",
      "Done adding Kyle Gibson 11/357\n",
      "Done adding Lucas Giolito 12/357\n",
      "Done adding Sonny Gray 13/357\n",
      "Done adding Mitch Keller 14/357\n",
      "Done adding Dean Kremer 15/357\n",
      "Done adding Pablo López 16/357\n",
      "Done adding Jesús Luzardo 17/357\n",
      "Done adding Aaron Nola 18/357\n",
      "Done adding Johan Oviedo 19/357\n",
      "Done adding Blake Snell 20/357\n",
      "Done adding Zach Eflin 21/357\n",
      "Done adding Bryce Elder 22/357\n",
      "Done adding Kyle Freeland 23/357\n",
      "Done adding Kevin Gausman 24/357\n",
      "Done adding Logan Gilbert 25/357\n",
      "Done adding Austin Gomber 26/357\n",
      "Done adding Josiah Gray 27/357\n",
      "Done adding Yusei Kikuchi 30/357\n",
      "Done adding Lance Lynn 31/357\n",
      "Done adding Jordan Montgomery 32/357\n",
      "Done adding Charlie Morton 33/357\n",
      "Done adding JP Sears 35/357\n",
      "Done adding Brady Singer 36/357\n",
      "Done adding Spencer Strider 37/357\n",
      "Done adding Framber Valdez 38/357\n",
      "Done adding Taijuan Walker 39/357\n",
      "Done adding Zack Wheeler 40/357\n",
      "Done adding Trevor Williams 41/357\n",
      "Done adding Graham Ashcraft 42/357\n",
      "Done adding Alex Cobb 43/357\n",
      "Done adding MacKenzie Gore 45/357\n",
      "Done adding Cristian Javier 46/357\n",
      "Done adding George Kirby 47/357\n",
      "Done adding Jordan Lyles 49/357\n",
      "Done adding Freddy Peralta 50/357\n",
      "Done adding Justin Steele 51/357\n",
      "Done adding Kyle Bradish 52/357\n",
      "Done adding Reid Detmers 54/357\n",
      "Done adding Jack Flaherty 55/357\n",
      "Done adding Jon Gray 56/357\n",
      "Done adding Merrill Kelly 57/357\n",
      "Done adding Max Scherzer 58/357\n",
      "Done adding Kodai Senga 59/357\n",
      "Done adding Jameson Taillon 60/357\n",
      "Done adding Brayan Bello 61/357\n",
      "Done adding Yu Darvish 62/357\n",
      "Done adding Michael Lorenzen 63/357\n",
      "Done adding Ryne Nelson 64/357\n",
      "Done adding Joe Ryan 65/357\n",
      "Done adding Patrick Sandoval 66/357\n",
      "Done adding Tanner Bibee 68/357\n",
      "Done adding Shohei Ohtani 70/357\n",
      "Done adding Seth Lugo 72/357\n",
      "Done adding Bailey Ober 73/357\n",
      "Done adding Justin Verlander 75/357\n",
      "Done adding Logan Allen 77/357\n",
      "Done adding Jake Irvin 79/357\n",
      "Done adding Clayton Kershaw 80/357\n",
      "Done adding Shane McClanahan 81/357\n",
      "Done adding Tylor Megill 82/357\n",
      "Done adding Bryce Miller 83/357\n",
      "Done adding Eduardo Rodriguez 84/357\n",
      "Done adding Julio Urías 85/357\n",
      "Done adding Carlos Carrasco 86/357\n",
      "Done adding Nathan Eovaldi 87/357\n",
      "Done adding Tony Gonsolin 89/357\n",
      "Done adding Kyle Hendricks 90/357\n",
      "Done adding Shane Bieber 95/357\n",
      "Done adding Aaron Civale 96/357\n",
      "Done adding Mike Clevinger 97/357\n",
      "Done adding Alek Manoah 100/357\n",
      "Done adding Wade Miley 101/357\n",
      "Done adding James Paxton 102/357\n",
      "Done adding Grayson Rodriguez 103/357\n",
      "Done adding Michael Wacha 104/357\n",
      "Done adding Brandon Williamson 105/357\n",
      "Done adding Ranger Suárez 108/357\n",
      "Done adding Noah Syndergaard 109/357\n",
      "Done adding Adam Wainwright 110/357\n",
      "Done adding Andrew Abbott 111/357\n",
      "Done adding Taj Bradley 112/357\n",
      "Done adding Hunter Greene 114/357\n",
      "Done adding Kenta Maeda 116/357\n",
      "Done adding Bobby Miller 118/357\n",
      "Done adding Joe Musgrove 119/357\n",
      "Done adding Tyler Glasnow 124/357\n",
      "Done adding Tanner Houck 126/357\n",
      "Done adding Eury Pérez 127/357\n",
      "Done adding Chris Sale 128/357\n",
      "Done adding Matthew Boyd 129/357\n",
      "Done adding Zach Davies 131/357\n",
      "Done adding Matt Manning 132/357\n",
      "Done adding Cal Quantrill 135/357\n",
      "Done adding Cristopher Sánchez 136/357\n",
      "Done adding Bryan Woo 137/357\n",
      "Done adding Gavin Williams 143/357\n",
      "Done adding Nestor Cortes 144/357\n",
      "Done\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2538 entries, 0 to 2537\n",
      "Data columns (total 18 columns):\n",
      " #   Column   Non-Null Count  Dtype         \n",
      "---  ------   --------------  -----         \n",
      " 0   Date     2538 non-null   datetime64[ns]\n",
      " 1   Opp      2538 non-null   object        \n",
      " 2   Dec      2538 non-null   int64         \n",
      " 3   DR       2538 non-null   int64         \n",
      " 4   H        2538 non-null   int64         \n",
      " 5   ER       2538 non-null   int64         \n",
      " 6   BB       2538 non-null   int64         \n",
      " 7   SO       2538 non-null   int64         \n",
      " 8   HR       2538 non-null   int64         \n",
      " 9   HBP      2538 non-null   int64         \n",
      " 10  FIP      2538 non-null   float64       \n",
      " 11  GSc      2538 non-null   int64         \n",
      " 12  2B       2538 non-null   int64         \n",
      " 13  Outs     2538 non-null   int64         \n",
      " 14  points   2538 non-null   int64         \n",
      " 15  QS       2538 non-null   float64       \n",
      " 16  pitcher  2538 non-null   object        \n",
      " 17  code     2538 non-null   object        \n",
      "dtypes: datetime64[ns](1), float64(2), int64(12), object(3)\n",
      "memory usage: 357.0+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Opp</th>\n",
       "      <th>Dec</th>\n",
       "      <th>DR</th>\n",
       "      <th>H</th>\n",
       "      <th>ER</th>\n",
       "      <th>BB</th>\n",
       "      <th>SO</th>\n",
       "      <th>HR</th>\n",
       "      <th>HBP</th>\n",
       "      <th>FIP</th>\n",
       "      <th>GSc</th>\n",
       "      <th>2B</th>\n",
       "      <th>Outs</th>\n",
       "      <th>points</th>\n",
       "      <th>QS</th>\n",
       "      <th>pitcher</th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-04-05</td>\n",
       "      <td>ATL</td>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.72</td>\n",
       "      <td>39</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Miles Mikolas</td>\n",
       "      <td>mikolmi01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-04-11</td>\n",
       "      <td>COL</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5.63</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>-6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Miles Mikolas</td>\n",
       "      <td>mikolmi01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-04-16</td>\n",
       "      <td>PIT</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.86</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Miles Mikolas</td>\n",
       "      <td>mikolmi01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-04-22</td>\n",
       "      <td>SEA</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5.47</td>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Miles Mikolas</td>\n",
       "      <td>mikolmi01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-04-27</td>\n",
       "      <td>SFG</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.93</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>21</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Miles Mikolas</td>\n",
       "      <td>mikolmi01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2533</th>\n",
       "      <td>2023-05-08</td>\n",
       "      <td>OAK</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.37</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Nestor Cortes</td>\n",
       "      <td>cortene01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2534</th>\n",
       "      <td>2023-05-13</td>\n",
       "      <td>TBR</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.56</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Nestor Cortes</td>\n",
       "      <td>cortene01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2535</th>\n",
       "      <td>2023-05-18</td>\n",
       "      <td>TOR</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.48</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Nestor Cortes</td>\n",
       "      <td>cortene01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2536</th>\n",
       "      <td>2023-05-24</td>\n",
       "      <td>BAL</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4.75</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Nestor Cortes</td>\n",
       "      <td>cortene01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2537</th>\n",
       "      <td>2023-05-30</td>\n",
       "      <td>SEA</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.57</td>\n",
       "      <td>52</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Nestor Cortes</td>\n",
       "      <td>cortene01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2538 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date  Opp  Dec  DR   H  ER  BB  SO  HR  HBP   FIP  GSc  2B  Outs  \\\n",
       "0    2023-04-05  ATL   -1   5   9   5   1   6   1    0  2.72   39   2    18   \n",
       "1    2023-04-11  COL    0   5  10   6   2   3   3    0  5.63   24   1    15   \n",
       "2    2023-04-16  PIT    0   4   7   2   2   4   0    0  4.86   47   1    17   \n",
       "3    2023-04-22  SEA    0   5   5   3   2   4   2    0  5.47   48   2    16   \n",
       "4    2023-04-27  SFG    1   4   4   0   2   6   0    1  4.93   69   1    19   \n",
       "...         ...  ...  ...  ..  ..  ..  ..  ..  ..  ...   ...  ...  ..   ...   \n",
       "2533 2023-05-08  OAK    0   7   6   2   2   4   0    0  4.37   49   1    15   \n",
       "2534 2023-05-13  TBR    0   4   7   6   2   3   1    0  4.56   26   1    13   \n",
       "2535 2023-05-18  TOR    1   4   5   2   1   6   1    0  4.48   59   0    18   \n",
       "2536 2023-05-24  BAL    0   5   5   4   2   5   2    0  4.75   49   0    18   \n",
       "2537 2023-05-30  SEA    1   5   5   2   3   6   0    0  4.57   52   3    15   \n",
       "\n",
       "      points   QS        pitcher       code  \n",
       "0          1  0.0  Miles Mikolas  mikolmi01  \n",
       "1         -6  0.0  Miles Mikolas  mikolmi01  \n",
       "2          8  0.0  Miles Mikolas  mikolmi01  \n",
       "3          7  0.0  Miles Mikolas  mikolmi01  \n",
       "4         21  1.0  Miles Mikolas  mikolmi01  \n",
       "...      ...  ...            ...        ...  \n",
       "2533       7  0.0  Nestor Cortes  cortene01  \n",
       "2534      -5  0.0  Nestor Cortes  cortene01  \n",
       "2535      17  1.0  Nestor Cortes  cortene01  \n",
       "2536       8  0.0  Nestor Cortes  cortene01  \n",
       "2537      12  0.0  Nestor Cortes  cortene01  \n",
       "\n",
       "[2538 rows x 18 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is a dataset drawn manually from b-ref.\n",
    "# There is probably a slick way to scrape this\n",
    "# but this only has to be updated every once in a while, not all the time\n",
    "# So manually works for now.\n",
    "all_starters = pd.read_csv('all_starters.csv')\n",
    "\n",
    "all_starters = pd.read_csv('all_starters.csv')\n",
    "\n",
    "\n",
    "## Identify desired columns to keep and drop others\n",
    "# Build list of wanted stats\n",
    "reqd_cols = ['Date','Opp','Dec', 'DR','IP', 'H', 'ER', 'BB', 'SO', 'HR', 'HBP']\n",
    "\n",
    "wanted_cols = []\n",
    "\n",
    "for key, value in stat_selector.items():\n",
    "    if value == 1: wanted_cols.append(key)\n",
    "\n",
    "# Combine with list of required stats\n",
    "keep_cols = reqd_cols + wanted_cols\n",
    "\n",
    "\n",
    "if pit_update == 'y':\n",
    "    # Initialize df\n",
    "    pitcher_data = pd.DataFrame()\n",
    "\n",
    "    for i in range(round(t*len(all_starters))):\n",
    "        try:\n",
    "            code = all_starters.loc[i,'code']\n",
    "            name = all_starters.loc[i,'name']\n",
    "\n",
    "            # Request setup\n",
    "            url = f'https://www.baseball-reference.com/players/gl.fcgi?id={code}&t=p&year=2023'\n",
    "            df = pd.read_html(url)\n",
    "            df = pd.DataFrame(df[0])\n",
    "\n",
    "            # # DATA CLEANING # #\n",
    "\n",
    "            # Drop rows that are mid-table column names\n",
    "            df = df[pd.to_numeric(df['Rk'], errors = 'coerce').notnull()]\n",
    "\n",
    "            # Reset index after dropping some rows\n",
    "            df = df.reset_index()\n",
    "\n",
    "\n",
    "\n",
    "            # Select for selected cols\n",
    "            df = df[keep_cols]\n",
    "\n",
    "            # Now let's make the date column usable\n",
    "            # Clean away situations where there's a double-header impacting the date\n",
    "            df['Date'] = df['Date'].str.split(\"(\", expand = True).loc[:,0]\n",
    "\n",
    "            # Extract day from date\n",
    "            days = df['Date'].str.split(n=1,expand = True).loc[:,1]\n",
    "\n",
    "            # Extract month from date\n",
    "            months = df['Date'].str.split(n=1,expand = True).loc[:,0]\n",
    "\n",
    "            # Convert month to numerical month\n",
    "            months = months.str.replace('Oct','10')\n",
    "            months = months.str.replace('Sep','9')\n",
    "            months = months.str.replace('Aug','8')\n",
    "            months = months.str.replace('Jul','7')\n",
    "            months = months.str.replace('Jun','6')\n",
    "            months = months.str.replace('May','5')\n",
    "            months = months.str.replace('Apr','4')\n",
    "            months = months.str.replace('Mar','3')\n",
    "\n",
    "            # Create year series\n",
    "            df['years'] = '2023'\n",
    "\n",
    "            # Build date string\n",
    "            df['Date'] = df['years'] + \"-\" + months + \"-\" + days\n",
    "\n",
    "            # Drop year series\n",
    "            df = df.drop(columns = ['years'])\n",
    "\n",
    "            # Clean Decision series\n",
    "            df['Dec'] = df['Dec'].str[0]\n",
    "\n",
    "            df['Dec'] = df['Dec'].fillna('0')\n",
    "\n",
    "            df['Dec'] = df['Dec'].str.replace('W','1')\n",
    "            df['Dec'] = df['Dec'].str.replace('L','-1')\n",
    "            df['Dec'] = df['Dec'].str.replace('B','-1')\n",
    "            df['Dec'] = df['Dec'].str.replace('S','2')\n",
    "            df['Dec'] = df['Dec'].str.replace('H','0')\n",
    "\n",
    "            # Make everything a string before the step below. Don't worry, we'll fix this later on.\n",
    "            # This is because some of our data processing functions require string inputs,\n",
    "            # and our data scraper might accidentally infer some things as numbers.\n",
    "            # We have to do this\n",
    "            df = df.applymap(str)\n",
    "\n",
    "            # Make outs series, convert IP to Outs, then drop IP series\n",
    "            whole = df['IP'].str.split(\".\", expand = True)[0].astype('int')\n",
    "            part = df['IP'].str.split(\".\", expand = True)[1].astype('int')\n",
    "\n",
    "            df['Outs'] = 3*whole + part\n",
    "\n",
    "            df = df.drop(columns = ['IP'])\n",
    "\n",
    "            # Sometimes my DR column gets interpreted as a float, that gets turned into a string,\n",
    "            # that can't be turned directly into an int. But it can be interpreted as a float, from a string,\n",
    "            # so we do that first, and then we can convert it to an int without issue.\n",
    "            df['DR'] = df['DR'].astype('float')\n",
    "\n",
    "            # Make a dictionary that will tell me what to cast each type as\n",
    "            dtype_applier = {}\n",
    "            for key, value in pitcher_data_cols_dtypes.items():\n",
    "                if key in keep_cols: dtype_applier[key]=value\n",
    "\n",
    "            # Cast numerical datatypes as numbers\n",
    "            df = df.astype(dtype_applier)\n",
    "\n",
    "            # Convert date string to date type\n",
    "            df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "            # Calculate fantasy points\n",
    "            df['points'] = 3*df['Dec'] - df['H'] - 2*df['ER'] - df['BB'] + df['SO'] - df['HBP'] + df['Outs']\n",
    "\n",
    "            # Create quality start series QS\n",
    "            for row in range(1,len(df)):\n",
    "                if df.loc[row,'ER']<=3 and df.loc[row,'Outs']>=18: df.loc[row,'QS'] = 1\n",
    "                else: df.loc[row,'QS'] = 0\n",
    "\n",
    "            # Add in pitcher name and code\n",
    "            df['pitcher'] = name\n",
    "            df['code'] = code\n",
    "\n",
    "            # Drop starts following 30+ days rest\n",
    "            df = df[df['DR'] <30]\n",
    "\n",
    "            # Add it to the overall pitcher data df\n",
    "            pitcher_data = pitcher_data.append(df, ignore_index=True)\n",
    "\n",
    "            # Let me know we're done with that player\n",
    "            print(f'Done adding {name} {i}/{len(all_starters)}')\n",
    "\n",
    "            # Wait for 3.5 seconds, b/c baseball-reference has a 20 request/min limit\n",
    "            time.sleep(3.5)\n",
    "        except: print(f'ERROR with {name} {i}/{len(all_starters)}')\n",
    "\n",
    "\n",
    "    # Export to csv\n",
    "    pitcher_data.to_csv('pitcher_data.csv',index = False)\n",
    "\n",
    "    print(\"Done\")\n",
    "\n",
    "# If we aren't pulling/updating data, just load whatever we had from the last time we ran it\n",
    "else: pitcher_data = pd.read_csv('pitcher_data.csv')\n",
    "\n",
    "pitcher_data['Date'] = pd.to_datetime(pitcher_data['Date'])\n",
    "\n",
    "pitcher_data.info()\n",
    "\n",
    "pitcher_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc44ef6",
   "metadata": {},
   "source": [
    "### This is the notebook where I take pitcher starting performance, and create a df of \"previous\" performance before each start, for each pitcher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "805d5161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.<=0', '0<.<=12', '12<.<=24', '24<.<=36', '36<.<=48']\n"
     ]
    }
   ],
   "source": [
    "# Calculate performance buckets\n",
    "N = math.ceil(30/bucket_width)+1\n",
    "th = [bucket_width*n for n in list(range(N+1))]\n",
    "\n",
    "# Build ordered list of bucket labels\n",
    "bucket_labels = ['.<=0']\n",
    "\n",
    "for j in range(len(th)-1):\n",
    "    bucket = f'{th[j]}<.<={th[j+1]}'\n",
    "    bucket_labels.append(bucket)\n",
    "\n",
    "print(bucket_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a1bc8a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2538 entries, 0 to 2537\n",
      "Data columns (total 17 columns):\n",
      " #   Column    Non-Null Count  Dtype         \n",
      "---  ------    --------------  -----         \n",
      " 0   Dec_1     2430 non-null   float64       \n",
      " 1   DR_1      2430 non-null   float64       \n",
      " 2   H_1       2430 non-null   float64       \n",
      " 3   ER_1      2430 non-null   float64       \n",
      " 4   BB_1      2430 non-null   float64       \n",
      " 5   SO_1      2430 non-null   float64       \n",
      " 6   HR_1      2430 non-null   float64       \n",
      " 7   HBP_1     2430 non-null   float64       \n",
      " 8   FIP_1     2430 non-null   float64       \n",
      " 9   GSc_1     2430 non-null   float64       \n",
      " 10  2B_1      2430 non-null   float64       \n",
      " 11  Outs_1    2430 non-null   float64       \n",
      " 12  points_1  2430 non-null   float64       \n",
      " 13  QS_1      2430 non-null   float64       \n",
      " 14  Date      2538 non-null   datetime64[ns]\n",
      " 15  code      2538 non-null   object        \n",
      " 16  bucket_1  2430 non-null   object        \n",
      "dtypes: datetime64[ns](1), float64(14), object(2)\n",
      "memory usage: 337.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pitcher_data\n",
    "\n",
    "# This is me getting a df of how the given pitcher performed\n",
    "# in the outing immediately before the given date\n",
    "df_last = pd.DataFrame()\n",
    "\n",
    "for i in range(len(df)):\n",
    "    # For a given row i, extract the code and date for that row\n",
    "    date = df.loc[i,:].Date\n",
    "    code = df.loc[i,:].code\n",
    "\n",
    "    # Given a code/date, extract the previous game data\n",
    "    df_last1 = df.loc[(df.Date < date) & (df.code == code)].sort_values('Date').tail(1)\n",
    "    \n",
    "    df_last1 = df_last1.drop(columns = ['Date', 'Opp','pitcher','code'])\n",
    "\n",
    "    # Get the average of those 1 rows, find the averages of averageable, transpose it from series to row\n",
    "    df_last1_avg = pd.DataFrame(df_last1.mean(axis=0)).transpose()\n",
    "\n",
    "    # Rename cols to indicate\n",
    "    df_last1_avg.columns = [f\"{col}_1\" for col in df_last1_avg.columns]\n",
    "\n",
    "    # Assign it to the date and code we're working with\n",
    "    df_last1_avg['Date'] = date\n",
    "    df_last1_avg['code'] = code\n",
    "\n",
    "    # Append into the last few games df\n",
    "    df_last = df_last.append(df_last1_avg)\n",
    "\n",
    "# Rest the index so that we can .loc through it\n",
    "df_last = df_last.reset_index(drop=True)\n",
    "\n",
    "#  Put in the performance buckets\n",
    "for row in range(1,len(df_last)):\n",
    "    for j in range(len(th)-1):\n",
    "        if (df_last.loc[row,'points_1']>th[j]) and (df_last.loc[row,'points_1']<=th[j+1]):\n",
    "            df_last.loc[row,'bucket_1'] = f'{th[j]}<.<={th[j+1]}'\n",
    "        if df_last.loc[row,'points_1']<=0: df_last.loc[row,'bucket_1'] = '.<=0'\n",
    "\n",
    "df_last.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2cc5a2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2538 entries, 0 to 2537\n",
      "Data columns (total 17 columns):\n",
      " #   Column    Non-Null Count  Dtype         \n",
      "---  ------    --------------  -----         \n",
      " 0   Dec_4     2430 non-null   float64       \n",
      " 1   DR_4      2430 non-null   float64       \n",
      " 2   H_4       2430 non-null   float64       \n",
      " 3   ER_4      2430 non-null   float64       \n",
      " 4   BB_4      2430 non-null   float64       \n",
      " 5   SO_4      2430 non-null   float64       \n",
      " 6   HR_4      2430 non-null   float64       \n",
      " 7   HBP_4     2430 non-null   float64       \n",
      " 8   FIP_4     2430 non-null   float64       \n",
      " 9   GSc_4     2430 non-null   float64       \n",
      " 10  2B_4      2430 non-null   float64       \n",
      " 11  Outs_4    2430 non-null   float64       \n",
      " 12  points_4  2430 non-null   float64       \n",
      " 13  QS_4      2430 non-null   float64       \n",
      " 14  Date      2538 non-null   datetime64[ns]\n",
      " 15  code      2538 non-null   object        \n",
      " 16  bucket_4  2430 non-null   object        \n",
      "dtypes: datetime64[ns](1), float64(14), object(2)\n",
      "memory usage: 337.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df_lastfew = pd.DataFrame()\n",
    "\n",
    "for i in range(len(df)):\n",
    "    # For a given row i, extract the code and date for that row\n",
    "    date = df.loc[i,:].Date\n",
    "    code = df.loc[i,:].code\n",
    "\n",
    "    # Given a code/date, extract the previous N games of data\n",
    "    df_lastN = df.loc[(df.Date < date) & (df.code == code)].sort_values('Date').tail(N)\n",
    "    \n",
    "    df_lastN = df_lastN.drop(columns = ['Date', 'Opp','pitcher','code'])\n",
    "\n",
    "    # Get the average of those N rows, find the averages of averageable series, transpose it from series to row\n",
    "    df_lastN_avg = pd.DataFrame(df_lastN.mean(axis=0)).transpose()\n",
    "\n",
    "    # Rename cols to indicate what it's the average of, and over how many games\n",
    "    df_lastN_avg.columns = [f'{col}_{N}' for col in df_lastN_avg.columns]\n",
    "\n",
    "    # Assign it to the date and code we're working with\n",
    "    df_lastN_avg['Date'] = date\n",
    "    df_lastN_avg['code'] = code\n",
    "\n",
    "    # Append into the last few games df\n",
    "    df_lastfew = df_lastfew.append(df_lastN_avg)\n",
    "\n",
    "# Rest the index so that we can .loc through it\n",
    "df_lastfew = df_lastfew.reset_index(drop=True)\n",
    "\n",
    "# Put in the performance buckets\n",
    "for row in range(1,len(df_lastfew)):\n",
    "    for j in range(len(th)-1):\n",
    "        if (df_lastfew.loc[row,f'points_{N}']>th[j]) and (df_lastfew.loc[row,f'points_{N}']<=th[j+1]):\n",
    "            df_lastfew.loc[row,f'bucket_{N}'] = f'{th[j]}<.<={th[j+1]}'\n",
    "        if df_lastfew.loc[row,f'points_{N}']<=0: df_lastfew.loc[row,f'bucket_{N}'] = '.<=0'\n",
    "\n",
    "df_lastfew.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70cce412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2538 entries, 0 to 2537\n",
      "Data columns (total 17 columns):\n",
      " #   Column      Non-Null Count  Dtype         \n",
      "---  ------      --------------  -----         \n",
      " 0   Dec_all     2430 non-null   float64       \n",
      " 1   DR_all      2430 non-null   float64       \n",
      " 2   H_all       2430 non-null   float64       \n",
      " 3   ER_all      2430 non-null   float64       \n",
      " 4   BB_all      2430 non-null   float64       \n",
      " 5   SO_all      2430 non-null   float64       \n",
      " 6   HR_all      2430 non-null   float64       \n",
      " 7   HBP_all     2430 non-null   float64       \n",
      " 8   FIP_all     2430 non-null   float64       \n",
      " 9   GSc_all     2430 non-null   float64       \n",
      " 10  2B_all      2430 non-null   float64       \n",
      " 11  Outs_all    2430 non-null   float64       \n",
      " 12  points_all  2430 non-null   float64       \n",
      " 13  QS_all      2430 non-null   float64       \n",
      " 14  Date        2538 non-null   datetime64[ns]\n",
      " 15  code        2538 non-null   object        \n",
      " 16  bucket_all  2430 non-null   object        \n",
      "dtypes: datetime64[ns](1), float64(14), object(2)\n",
      "memory usage: 337.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df_cummulative = pd.DataFrame()\n",
    "\n",
    "for i in range(len(df)):\n",
    "    # For a given row i, extract the code and date for that row\n",
    "    date = df.loc[i,:].Date\n",
    "    code = df.loc[i,:].code\n",
    "\n",
    "    # Given a code/date, extract the previous game data\n",
    "    df_cummu = df.loc[(df.Date < date) & (df.code == code)].sort_values('Date')\n",
    "    \n",
    "    df_cummu = df_cummu.drop(columns = ['Date', 'Opp','pitcher','code'])\n",
    "\n",
    "    # Get the average of all rows, find the averages of averageable, transpose it from series to row\n",
    "    df_cummu_avg = pd.DataFrame(df_cummu.mean(axis=0)).transpose()\n",
    "\n",
    "    # Rename cols to indicate\n",
    "    df_cummu_avg.columns = [f\"{col}_all\" for col in df_cummu_avg.columns]\n",
    "\n",
    "    # Assign it to the date and code we're working with\n",
    "    df_cummu_avg['Date'] = date\n",
    "    df_cummu_avg['code'] = code\n",
    "\n",
    "    # Append into the last few games df\n",
    "    df_cummulative = df_cummulative.append(df_cummu_avg)\n",
    "\n",
    "# Rest the index so that we can .loc through it\n",
    "df_cummulative = df_cummulative.reset_index(drop=True)\n",
    "\n",
    "# Put in the performance buckets\n",
    "for row in range(1,len(df_cummulative)):\n",
    "    for j in range(len(th)-1):\n",
    "        if (df_cummulative.loc[row,'points_all']>th[j]) and (df_cummulative.loc[row,'points_all']<=th[j+1]):\n",
    "            df_cummulative.loc[row,'bucket_all'] = f'{th[j]}<.<={th[j+1]}'\n",
    "        if df_cummulative.loc[row,'points_all']<=0: df_cummulative.loc[row,'bucket_all'] = '.<=0'\n",
    "\n",
    "df_cummulative.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "586aceb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2538 entries, 0 to 2537\n",
      "Data columns (total 50 columns):\n",
      " #   Column      Non-Null Count  Dtype         \n",
      "---  ------      --------------  -----         \n",
      " 0   Date        2538 non-null   datetime64[ns]\n",
      " 1   Opp         2538 non-null   object        \n",
      " 2   points      2538 non-null   int64         \n",
      " 3   pitcher     2538 non-null   object        \n",
      " 4   code        2538 non-null   object        \n",
      " 5   Dec_1       2430 non-null   float64       \n",
      " 6   DR_1        2430 non-null   float64       \n",
      " 7   H_1         2430 non-null   float64       \n",
      " 8   ER_1        2430 non-null   float64       \n",
      " 9   BB_1        2430 non-null   float64       \n",
      " 10  SO_1        2430 non-null   float64       \n",
      " 11  HR_1        2430 non-null   float64       \n",
      " 12  HBP_1       2430 non-null   float64       \n",
      " 13  FIP_1       2430 non-null   float64       \n",
      " 14  GSc_1       2430 non-null   float64       \n",
      " 15  2B_1        2430 non-null   float64       \n",
      " 16  Outs_1      2430 non-null   float64       \n",
      " 17  points_1    2430 non-null   float64       \n",
      " 18  QS_1        2430 non-null   float64       \n",
      " 19  bucket_1    2430 non-null   object        \n",
      " 20  Dec_4       2430 non-null   float64       \n",
      " 21  DR_4        2430 non-null   float64       \n",
      " 22  H_4         2430 non-null   float64       \n",
      " 23  ER_4        2430 non-null   float64       \n",
      " 24  BB_4        2430 non-null   float64       \n",
      " 25  SO_4        2430 non-null   float64       \n",
      " 26  HR_4        2430 non-null   float64       \n",
      " 27  HBP_4       2430 non-null   float64       \n",
      " 28  FIP_4       2430 non-null   float64       \n",
      " 29  GSc_4       2430 non-null   float64       \n",
      " 30  2B_4        2430 non-null   float64       \n",
      " 31  Outs_4      2430 non-null   float64       \n",
      " 32  points_4    2430 non-null   float64       \n",
      " 33  QS_4        2430 non-null   float64       \n",
      " 34  bucket_4    2430 non-null   object        \n",
      " 35  Dec_all     2430 non-null   float64       \n",
      " 36  DR_all      2430 non-null   float64       \n",
      " 37  H_all       2430 non-null   float64       \n",
      " 38  ER_all      2430 non-null   float64       \n",
      " 39  BB_all      2430 non-null   float64       \n",
      " 40  SO_all      2430 non-null   float64       \n",
      " 41  HR_all      2430 non-null   float64       \n",
      " 42  HBP_all     2430 non-null   float64       \n",
      " 43  FIP_all     2430 non-null   float64       \n",
      " 44  GSc_all     2430 non-null   float64       \n",
      " 45  2B_all      2430 non-null   float64       \n",
      " 46  Outs_all    2430 non-null   float64       \n",
      " 47  points_all  2430 non-null   float64       \n",
      " 48  QS_all      2430 non-null   float64       \n",
      " 49  bucket_all  2430 non-null   object        \n",
      "dtypes: datetime64[ns](1), float64(42), int64(1), object(6)\n",
      "memory usage: 1011.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# Merge in all those different windows of data\n",
    "\n",
    "# Merge in last 1 game of data\n",
    "compiled_df = pd.merge(df,df_last,\n",
    "                       on = ['Date','code'])\n",
    "\n",
    "# Merge in last N games of data\n",
    "compiled_df = pd.merge(compiled_df,df_lastfew,\n",
    "                       on = ['Date','code'])\n",
    "\n",
    "# Merge in all season games of data\n",
    "compiled_df = pd.merge(compiled_df,df_cummulative,\n",
    "                       on = ['Date','code'])\n",
    "\n",
    "# Drop the data from that day, so we're only training on data that is known at the time before the given date\n",
    "dont_drop_from_reqs = ['IP','Dec','Date','Opp']\n",
    "reqs_to_drop = [ele for ele in reqd_cols if ele not in dont_drop_from_reqs]\n",
    "drop_cols = ['QS', 'Outs', 'Dec']+wanted_cols+reqs_to_drop\n",
    "\n",
    "pitcher_perf = compiled_df.drop(columns = drop_cols)\n",
    "\n",
    "pitcher_perf.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2931484d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Opp</th>\n",
       "      <th>points</th>\n",
       "      <th>pitcher</th>\n",
       "      <th>code</th>\n",
       "      <th>Dec_1</th>\n",
       "      <th>DR_1</th>\n",
       "      <th>H_1</th>\n",
       "      <th>ER_1</th>\n",
       "      <th>BB_1</th>\n",
       "      <th>...</th>\n",
       "      <th>HR_all</th>\n",
       "      <th>HBP_all</th>\n",
       "      <th>FIP_all</th>\n",
       "      <th>GSc_all</th>\n",
       "      <th>2B_all</th>\n",
       "      <th>Outs_all</th>\n",
       "      <th>points_all</th>\n",
       "      <th>QS_all</th>\n",
       "      <th>bucket_all</th>\n",
       "      <th>bucket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-04-11</td>\n",
       "      <td>COL</td>\n",
       "      <td>-6</td>\n",
       "      <td>Miles Mikolas</td>\n",
       "      <td>mikolmi01</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.720000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0&lt;.&lt;=12</td>\n",
       "      <td>.&lt;=0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-04-16</td>\n",
       "      <td>PIT</td>\n",
       "      <td>8</td>\n",
       "      <td>Miles Mikolas</td>\n",
       "      <td>mikolmi01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.175000</td>\n",
       "      <td>31.500000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>16.500000</td>\n",
       "      <td>-2.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>.&lt;=0</td>\n",
       "      <td>0&lt;.&lt;=12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-04-22</td>\n",
       "      <td>SEA</td>\n",
       "      <td>7</td>\n",
       "      <td>Miles Mikolas</td>\n",
       "      <td>mikolmi01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.403333</td>\n",
       "      <td>36.666667</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>16.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0&lt;.&lt;=12</td>\n",
       "      <td>0&lt;.&lt;=12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-04-27</td>\n",
       "      <td>SFG</td>\n",
       "      <td>21</td>\n",
       "      <td>Miles Mikolas</td>\n",
       "      <td>mikolmi01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.670000</td>\n",
       "      <td>39.500000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>16.500000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0&lt;.&lt;=12</td>\n",
       "      <td>12&lt;.&lt;=24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-05-03</td>\n",
       "      <td>LAA</td>\n",
       "      <td>7</td>\n",
       "      <td>Miles Mikolas</td>\n",
       "      <td>mikolmi01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>4.722000</td>\n",
       "      <td>45.400000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0&lt;.&lt;=12</td>\n",
       "      <td>0&lt;.&lt;=12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2533</th>\n",
       "      <td>2023-05-08</td>\n",
       "      <td>OAK</td>\n",
       "      <td>7</td>\n",
       "      <td>Nestor Cortes</td>\n",
       "      <td>cortene01</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>16.800000</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0&lt;.&lt;=12</td>\n",
       "      <td>0&lt;.&lt;=12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2534</th>\n",
       "      <td>2023-05-13</td>\n",
       "      <td>TBR</td>\n",
       "      <td>-5</td>\n",
       "      <td>Nestor Cortes</td>\n",
       "      <td>cortene01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3.645000</td>\n",
       "      <td>50.666667</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>16.500000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0&lt;.&lt;=12</td>\n",
       "      <td>.&lt;=0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2535</th>\n",
       "      <td>2023-05-18</td>\n",
       "      <td>TOR</td>\n",
       "      <td>17</td>\n",
       "      <td>Nestor Cortes</td>\n",
       "      <td>cortene01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>3.775714</td>\n",
       "      <td>47.142857</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0&lt;.&lt;=12</td>\n",
       "      <td>12&lt;.&lt;=24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2536</th>\n",
       "      <td>2023-05-24</td>\n",
       "      <td>BAL</td>\n",
       "      <td>8</td>\n",
       "      <td>Nestor Cortes</td>\n",
       "      <td>cortene01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>3.863750</td>\n",
       "      <td>48.625000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>16.250000</td>\n",
       "      <td>8.250000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0&lt;.&lt;=12</td>\n",
       "      <td>0&lt;.&lt;=12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2537</th>\n",
       "      <td>2023-05-30</td>\n",
       "      <td>SEA</td>\n",
       "      <td>12</td>\n",
       "      <td>Nestor Cortes</td>\n",
       "      <td>cortene01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.111111</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>3.962222</td>\n",
       "      <td>48.666667</td>\n",
       "      <td>1.111111</td>\n",
       "      <td>16.444444</td>\n",
       "      <td>8.222222</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0&lt;.&lt;=12</td>\n",
       "      <td>0&lt;.&lt;=12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2430 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date  Opp  points        pitcher       code  Dec_1  DR_1   H_1  \\\n",
       "1    2023-04-11  COL      -6  Miles Mikolas  mikolmi01   -1.0   5.0   9.0   \n",
       "2    2023-04-16  PIT       8  Miles Mikolas  mikolmi01    0.0   5.0  10.0   \n",
       "3    2023-04-22  SEA       7  Miles Mikolas  mikolmi01    0.0   4.0   7.0   \n",
       "4    2023-04-27  SFG      21  Miles Mikolas  mikolmi01    0.0   5.0   5.0   \n",
       "5    2023-05-03  LAA       7  Miles Mikolas  mikolmi01    1.0   4.0   4.0   \n",
       "...         ...  ...     ...            ...        ...    ...   ...   ...   \n",
       "2533 2023-05-08  OAK       7  Nestor Cortes  cortene01   -1.0   4.0   5.0   \n",
       "2534 2023-05-13  TBR      -5  Nestor Cortes  cortene01    0.0   7.0   6.0   \n",
       "2535 2023-05-18  TOR      17  Nestor Cortes  cortene01    0.0   4.0   7.0   \n",
       "2536 2023-05-24  BAL       8  Nestor Cortes  cortene01    1.0   4.0   5.0   \n",
       "2537 2023-05-30  SEA      12  Nestor Cortes  cortene01    0.0   5.0   5.0   \n",
       "\n",
       "      ER_1  BB_1  ...    HR_all   HBP_all   FIP_all    GSc_all    2B_all  \\\n",
       "1      5.0   1.0  ...  1.000000  0.000000  2.720000  39.000000  2.000000   \n",
       "2      6.0   2.0  ...  2.000000  0.000000  4.175000  31.500000  1.500000   \n",
       "3      2.0   2.0  ...  1.333333  0.000000  4.403333  36.666667  1.333333   \n",
       "4      3.0   2.0  ...  1.500000  0.000000  4.670000  39.500000  1.500000   \n",
       "5      0.0   2.0  ...  1.200000  0.200000  4.722000  45.400000  1.400000   \n",
       "...    ...   ...  ...       ...       ...       ...        ...       ...   \n",
       "2533   7.0   4.0  ...  1.200000  0.600000  3.500000  51.000000  1.600000   \n",
       "2534   2.0   2.0  ...  1.000000  0.500000  3.645000  50.666667  1.500000   \n",
       "2535   6.0   2.0  ...  1.000000  0.428571  3.775714  47.142857  1.428571   \n",
       "2536   2.0   1.0  ...  1.000000  0.375000  3.863750  48.625000  1.250000   \n",
       "2537   4.0   2.0  ...  1.111111  0.333333  3.962222  48.666667  1.111111   \n",
       "\n",
       "       Outs_all  points_all    QS_all  bucket_all    bucket  \n",
       "1     18.000000    1.000000  0.000000     0<.<=12      .<=0  \n",
       "2     16.500000   -2.500000  0.000000        .<=0   0<.<=12  \n",
       "3     16.666667    1.000000  0.000000     0<.<=12   0<.<=12  \n",
       "4     16.500000    2.500000  0.000000     0<.<=12  12<.<=24  \n",
       "5     17.000000    6.200000  0.200000     0<.<=12   0<.<=12  \n",
       "...         ...         ...       ...         ...       ...  \n",
       "2533  16.800000    9.400000  0.400000     0<.<=12   0<.<=12  \n",
       "2534  16.500000    9.000000  0.333333     0<.<=12      .<=0  \n",
       "2535  16.000000    7.000000  0.285714     0<.<=12  12<.<=24  \n",
       "2536  16.250000    8.250000  0.375000     0<.<=12   0<.<=12  \n",
       "2537  16.444444    8.222222  0.333333     0<.<=12   0<.<=12  \n",
       "\n",
       "[2430 rows x 51 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rest the index so that we can .loc through it\n",
    "pitcher_perf = pitcher_perf.reset_index(drop=True)\n",
    "\n",
    "# Put in the performance buckets\n",
    "for row in range(1,len(pitcher_perf)):\n",
    "    for j in range(len(th)-1):\n",
    "        if (pitcher_perf.loc[row,'points']>th[j]) and (pitcher_perf.loc[row,'points']<=th[j+1]):\n",
    "            pitcher_perf.loc[row,'bucket'] = f'{th[j]}<.<={th[j+1]}'\n",
    "        if pitcher_perf.loc[row,'points']<=0: pitcher_perf.loc[row,'bucket'] = '.<=0'\n",
    "\n",
    "# These NaNs from asking for performance on the last 1, N games when there have been fewer than 1, N games\n",
    "pitcher_perf = pitcher_perf.dropna()\n",
    "\n",
    "# Export to csv\n",
    "pitcher_perf.to_csv('pitcher_previous_perf.csv',index = False)\n",
    "\n",
    "pitcher_perf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da689a7e",
   "metadata": {},
   "source": [
    "### This is the section where for each team, before a given game, I calculate their previous performance\n",
    "\n",
    "Things it'd be cool to add here:\\\n",
    "In the progress printout, maybe include the number of records in each team?\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8a0e1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4584 entries, 0 to 4583\n",
      "Data columns (total 20 columns):\n",
      " #   Column   Non-Null Count  Dtype         \n",
      "---  ------   --------------  -----         \n",
      " 0   PA_30    4584 non-null   float64       \n",
      " 1   R_30     4584 non-null   float64       \n",
      " 2   H_30     4584 non-null   float64       \n",
      " 3   HR_30    4584 non-null   float64       \n",
      " 4   BB_30    4584 non-null   float64       \n",
      " 5   SO_30    4584 non-null   float64       \n",
      " 6   OBP_30   4584 non-null   float64       \n",
      " 7   SLG_30   4584 non-null   float64       \n",
      " 8   LOB_30   4584 non-null   float64       \n",
      " 9   Date     4584 non-null   datetime64[ns]\n",
      " 10  Team     4584 non-null   object        \n",
      " 11  PA_all   4584 non-null   float64       \n",
      " 12  R_all    4584 non-null   float64       \n",
      " 13  H_all    4584 non-null   float64       \n",
      " 14  HR_all   4584 non-null   float64       \n",
      " 15  BB_all   4584 non-null   float64       \n",
      " 16  SO_all   4584 non-null   float64       \n",
      " 17  OBP_all  4584 non-null   float64       \n",
      " 18  SLG_all  4584 non-null   float64       \n",
      " 19  LOB_all  4584 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(18), object(1)\n",
      "memory usage: 716.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# Get team codes\n",
    "team_codes = pd.read_csv('team_codes.csv')\n",
    "codes = team_codes['code'].tolist()\n",
    "\n",
    "if opp_update == 'y':\n",
    "    ## Make last 30 days df\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    # For every team in our list of team codes\n",
    "    for i in range(round(t*len(codes))):\n",
    "\n",
    "        # Loop through teams\n",
    "        team = codes[i]\n",
    "\n",
    "        # Request setup\n",
    "        url = f'https://www.baseball-reference.com/teams/tgl.cgi?team={team}&t=b&year=2023'\n",
    "\n",
    "        team_df = pd.read_html(url)\n",
    "        team_df = pd.DataFrame((team_df[0]))\n",
    "\n",
    "        # Add team identifier\n",
    "        team_df['Team'] = team\n",
    "\n",
    "        # Append into overall team dataframe\n",
    "        df = df.append(team_df)\n",
    "\n",
    "        # Print status\n",
    "        print(f'Done: {team}')\n",
    "\n",
    "        # Wait for >3 seconds b/c site limits requests to 20/min\n",
    "        time.sleep(4)\n",
    "\n",
    "    ## Now we clean the data!\n",
    "    # Build list of wanted stats\n",
    "    wanted_cols = []\n",
    "\n",
    "    for key, value in opp_stat_selector.items():\n",
    "        if value == 1: wanted_cols.append(key)\n",
    "\n",
    "    reqd_cols = ['Team', 'Date', 'PA']\n",
    "\n",
    "    # Combine with list of required stats\n",
    "    keep_cols = reqd_cols + wanted_cols\n",
    "\n",
    "    # Select for those key columns\n",
    "    df = df[keep_cols]\n",
    "\n",
    "    # Drop rows that contain mid-table row headers\n",
    "    df = df[pd.to_numeric(df['PA'], errors='coerce').notnull()]\n",
    "\n",
    "    # Now let's make the date column usable\n",
    "    # Clean away situations where there's a double-header impacting the date\n",
    "    df['Date'] = df['Date'].str.split(\"(\", expand = True).loc[:,0]\n",
    "\n",
    "    # Extract day from date\n",
    "    days = df['Date'].str.split(n=1,expand = True).loc[:,1]\n",
    "\n",
    "    # Extract month from date\n",
    "    months = df['Date'].str.split(n=1,expand = True).loc[:,0]\n",
    "\n",
    "    # Convert month to numerical month\n",
    "    months = months.str.replace('Oct','10')\n",
    "    months = months.str.replace('Sep','9')\n",
    "    months = months.str.replace('Aug','8')\n",
    "    months = months.str.replace('Jul','7')\n",
    "    months = months.str.replace('Jun','6')\n",
    "    months = months.str.replace('May','5')\n",
    "    months = months.str.replace('Apr','4')\n",
    "    months = months.str.replace('Mar','3')\n",
    "\n",
    "    # Create year series\n",
    "    df['years'] = '2023'\n",
    "\n",
    "    # Build date string\n",
    "    df['Date'] = df['years'] + \"-\" + months + \"-\" + days\n",
    "\n",
    "    # Drop year series\n",
    "    df = df.drop(columns = ['years'])\n",
    "\n",
    "    # Cast series as numeric/datetime\n",
    "    df = df.apply(pd.to_numeric, errors = 'ignore')\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "    df = df.reset_index(drop = True)\n",
    "\n",
    "    ##\n",
    "    # Variable to determine the length of our rolling average\n",
    "    M=30\n",
    "\n",
    "    # Now let's make a df showing the average performance over the last N days\n",
    "\n",
    "    # Initialize our df\n",
    "    df_LM = pd.DataFrame()\n",
    "\n",
    "    for i in range(len(df)):\n",
    "\n",
    "        # For a given row i, extract the code and date for that row\n",
    "        date = df.loc[i,:].Date\n",
    "        team = df.loc[i,:].Team\n",
    "\n",
    "        # Given a code/date, extract the previous game data\n",
    "        # WHAT AM I GOING TO DO IF THERE IS NO PREVIOUS GAME DATA?!??!!\n",
    "        df_lastM = df.loc[(df['Date'] < date) & (df['Team'] == team)].sort_values('Date').tail(M)\n",
    "\n",
    "        # Get the average of those N rows, find the averages of averageable, transpose it from series to row\n",
    "        df_lastM_avg = pd.DataFrame(df_lastM.mean(axis=0)).transpose()\n",
    "\n",
    "        # Rename cols to indicate\n",
    "        df_lastM_avg.columns = [f\"{col}_{M}\" for col in df_lastM_avg.columns]\n",
    "\n",
    "        # Assign it to the date and code we're working with\n",
    "        df_lastM_avg['Date'] = date\n",
    "        df_lastM_avg['code'] = team\n",
    "\n",
    "        # Append into the last few games df\n",
    "        df_LM = df_LM.append(df_lastM_avg)\n",
    "\n",
    "    # Drop errant team name column\n",
    "    df_LM = df_LM.drop(columns = [f'Team_{M}'])\n",
    "\n",
    "    # Relabel code column as true team name column\n",
    "    df_LM = df_LM.rename(columns={\"code\": \"Team\"})\n",
    "\n",
    "    df_LM = df_LM.reset_index(drop=True)\n",
    "\n",
    "    ##\n",
    "\n",
    "    # Now let's make the season running total df\n",
    "    df_Lall = pd.DataFrame()\n",
    "\n",
    "    for i in range(len(df)):\n",
    "\n",
    "        # For a given row i, extract the code and date for that row\n",
    "        date = df.loc[i,:].Date\n",
    "        team = df.loc[i,:].Team\n",
    "\n",
    "        # Given a code/date, extract the previous game data\n",
    "        df_lastall = df.loc[(df['Date'] < date) & (df['Team'] == team)]\n",
    "\n",
    "        # Get the average of those 5 rows, find the averages of averageable, transpose it from series to row\n",
    "        df_lastall_avg = pd.DataFrame(df_lastall.mean(axis=0)).transpose()\n",
    "\n",
    "        # Rename cols to indicate\n",
    "        df_lastall_avg.columns = [f\"{col}_all\" for col in df_lastall_avg.columns]\n",
    "\n",
    "        # Assign it to the date and code we're working with\n",
    "        df_lastall_avg['Date'] = date\n",
    "        df_lastall_avg['code'] = team\n",
    "\n",
    "        # Append into the last few games df\n",
    "        df_Lall = df_Lall.append(df_lastall_avg)\n",
    "\n",
    "    # Drop errant team name column\n",
    "    df_Lall = df_Lall.drop(columns = ['Team_all'])\n",
    "\n",
    "    # Relabel code column as true team name column\n",
    "    df_Lall = df_Lall.rename(columns={\"code\": \"Team\"})\n",
    "\n",
    "    df_Lall = df_Lall.reset_index(drop=True)\n",
    "\n",
    "    ##\n",
    "\n",
    "    # Now let's combine these to dataframes to make an overall 'previous performance'\n",
    "    opp_prev_perf = df_LM.merge(df_Lall, on = ['Team', 'Date'])\n",
    "\n",
    "    # Drop rows that are NaN bc there weren't any previous days of performance to pull (i.e., first day in window)\n",
    "    opp_prev_perf = opp_prev_perf.dropna()\n",
    "\n",
    "    # Export to csv\n",
    "    opp_prev_perf.to_csv('opp_previous_perf.csv', index = False)\n",
    "\n",
    "    print('Done')\n",
    "\n",
    "else: opp_prev_perf = pd.read_csv('opp_previous_perf.csv')\n",
    "\n",
    "opp_prev_perf['Date'] = pd.to_datetime(opp_prev_perf['Date'])\n",
    "\n",
    "opp_prev_perf.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2845d832",
   "metadata": {},
   "source": [
    "This is where we make the combined df of all data to train on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94f2109c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2622 entries, 0 to 2621\n",
      "Data columns (total 69 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   bucket          2622 non-null   object        \n",
      " 1   Date            2622 non-null   datetime64[ns]\n",
      " 2   Opp             2622 non-null   object        \n",
      " 3   pitcher         2622 non-null   object        \n",
      " 4   code            2622 non-null   object        \n",
      " 5   Dec_1           2622 non-null   float64       \n",
      " 6   DR_1            2622 non-null   float64       \n",
      " 7   H_1             2622 non-null   float64       \n",
      " 8   ER_1            2622 non-null   float64       \n",
      " 9   BB_1            2622 non-null   float64       \n",
      " 10  SO_1            2622 non-null   float64       \n",
      " 11  HR_1            2622 non-null   float64       \n",
      " 12  HBP_1           2622 non-null   float64       \n",
      " 13  FIP_1           2622 non-null   float64       \n",
      " 14  GSc_1           2622 non-null   float64       \n",
      " 15  2B_1            2622 non-null   float64       \n",
      " 16  Outs_1          2622 non-null   float64       \n",
      " 17  points_1        2622 non-null   float64       \n",
      " 18  QS_1            2622 non-null   float64       \n",
      " 19  bucket_1        2622 non-null   object        \n",
      " 20  Dec_4           2622 non-null   float64       \n",
      " 21  DR_4            2622 non-null   float64       \n",
      " 22  H_4             2622 non-null   float64       \n",
      " 23  ER_4            2622 non-null   float64       \n",
      " 24  BB_4            2622 non-null   float64       \n",
      " 25  SO_4            2622 non-null   float64       \n",
      " 26  HR_4            2622 non-null   float64       \n",
      " 27  HBP_4           2622 non-null   float64       \n",
      " 28  FIP_4           2622 non-null   float64       \n",
      " 29  GSc_4           2622 non-null   float64       \n",
      " 30  2B_4            2622 non-null   float64       \n",
      " 31  Outs_4          2622 non-null   float64       \n",
      " 32  points_4        2622 non-null   float64       \n",
      " 33  QS_4            2622 non-null   float64       \n",
      " 34  bucket_4        2622 non-null   object        \n",
      " 35  Dec_all         2622 non-null   float64       \n",
      " 36  DR_all          2622 non-null   float64       \n",
      " 37  H_all_pitcher   2622 non-null   float64       \n",
      " 38  ER_all          2622 non-null   float64       \n",
      " 39  BB_all_pitcher  2622 non-null   float64       \n",
      " 40  SO_all_pitcher  2622 non-null   float64       \n",
      " 41  HR_all_pitcher  2622 non-null   float64       \n",
      " 42  HBP_all         2622 non-null   float64       \n",
      " 43  FIP_all         2622 non-null   float64       \n",
      " 44  GSc_all         2622 non-null   float64       \n",
      " 45  2B_all          2622 non-null   float64       \n",
      " 46  Outs_all        2622 non-null   float64       \n",
      " 47  points_all      2622 non-null   float64       \n",
      " 48  QS_all          2622 non-null   float64       \n",
      " 49  bucket_all      2622 non-null   object        \n",
      " 50  Team            2622 non-null   object        \n",
      " 51  PA_30           2622 non-null   float64       \n",
      " 52  R_30            2622 non-null   float64       \n",
      " 53  H_30            2622 non-null   float64       \n",
      " 54  HR_30           2622 non-null   float64       \n",
      " 55  BB_30           2622 non-null   float64       \n",
      " 56  SO_30           2622 non-null   float64       \n",
      " 57  OBP_30          2622 non-null   float64       \n",
      " 58  SLG_30          2622 non-null   float64       \n",
      " 59  LOB_30          2622 non-null   float64       \n",
      " 60  PA_all          2622 non-null   float64       \n",
      " 61  R_all           2622 non-null   float64       \n",
      " 62  H_all_opp       2622 non-null   float64       \n",
      " 63  HR_all_opp      2622 non-null   float64       \n",
      " 64  BB_all_opp      2622 non-null   float64       \n",
      " 65  SO_all_opp      2622 non-null   float64       \n",
      " 66  OBP_all         2622 non-null   float64       \n",
      " 67  SLG_all         2622 non-null   float64       \n",
      " 68  LOB_all         2622 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(60), object(8)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# Read in opponent performance\n",
    "opp_perf_df = opp_prev_perf\n",
    "\n",
    "# Extract column names\n",
    "cols = list(opp_perf_df.columns)\n",
    "\n",
    "# Move date and team to front of list\n",
    "cols.remove('Date')\n",
    "cols.insert(0,'Date')\n",
    "cols.remove('Team')\n",
    "cols.insert(0,'Team')\n",
    "opp_perf_df = opp_perf_df[cols]\n",
    "\n",
    "# Read in pitcher performance\n",
    "pitcher_perf_df = pitcher_perf\n",
    "\n",
    "# Perform merge\n",
    "df = pitcher_perf_df.merge(opp_perf_df,\n",
    "                           left_on = ['Date', 'Opp'], right_on = ['Date', 'Team'],\n",
    "                           suffixes = ('_pitcher', '_opp')\n",
    "                          )\n",
    "# Drop weird rows\n",
    "df = df.dropna()\n",
    "\n",
    "# Move 'bucket' column to front\n",
    "cols = list(df.columns)\n",
    "cols.remove('bucket')\n",
    "cols.insert(0,'bucket')\n",
    "\n",
    "# Drop 'points' column\n",
    "cols.remove('points')\n",
    "\n",
    "# Rearrange columns\n",
    "df = df[cols]\n",
    "\n",
    "training_df = df\n",
    "\n",
    "# Export to csv\n",
    "training_df.to_csv('training_data.csv', index=False)\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed083b9a",
   "metadata": {},
   "source": [
    "## This is where we build the prediction input dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e50270f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 429: Too Many Requests",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Request setup\u001b[39;00m\n\u001b[1;32m      2\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.baseball-reference.com/previews/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43murllib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m response:\n\u001b[1;32m      5\u001b[0m     html \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m      7\u001b[0m soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(html, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/urllib/request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[0;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/urllib/request.py:525\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_response\u001b[38;5;241m.\u001b[39mget(protocol, []):\n\u001b[1;32m    524\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[0;32m--> 525\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/urllib/request.py:634\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[0;32m--> 634\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/urllib/request.py:563\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[1;32m    562\u001b[0m     args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp_error_default\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m orig_args\n\u001b[0;32m--> 563\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/urllib/request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[1;32m    495\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    498\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/urllib/request.py:643\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[0;32m--> 643\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req\u001b[38;5;241m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 429: Too Many Requests"
     ]
    }
   ],
   "source": [
    "# Request setup\n",
    "url = \"https://www.baseball-reference.com/previews/\"\n",
    "\n",
    "with urllib.request.urlopen(url) as response:\n",
    "    html = response.read()\n",
    "\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# Get the list of probables\n",
    "probables = []\n",
    "probables = pd.DataFrame()\n",
    "\n",
    "# We're going to loop through this list of matchups\n",
    "matchups = soup.find_all('div', class_='game_summary nohover')\n",
    "\n",
    "# For each matchup in the full list of matchups\n",
    "for matchup in matchups:\n",
    "\n",
    "    # Get the first pitcher's name\n",
    "    p1_name = matchup.find_all('a')[3].text\n",
    "\n",
    "    # Get the first pitcher's code\n",
    "    try: p1_code = matchup.find_all('a')[3].get('href').split(\"/\")[5].split(\".\")[0]\n",
    "    except: p1_code = np.nan\n",
    "\n",
    "    # Get the first pitcher's team\n",
    "    team1 = matchup.find_all('strong')[0].text\n",
    "\n",
    "    # Get the second pitcher's name\n",
    "    try: p2_name = matchup.find_all('a')[4].text\n",
    "    except: p2_name = np.nan\n",
    "\n",
    "    # Get the second pitcher's code\n",
    "    try: p2_code = matchup.find_all('a')[4].get('href').split(\"/\")[5].split(\".\")[0]\n",
    "    except: p2_code = np.nan\n",
    "\n",
    "    # Get the second pitcher's team\n",
    "    # Had to add a function that handles if there is a debut in the matchup,\n",
    "    # Which would otherwise change the list of 'strong' divs in the matchup\n",
    "    debut_adj = math.ceil(len(matchup.find_all('strong'))/2)\n",
    "    try: team2 = matchup.find_all('strong')[debut_adj].text\n",
    "    except: team2 = np.nan\n",
    "\n",
    "    # Create a dictionary for the first pitcher and their matchup\n",
    "    pitcher1 = {\n",
    "        'date':date.today(),\n",
    "        'name':p1_name,\n",
    "        'code':p1_code,\n",
    "        'for':team1,\n",
    "        'against':team2\n",
    "    }\n",
    "\n",
    "    # Create a dictionary for the second pitcher and their matchup\n",
    "    pitcher2 = {\n",
    "        'date':date.today(),\n",
    "        'name':p2_name,\n",
    "        'code':p2_code,\n",
    "        'for':team2,\n",
    "        'against':team1\n",
    "    }\n",
    "\n",
    "    # Put both pitchers into a list of probable matchups, separately\n",
    "    probables = probables.append(pitcher1, ignore_index=True)\n",
    "    probables = probables.append(pitcher2, ignore_index=True)\n",
    "\n",
    "# Export to csv\n",
    "probables.to_csv('probables.csv',index = False)\n",
    "\n",
    "# NOTE: NaN usually means the pitcher hasn't been posted on b-ref yet\n",
    "\n",
    "probables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728c5d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in opponent performance\n",
    "probables_df = probables\n",
    "\n",
    "# This is is the data for just the starting pitchers, to be used for predictions\n",
    "all_starters = probables_df['code']\n",
    "pitcher_data = pitcher_perf[pitcher_perf['code'].isin(list(all_starters))]\n",
    "\n",
    "# This is is the data for just the starting pitchers, to be used for predictions\n",
    "all_opps = probables_df['against']\n",
    "all_opps = opp_prev_perf[opp_prev_perf['Team'].isin(list(all_opps))]\n",
    "\n",
    "# Perform merge\n",
    "df = pitcher_data.merge(all_opps,\n",
    "                           left_on = ['Date', 'Opp'], right_on = ['Date', 'Team'],\n",
    "                           suffixes = ('_pitcher', '_opp')\n",
    "                          )\n",
    "\n",
    "df_cols = list(df.columns)\n",
    "df_cols.remove('code')\n",
    "df_cols.insert(0,'code')\n",
    "\n",
    "df_cols.remove('pitcher')\n",
    "df_cols.insert(0,'pitcher')\n",
    "\n",
    "df_cols.remove('Opp')\n",
    "df_cols.insert(0,'Opp')\n",
    "\n",
    "df_cols.remove('Date')\n",
    "df_cols.insert(0,'Date')\n",
    "\n",
    "df_cols.remove('points')\n",
    "df_cols.insert(0,'points')\n",
    "\n",
    "df_cols.remove('bucket')\n",
    "df_cols.insert(0,'bucket')\n",
    "\n",
    "df = df[df_cols]\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ca75fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize df\n",
    "prediction_input = pd.DataFrame()\n",
    "\n",
    "# Extract list of starters from probables df\n",
    "starters = df['code'].unique()\n",
    "\n",
    "# Loop through all starters\n",
    "for starter in starters:\n",
    "    # Get most recent row of data\n",
    "    most_recent = df.loc[df['code'] == starter].sort_values('Date').tail(1)\n",
    "\n",
    "    # Put into df to use as prediciton inputs\n",
    "    prediction_input = prediction_input.append(most_recent)\n",
    "\n",
    "# Drop target columns\n",
    "prediction_input = prediction_input.drop(columns=['bucket', 'points'])\n",
    "\n",
    "prediction_input.to_csv('STARTERS_input_data.csv', index=False)\n",
    "\n",
    "prediction_input.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cf4253",
   "metadata": {},
   "source": [
    "# This is where we actually run the actual model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4446ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDICTION INPUT DATA PREP\n",
    "\n",
    "# Read in input data\n",
    "input_df = prediction_input\n",
    "\n",
    "# Take out columns that we'll need in order to read our predictions\n",
    "id_info = input_df[['pitcher','code']]\n",
    "\n",
    "# Drop columns that will not be included in training\n",
    "input_df = input_df.drop(columns = ['Date','pitcher','code'])\n",
    "\n",
    "# Dropping this column separately just b/c I maybe want to come back to considering NOT dropping it\n",
    "# Yeah, the opponent performance is still here, but sometimes it's just the TEAM itself that seems\n",
    "# to make a difference for some teams/pitchers (i.e., Devers vs. NYY)\n",
    "input_df = input_df.drop(columns = 'Opp')\n",
    "\n",
    "# Separate target as y and features as X\n",
    "Xp = input_df\n",
    "\n",
    "# Get list of non-numerical columns\n",
    "Xp_cat = Xp.dtypes[Xp.dtypes == 'object'].index.tolist()\n",
    "\n",
    "# Get dummies for those columns\n",
    "one_hot = pd.get_dummies(Xp[Xp_cat])\n",
    "\n",
    "# Drop the original non-numerical columns\n",
    "Xp = Xp.drop(columns = Xp_cat)\n",
    "\n",
    "# Put in ALL the possible buckets\n",
    "bucket1 = [f'bucket_1_{label}' for label in bucket_labels]\n",
    "bucketN = [f'bucket_{N}_{label}' for label in bucket_labels]\n",
    "bucketall = [f'bucket_all_{label}' for label in bucket_labels]\n",
    "\n",
    "buckets = bucket1 + bucketN + bucketall\n",
    "\n",
    "Xp[buckets] = 0\n",
    "\n",
    "# update the bucket columns with the numerical dummies for those non-numerical columns\n",
    "Xp.update(one_hot)\n",
    "\n",
    "# This is officially the data we're going to put into our predictor\n",
    "Xp.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afe92d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TESTING DATA PREP\n",
    "\n",
    "# Drop columns that will not be included in training\n",
    "training_df = training_df.drop(columns = ['Date','pitcher','code'])\n",
    "\n",
    "# Dropping this column separately just b/c I maybe want to come back to considering NOT dropping it\n",
    "# Yeah, the opponent performance is still here, but sometimes it's just the TEAM itself that seems\n",
    "# to make a difference for some teams/pitchers (i.e., Devers vs. NYY)\n",
    "training_df = training_df.drop(columns = 'Opp')\n",
    "\n",
    "\n",
    "# Separate target as y and features as X\n",
    "y = training_df['bucket']\n",
    "X = training_df.drop(columns = 'bucket')\n",
    "\n",
    "# Get list of non-numerical columns\n",
    "X_cat = X.dtypes[X.dtypes == 'object'].index.tolist()\n",
    "\n",
    "# Get dummies for those columns\n",
    "one_hot = pd.get_dummies(X[X_cat])\n",
    "\n",
    "# Drop the original non-numerical columns\n",
    "X = X.drop(columns = X_cat)\n",
    "\n",
    "# Put in ALL the possible buckets\n",
    "bucket1 = [f'bucket_1_{label}' for label in bucket_labels]\n",
    "bucketN = [f'bucket_{N}_{label}' for label in bucket_labels]\n",
    "bucketall = [f'bucket_all_{label}' for label in bucket_labels]\n",
    "\n",
    "buckets = bucket1 + bucketN + bucketall\n",
    "\n",
    "X[buckets] = 0\n",
    "\n",
    "# update the bucket columns with the numerical dummies for those non-numerical columns\n",
    "X.update(one_hot)\n",
    "\n",
    "# This is officially the data we're going to put into our predictor\n",
    "X.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebba6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is us converting one vector of 6 distinct classes into basically get-dummies\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "outcomes = bucket_labels\n",
    "\n",
    "y_factors = to_categorical(pd.Categorical(y,categories = outcomes).codes,len(bucket_labels))\n",
    "\n",
    "\n",
    "# Split training/test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_factors, random_state=42)\n",
    "\n",
    "## Preprocess numerical data for neural network\n",
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516c51b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the deep learning model \n",
    "nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "p=0\n",
    "nn_model.add(tf.keras.layers.Dense(units=round(0.6*len(list(X.columns))),\n",
    "                                   activation=\"relu\", input_dim = X_train.shape[1]))\n",
    "nn_model.add(tf.keras.layers.Dense(units=round(0.75*0.6*len(list(X.columns))+0.25*len(bucket_labels)),\n",
    "                                   activation=\"tanh\"))\n",
    "nn_model.add(tf.keras.layers.Dense(units=round(0.50*0.6*len(list(X.columns))+0.50*len(bucket_labels)),\n",
    "                                   activation=\"relu\"))\n",
    "nn_model.add(tf.keras.layers.Dense(units=round(0.25*0.6*len(list(X.columns))+0.75*len(bucket_labels)),\n",
    "                                   activation=\"tanh\"))\n",
    "nn_model.add(tf.keras.layers.Dense(units=len(bucket_labels),\n",
    "                                   activation=\"softmax\"))\n",
    "\n",
    "\n",
    "# Compile the Sequential model together and customize metrics\n",
    "nn_model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "fit_model = nn_model.fit(X_train_scaled, y_train, epochs=50)\n",
    "\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42a9497",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_perf = nn_model.predict(Xp)\n",
    "predicted_perf = pd.DataFrame(predicted_perf)\n",
    "predicted_perf.columns = outcomes\n",
    "predicted_perf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1fed08",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_perf = predicted_perf.round(1)\n",
    "\n",
    "predicted_perf\n",
    "\n",
    "id_info = id_info.reset_index(drop=True)\n",
    "\n",
    "output = id_info.join(predicted_perf)\n",
    "output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6831d8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- %s minutes ---\" % round((time.time() - start_time)/60,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f64b0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea1b3a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
