{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4313aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import requests\n",
    "import urllib.request\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "from datetime import date, datetime, timedelta\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "start_time = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44260d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How much do you want to scale back this run? Pick a number between 0 (none) and 1 (all)\n",
    "\n",
    "t = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33955873",
   "metadata": {},
   "source": [
    "## This is where we build training dataset\n",
    "This can be skipped if we don't want to make the 30 minute time investment of re-training the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77cba4c",
   "metadata": {},
   "source": [
    "This is the section where I pull the list of probable pitchers from b-ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0112bcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### WE MIGHT BE ABLE TO SKIP THIS CELL\n",
    "# # Request setup\n",
    "# url = \"https://www.baseball-reference.com/previews/\"\n",
    "\n",
    "# with urllib.request.urlopen(url) as response:\n",
    "#     html = response.read()\n",
    "\n",
    "# soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# # Get the list of probables\n",
    "# probables = []\n",
    "# probables = pd.DataFrame()\n",
    "\n",
    "# # We're going to loop through this list of matchups\n",
    "# matchups = soup.find_all('div', class_='game_summary nohover')\n",
    "\n",
    "# # For each matchup in the full list of matchups\n",
    "# for matchup in matchups:\n",
    "\n",
    "#     # Get the first pitcher's name\n",
    "#     p1_name = matchup.find_all('a')[3].text\n",
    "\n",
    "#     # Get the first pitcher's code\n",
    "#     try: p1_code = matchup.find_all('a')[3].get('href').split(\"/\")[5].split(\".\")[0]\n",
    "#     except: p1_code = np.nan\n",
    "\n",
    "#     # Get the first pitcher's team\n",
    "#     team1 = matchup.find_all('strong')[0].text\n",
    "\n",
    "#     # Get the second pitcher's name\n",
    "#     try: p2_name = matchup.find_all('a')[4].text\n",
    "#     except: p2_name = np.nan\n",
    "\n",
    "#     # Get the second pitcher's code\n",
    "#     try: p2_code = matchup.find_all('a')[4].get('href').split(\"/\")[5].split(\".\")[0]\n",
    "#     except: p2_code = np.nan\n",
    "\n",
    "#     # Get the second pitcher's team\n",
    "#     # Had to add a function that handles if there is a debut in the matchup,\n",
    "#     # Which would otherwise change the list of 'strong' divs in the matchup\n",
    "#     debut_adj = math.ceil(len(matchup.find_all('strong'))/2)\n",
    "#     try: team2 = matchup.find_all('strong')[debut_adj].text\n",
    "#     except: team2 = np.nan\n",
    "\n",
    "#     # Create a dictionary for the first pitcher and their matchup\n",
    "#     pitcher1 = {\n",
    "#         'date':date.today(),\n",
    "#         'name':p1_name,\n",
    "#         'code':p1_code,\n",
    "#         'for':team1,\n",
    "#         'against':team2\n",
    "#     }\n",
    "\n",
    "#     # Create a dictionary for the second pitcher and their matchup\n",
    "#     pitcher2 = {\n",
    "#         'date':date.today(),\n",
    "#         'name':p2_name,\n",
    "#         'code':p2_code,\n",
    "#         'for':team2,\n",
    "#         'against':team1\n",
    "#     }\n",
    "\n",
    "#     # Put both pitchers into a list of probable matchups, separately\n",
    "#     probables = probables.append(pitcher1, ignore_index=True)\n",
    "#     probables = probables.append(pitcher2, ignore_index=True)\n",
    "\n",
    "# # Export to csv\n",
    "# probables.to_csv('probables.csv',index = False)\n",
    "\n",
    "# probables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8538fd29",
   "metadata": {},
   "source": [
    "### This is the section where I scrape individual starting pitchers' individual game performance\n",
    "\n",
    "#### Things it'd be cool to add here:\n",
    "Add a counter that shows the total number of pitchers logged, compared to the total number fed in, so I can see how much loss there was when we triggered the except/pass code\\\n",
    "\\\n",
    "Add in a we could try to scrape away some time by ignoring pitchchers who haven't pitched since the last time we logged? Probably won't save that much time, depending on how much time it has been.\\\n",
    "\\\n",
    "How valuable is the information we are getting from the guys who are towards the end of the list? The list of pitchers is sorted by number of starts, so cutting the bottom 20% of the list will take away 20% of the run time, but only ~10% of the data. But maybe it's important to have representation for those pitchers with only a few starts?\\\n",
    "\\\n",
    "Some way for me to more easily pick which variables I want to choose. Like maybe have a dictionary with stats as the keys, and booleans as the values, so I can just go through, try out different combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7a2cbe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done adding Miles Mikolas 0/357\n",
      "Done adding Chris Bassitt 1/357\n",
      "Done adding Dylan Cease 2/357\n",
      "Done adding Gerrit Cole 3/357\n",
      "Done adding Zac Gallen 4/357\n",
      "Done adding Logan Webb 5/357\n",
      "Done adding Sandy Alcantara 6/357\n",
      "Done adding José Berríos 7/357\n",
      "Done adding Corbin Burnes 8/357\n",
      "Done adding Luis Castillo 9/357\n",
      "Done adding Patrick Corbin 10/357\n",
      "Done adding Kyle Gibson 11/357\n",
      "Done adding Lucas Giolito 12/357\n",
      "Done adding Sonny Gray 13/357\n",
      "Done adding Mitch Keller 14/357\n",
      "Done adding Dean Kremer 15/357\n",
      "Done adding Pablo López 16/357\n",
      "Done adding Jesús Luzardo 17/357\n",
      "Done adding Aaron Nola 18/357\n",
      "Done adding Johan Oviedo 19/357\n",
      "Done adding Blake Snell 20/357\n",
      "Done adding Zach Eflin 21/357\n",
      "Done adding Bryce Elder 22/357\n",
      "Done adding Kyle Freeland 23/357\n",
      "Done adding Kevin Gausman 24/357\n",
      "Done adding Logan Gilbert 25/357\n",
      "Done adding Austin Gomber 26/357\n",
      "Done adding Josiah Gray 27/357\n",
      "Done adding Andrew Heaney 28/357\n",
      "Done adding Rich Hill 29/357\n",
      "Done adding Yusei Kikuchi 30/357\n",
      "Done adding Lance Lynn 31/357\n",
      "Done adding Jordan Montgomery 32/357\n",
      "Done adding Charlie Morton 33/357\n",
      "Done adding Clarke Schmidt 34/357\n",
      "Done adding JP Sears 35/357\n",
      "Done adding Brady Singer 36/357\n",
      "Done adding Spencer Strider 37/357\n",
      "Done adding Framber Valdez 38/357\n",
      "Done adding Taijuan Walker 39/357\n",
      "Done adding Zack Wheeler 40/357\n",
      "Done adding Trevor Williams 41/357\n",
      "Done adding Graham Ashcraft 42/357\n",
      "Done adding Alex Cobb 43/357\n",
      "Done adding Braxton Garrett 44/357\n",
      "Done adding MacKenzie Gore 45/357\n",
      "Done adding Cristian Javier 46/357\n",
      "Done adding George Kirby 47/357\n",
      "Done adding Michael Kopech 48/357\n",
      "Done adding Jordan Lyles 49/357\n",
      "Done adding Freddy Peralta 50/357\n",
      "Done adding Justin Steele 51/357\n",
      "Done adding Kyle Bradish 52/357\n",
      "Done adding Hunter Brown 53/357\n",
      "Done adding Reid Detmers 54/357\n",
      "Done adding Jack Flaherty 55/357\n",
      "Done adding Jon Gray 56/357\n",
      "Done adding Merrill Kelly 57/357\n",
      "Done adding Max Scherzer 58/357\n",
      "Done adding Kodai Senga 59/357\n",
      "Done adding Jameson Taillon 60/357\n",
      "Done adding Brayan Bello 61/357\n",
      "Done adding Yu Darvish 62/357\n",
      "Done adding Michael Lorenzen 63/357\n",
      "Done adding Ryne Nelson 64/357\n",
      "Done adding Joe Ryan 65/357\n",
      "Done adding Patrick Sandoval 66/357\n",
      "Done adding Tyler Anderson 67/357\n",
      "Done adding Tanner Bibee 68/357\n",
      "Done adding Zack Greinke 69/357\n",
      "Done adding Shohei Ohtani 70/357\n",
      "Done adding Marcus Stroman 71/357\n",
      "Done adding Seth Lugo 72/357\n",
      "Done adding Bailey Ober 73/357\n",
      "Done adding Drew Smyly 74/357\n",
      "Done adding Justin Verlander 75/357\n",
      "Done adding Luke Weaver 76/357\n",
      "Done adding Logan Allen 77/357\n",
      "Done adding Dane Dunning 78/357\n",
      "Done adding Jake Irvin 79/357\n",
      "Done adding Clayton Kershaw 80/357\n",
      "Done adding Shane McClanahan 81/357\n",
      "Done adding Tylor Megill 82/357\n",
      "Done adding Bryce Miller 83/357\n",
      "Done adding Eduardo Rodriguez 84/357\n",
      "Done adding Julio Urías 85/357\n",
      "Done adding Carlos Carrasco 86/357\n",
      "Done adding Nathan Eovaldi 87/357\n",
      "Done adding J.P. France 88/357\n",
      "Done adding Tony Gonsolin 89/357\n",
      "Done adding Kyle Hendricks 90/357\n",
      "Done adding Martín Pérez 91/357\n",
      "Done adding Colin Rea 92/357\n",
      "Done adding Ken Waldichuk 93/357\n",
      "Done adding Tyler Wells 94/357\n",
      "Done adding Shane Bieber 95/357\n",
      "Done adding Aaron Civale 96/357\n",
      "Done adding Mike Clevinger 97/357\n",
      "Done adding Kutter Crawford 98/357\n",
      "Done adding Domingo Germán 99/357\n",
      "Done adding Alek Manoah 100/357\n",
      "Done adding Wade Miley 101/357\n",
      "Done adding James Paxton 102/357\n",
      "Done adding Grayson Rodriguez 103/357\n",
      "Done adding Michael Wacha 104/357\n",
      "Done adding Brandon Williamson 105/357\n",
      "Done adding Griffin Canning 106/357\n",
      "Done adding Anthony DeSclafani 107/357\n",
      "Done adding Ranger Suárez 108/357\n",
      "Done adding Noah Syndergaard 109/357\n",
      "Done adding Adam Wainwright 110/357\n",
      "Done adding Andrew Abbott 111/357\n",
      "Done adding Taj Bradley 112/357\n",
      "Done adding Edward Cabrera 113/357\n",
      "Done adding Hunter Greene 114/357\n",
      "Done adding Adrian Houser 115/357\n",
      "Done adding Kenta Maeda 116/357\n",
      "Done adding Steven Matz 117/357\n",
      "Done adding Bobby Miller 118/357\n",
      "Done adding Joe Musgrove 119/357\n",
      "Done adding David Peterson 120/357\n",
      "Done adding Luis Severino 121/357\n",
      "Done adding Joey Wentz 122/357\n",
      "Done adding Paul Blackburn 123/357\n",
      "Done adding Tyler Glasnow 124/357\n",
      "Done adding Tommy Henry 125/357\n",
      "Done adding Tanner Houck 126/357\n",
      "Done adding Eury Pérez 127/357\n",
      "Done adding Chris Sale 128/357\n",
      "Done adding Matthew Boyd 129/357\n",
      "Done adding Brandon Pfaadt 130/357\n",
      "Done adding Zach Davies 131/357\n",
      "Done adding Matt Manning 132/357\n",
      "Done adding Luis Medina 133/357\n",
      "Done adding Reese Olson 134/357\n",
      "Done adding Cal Quantrill 135/357\n",
      "Done adding Cristopher Sánchez 136/357\n",
      "Done adding Bryan Woo 137/357\n",
      "Done adding Chase Anderson 138/357\n",
      "Done adding Brandon Bielak 139/357\n",
      "Done adding Jhony Brito 140/357\n",
      "Done adding Kyle Muller 141/357\n",
      "Done adding Connor Seabold 142/357\n",
      "Done adding Gavin Williams 143/357\n",
      "Done adding Nestor Cortes 144/357\n",
      "Done adding Alex Faedo 145/357\n",
      "Done adding Michael Grove 146/357\n",
      "Done adding Cole Irvin 147/357\n",
      "Done adding Ben Lively 148/357\n",
      "Done adding Luis Ortiz 149/357\n",
      "Done adding Ryan Walker 150/357\n",
      "Done adding Roansy Contreras 151/357\n",
      "Done adding Bailey Falter 152/357\n",
      "Done adding Chris Flexen 153/357\n",
      "Done adding Max Fried 154/357\n",
      "Done adding James Kaprielian 155/357\n",
      "Done adding Matthew Liberatore 156/357\n",
      "Done adding Nick Pivetta 157/357\n",
      "Done adding Tarik Skubal 158/357\n",
      "Done adding Ross Stripling 159/357\n",
      "Done adding Julio Teheran 160/357\n",
      "Done adding Touki Toussaint 161/357\n",
      "Done adding Ryan Weathers 162/357\n",
      "Done adding Hayden Wesneski 163/357\n",
      "Done adding Alex Wood 164/357\n",
      "Done adding Marco Gonzales 165/357\n",
      "Done adding Peter Lambert 166/357\n",
      "Done adding Zack Littell 167/357\n",
      "Done adding Jared Shuster 168/357\n",
      "Done adding Louie Varland 169/357\n",
      "Done adding Garrett Whitlock 170/357\n",
      "Done adding Yonny Chirinos 171/357\n",
      "Done adding Xzavion Curry 172/357\n",
      "Done adding José Urquidy 173/357\n",
      "Done adding Brad Keller 174/357\n",
      "Done adding Corey Kluber 175/357\n",
      "Done adding Daniel Lynch IV 176/357\n",
      "Done adding Dustin May 177/357\n",
      "Done adding José Quintana 178/357\n",
      "Done adding Carlos Rodón 179/357\n",
      "Done adding Jesse Scholtens 180/357\n",
      "Done adding Matt Strahm 181/357\n",
      "Done adding Jalen Beeks 182/357\n",
      "Done adding Osvaldo Bido 183/357\n",
      "Done adding Ty Blach 184/357\n",
      "Done adding John Brebbia 185/357\n",
      "Done adding Ryan Feltner 186/357\n",
      "Done adding Eric Lauer 187/357\n",
      "Done adding Alec Marsh 188/357\n",
      "Done adding Cole Ragans 189/357\n",
      "Done adding Drew Rasmussen 190/357\n",
      "Done adding Emmet Sheehan 191/357\n",
      "Done adding Vince Velasquez 192/357\n",
      "Done adding Brandon Woodruff 193/357\n",
      "Done adding Scott Alexander 194/357\n",
      "Done adding Javier Assad 195/357\n",
      "Done adding Ronel Blanco 196/357\n",
      "Done adding Johnny Cueto 197/357\n",
      "Done adding Shintaro Fujinami 198/357\n",
      "Done adding Dakota Hudson 199/357\n",
      "Done adding Nick Lodolo 200/357\n",
      "Done adding Chase Silseth 201/357\n",
      "Done adding Spencer Turnbull 202/357\n",
      "Done adding Ryan Yarbrough 203/357\n",
      "Done adding Jaime Barria 204/357\n",
      "Done adding Peyton Battenfield 205/357\n",
      "Done adding Brennan Bernardino 206/357\n",
      "Done adding Cody Bradford 207/357\n",
      "Done adding Luis Cessa 208/357\n",
      "Done adding Jacob deGrom 209/357\n",
      "Done adding Hunter Gaddis 210/357\n",
      "Done adding Luis Garcia 211/357\n",
      "Done adding Hogan Harris 212/357\n",
      "Done adding Bryan Hoeing 213/357\n",
      "Done adding Joey Lucchesi 214/357\n",
      "Done adding Sean Manaea 215/357\n",
      "Done adding Nick Martinez 216/357\n",
      "Done adding Quinn Priester 217/357\n",
      "Done adding Austin Pruitt 218/357\n",
      "Done adding Hyun Jin Ryu 219/357\n",
      "Done adding Michael Soroka 220/357\n",
      "Done adding José Suarez 221/357\n",
      "Done adding Jake Woodford 222/357\n",
      "Done adding Joan Adon 223/357\n",
      "Done adding Shawn Armstrong 224/357\n",
      "Done adding Dylan Dodd 225/357\n",
      "Done adding Chad Kuhl 226/357\n",
      "Done adding Tyler Mahle 227/357\n",
      "Done adding Zach Plesac 228/357\n",
      "Done adding Zack Thompson 229/357\n",
      "Done adding José Ureña 230/357\n",
      "Done adding Kyle Wright 231/357\n",
      "Done adding Pedro Avila 232/357\n",
      "Done adding Madison Bumgarner 233/357\n",
      "Done adding Slade Cecconi 234/357\n",
      "Done adding Noah Davis 235/357\n",
      "Done adding Calvin Faucher 236/357\n",
      "Done adding Caleb Ferguson 237/357\n",
      "Done adding Carlos Hernández 238/357\n",
      "Done adding Andre Jackson 239/357\n",
      "Done adding Jakob Junis 240/357\n",
      "Done adding Dallas Keuchel 241/357\n",
      "Done adding Michael King 242/357\n",
      "Done adding Dinelson Lamet 243/357\n",
      "Done adding Germán Márquez 244/357\n",
      "Done adding Mason Miller 245/357\n",
      "Done adding Trevor Rogers 246/357\n",
      "Done adding Drew Rucinski 247/357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done adding AJ Smith-Shawver 248/357\n",
      "Done adding Randy Vásquez 249/357\n",
      "Done adding Kolby Allard 250/357\n",
      "Done adding Tanner Banks 251/357\n",
      "Done adding Jake Bird 252/357\n",
      "Done adding Kris Bubic 253/357\n",
      "Done adding Austin Cox 254/357\n",
      "Done adding Josh Fleming 255/357\n",
      "Done adding Ian Hamilton 256/357\n",
      "Done adding Emerson Hancock 257/357\n",
      "Done adding Kyle Harrison 258/357\n",
      "Done adding Drey Jameson 259/357\n",
      "Done adding Karl Kauffmann 260/357\n",
      "Done adding Trevor Kelley 261/357\n",
      "Done adding Connor Overton 262/357\n",
      "Done adding Denyi Reyes 263/357\n",
      "Done adding Lyon Richardson 264/357\n",
      "Done adding Trevor Richards 265/357\n",
      "Done adding Drew Rom 266/357\n",
      "Done adding Jeffrey Springs 267/357\n",
      "Done adding Gavin Stone 268/357\n",
      "Done adding Will Vest 269/357\n",
      "Done adding Allan Winans 270/357\n",
      "Done adding Ángel Zerpa 271/357\n",
      "Done adding Tristan Beck 272/357\n",
      "Done adding Ryan Borucki 273/357\n",
      "Done adding José Butto 274/357\n",
      "Done adding Taylor Clarke 275/357\n",
      "Done adding José Cuas 276/357\n",
      "Done adding Javy Guerra 277/357\n",
      "Done adding Thomas Hatch 278/357\n",
      "Done adding Brett Kennedy 279/357\n",
      "Done adding Derek Law 280/357\n",
      "Done adding Joe Mantiply 281/357\n",
      "Done adding Mike Mayers 282/357\n",
      "Done adding Triston McKenzie 283/357\n",
      "Done adding Tommy Milone 284/357\n",
      "Done adding Zach Neal 285/357\n",
      "Done adding Kaleb Ort 286/357\n",
      "Done adding Erasmo Ramírez 287/357\n",
      "Done adding John Schreiber 288/357\n",
      "Done adding Tayler Scott 289/357\n",
      "Done adding Colin Selby 290/357\n",
      "Done adding Antonio Senzatela 291/357\n",
      "Done adding Levi Stoudt 292/357\n",
      "Done adding Matt Waldron 293/357\n",
      "Done adding Brendan White 294/357\n",
      "Done adding Jordan Wicks 295/357\n",
      "Done adding Keaton Winn 296/357\n",
      "Done adding Keegan Akin 297/357\n",
      "Done adding Tyler Alexander 298/357\n",
      "Done adding Tejay Antone 299/357\n",
      "Done adding Matt Barnes 300/357\n",
      "Done adding Beau Brieske 301/357\n",
      "Done adding Connor Brogdon 302/357\n",
      "Done adding JT Chargois 303/357\n",
      "Done adding Jesse Chavez 304/357\n",
      "Done adding Dylan Coleman 305/357\n",
      "Done adding Jimmy Cordero 306/357\n",
      "Done adding Dylan Covey 307/357\n",
      "Done adding Fernando Cruz 308/357\n",
      "Done adding Tucker Davidson 309/357\n",
      "Done adding José De León 310/357\n",
      "Done adding Matt Dermody 311/357\n",
      "Done adding Shawn Dubin 312/357\n",
      "Done adding Mason Englert 313/357\n",
      "Done adding Michael Fulmer 314/357\n",
      "Done adding Justin Garza 315/357\n",
      "Done adding Victor González 316/357\n",
      "Done adding Brusdar Graterol 317/357\n",
      "Done adding Tyler Holton 318/357\n",
      "Done adding Dany Jiménez 320/357\n",
      "Done adding Janson Junk 321/357\n",
      "Done adding Caleb Kilian 322/357\n",
      "Done adding Reiss Knehr 323/357\n",
      "Done adding Jimmy Lambert 324/357\n",
      "Done adding Dylan Lee 325/357\n",
      "Done adding Sam Long 326/357\n",
      "Done adding Adrián Martínez 327/357\n",
      "Done adding James McArthur 328/357\n",
      "Done adding Easton McGee 329/357\n",
      "Done adding Scott McGough 330/357\n",
      "Done adding Collin McHugh 331/357\n",
      "Done adding Carmen Mlodzinski 332/357\n",
      "Done adding Sam Moll 333/357\n",
      "Done adding Adrián Morejón 334/357\n",
      "Done adding Kyle Nelson 335/357\n",
      "Done adding Steven Okert 336/357\n",
      "Done adding Adam Oller 337/357\n",
      "Done adding Ryan Pepiot 338/357\n",
      "Done adding Francisco Pérez 339/357\n",
      "Done adding Connor Phillips 340/357\n",
      "Done adding Robbie Ray 341/357\n",
      "Done adding Yerry Rodríguez 342/357\n",
      "Done adding Kenny Rosenberg 343/357\n",
      "Done adding José Ruiz 344/357\n",
      "Done adding Devin Smeltzer 345/357\n",
      "Done adding George Soriano 346/357\n",
      "Done adding Carson Spiers 347/357\n",
      "Done adding Josh Staumont 348/357\n",
      "Done adding Freddy Tarnok 349/357\n",
      "Done adding Josh Taylor 350/357\n",
      "Done adding Alex Vesia 351/357\n",
      "Done adding Darius Vines 352/357\n",
      "Done adding Spenser Watkins 353/357\n",
      "Done adding Josh Winckowski 354/357\n",
      "Done adding Jackson Wolf 355/357\n",
      "Done adding Rob Zastryzny 356/357\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Opp</th>\n",
       "      <th>Dec</th>\n",
       "      <th>DR</th>\n",
       "      <th>H</th>\n",
       "      <th>ER</th>\n",
       "      <th>BB</th>\n",
       "      <th>SO</th>\n",
       "      <th>HR</th>\n",
       "      <th>HBP</th>\n",
       "      <th>FIP</th>\n",
       "      <th>Outs</th>\n",
       "      <th>points</th>\n",
       "      <th>QS</th>\n",
       "      <th>pitcher</th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-04-05</td>\n",
       "      <td>ATL</td>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.72</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Miles Mikolas</td>\n",
       "      <td>mikolmi01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-04-11</td>\n",
       "      <td>COL</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5.63</td>\n",
       "      <td>15</td>\n",
       "      <td>-6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Miles Mikolas</td>\n",
       "      <td>mikolmi01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-04-16</td>\n",
       "      <td>PIT</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.86</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Miles Mikolas</td>\n",
       "      <td>mikolmi01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-04-22</td>\n",
       "      <td>SEA</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5.47</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Miles Mikolas</td>\n",
       "      <td>mikolmi01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-04-27</td>\n",
       "      <td>SFG</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.93</td>\n",
       "      <td>19</td>\n",
       "      <td>21</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Miles Mikolas</td>\n",
       "      <td>mikolmi01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7122</th>\n",
       "      <td>2023-06-09</td>\n",
       "      <td>NYM</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.37</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Rob Zastryzny</td>\n",
       "      <td>zastrro01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7123</th>\n",
       "      <td>2023-06-13</td>\n",
       "      <td>CHC</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.01</td>\n",
       "      <td>5</td>\n",
       "      <td>-3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Rob Zastryzny</td>\n",
       "      <td>zastrro01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7124</th>\n",
       "      <td>2023-06-15</td>\n",
       "      <td>CHC</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.79</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Rob Zastryzny</td>\n",
       "      <td>zastrro01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7125</th>\n",
       "      <td>2023-08-26</td>\n",
       "      <td>CHC</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.52</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Rob Zastryzny</td>\n",
       "      <td>zastrro01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7126</th>\n",
       "      <td>2023-09-03</td>\n",
       "      <td>STL</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.32</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Rob Zastryzny</td>\n",
       "      <td>zastrro01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7127 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date  Opp  Dec  DR   H  ER  BB  SO  HR  HBP   FIP  Outs  points  \\\n",
       "0    2023-04-05  ATL   -1   5   9   5   1   6   1    0  2.72    18       1   \n",
       "1    2023-04-11  COL    0   5  10   6   2   3   3    0  5.63    15      -6   \n",
       "2    2023-04-16  PIT    0   4   7   2   2   4   0    0  4.86    17       8   \n",
       "3    2023-04-22  SEA    0   5   5   3   2   4   2    0  5.47    16       7   \n",
       "4    2023-04-27  SFG    1   4   4   0   2   6   0    1  4.93    19      21   \n",
       "...         ...  ...  ...  ..  ..  ..  ..  ..  ..  ...   ...   ...     ...   \n",
       "7122 2023-06-09  NYM    0   1   2   0   0   2   0    0  4.37     5       5   \n",
       "7123 2023-06-13  CHC    0   3   3   3   1   2   1    0  5.01     5      -3   \n",
       "7124 2023-06-15  CHC    0   1   1   0   0   1   0    0  4.79     3       3   \n",
       "7125 2023-08-26  CHC    0   1   0   0   0   0   0    0  4.52     3       3   \n",
       "7126 2023-09-03  STL    0   7   2   0   0   1   0    0  4.32     5       4   \n",
       "\n",
       "       QS        pitcher       code  \n",
       "0     0.0  Miles Mikolas  mikolmi01  \n",
       "1     0.0  Miles Mikolas  mikolmi01  \n",
       "2     0.0  Miles Mikolas  mikolmi01  \n",
       "3     0.0  Miles Mikolas  mikolmi01  \n",
       "4     1.0  Miles Mikolas  mikolmi01  \n",
       "...   ...            ...        ...  \n",
       "7122  0.0  Rob Zastryzny  zastrro01  \n",
       "7123  0.0  Rob Zastryzny  zastrro01  \n",
       "7124  0.0  Rob Zastryzny  zastrro01  \n",
       "7125  0.0  Rob Zastryzny  zastrro01  \n",
       "7126  0.0  Rob Zastryzny  zastrro01  \n",
       "\n",
       "[7127 rows x 16 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is a dataset drawn manually from b-ref.\n",
    "# There is probably a slick way to scrape this\n",
    "# but this only has to be updated every once in a while, not all the time\n",
    "# So manually works for now.\n",
    "all_starters = pd.read_csv('all_starters.csv')\n",
    "\n",
    "# Initialize df\n",
    "pitcher_data = pd.DataFrame()\n",
    "\n",
    "# For every starter we have\n",
    "for i in range(round(t*len(all_starters))):\n",
    "    try:\n",
    "        code = all_starters.loc[i,'code']\n",
    "        name = all_starters.loc[i,'name']\n",
    "\n",
    "        # Request setup\n",
    "        url = f'https://www.baseball-reference.com/players/gl.fcgi?id={code}&t=p&year=2023'\n",
    "        df = pd.read_html(url)\n",
    "        df = pd.DataFrame(df[0])\n",
    "\n",
    "        # # DATA CLEANING # #\n",
    "\n",
    "        # Drop weird rows\n",
    "        df = df[pd.to_numeric(df['Rk'], errors = 'coerce').notnull()]\n",
    "\n",
    "        # Reset index after dropping some rows\n",
    "        df = df.reset_index()\n",
    "\n",
    "        # Identify desired columns to keep and drop others\n",
    "        keep_cols = ['Date','Opp','Dec', 'DR',\n",
    "                     'IP', 'H', 'ER', 'BB', 'SO', 'HR', 'HBP',\n",
    "                     'FIP']\n",
    "\n",
    "        df = df[keep_cols]\n",
    "\n",
    "        # Now let's make the date column usable\n",
    "        # Clean away situations where there's a double-header impacting the date\n",
    "        df['Date'] = df['Date'].str.split(\"(\", expand = True).loc[:,0]\n",
    "\n",
    "        # Extract day from date\n",
    "        days = df['Date'].str.split(n=1,expand = True).loc[:,1]\n",
    "\n",
    "        # Extract month from date\n",
    "        months = df['Date'].str.split(n=1,expand = True).loc[:,0]\n",
    "\n",
    "        # Convert month to numerical month\n",
    "        months = months.str.replace('Oct','10')\n",
    "        months = months.str.replace('Sep','9')\n",
    "        months = months.str.replace('Aug','8')\n",
    "        months = months.str.replace('Jul','7')\n",
    "        months = months.str.replace('Jun','6')\n",
    "        months = months.str.replace('May','5')\n",
    "        months = months.str.replace('Apr','4')\n",
    "        months = months.str.replace('Mar','3')\n",
    "\n",
    "        # Create year series\n",
    "        df['years'] = '2023'\n",
    "\n",
    "        # Build date string\n",
    "        df['Date'] = df['years'] + \"-\" + months + \"-\" + days\n",
    "\n",
    "        # Drop year series\n",
    "        df = df.drop(columns = ['years'])\n",
    "\n",
    "        # Clean Decision series\n",
    "        df['Dec'] = df['Dec'].str[0]\n",
    "\n",
    "        df['Dec'] = df['Dec'].fillna('0')\n",
    "\n",
    "        df['Dec'] = df['Dec'].str.replace('W','1')\n",
    "        df['Dec'] = df['Dec'].str.replace('L','-1')\n",
    "        df['Dec'] = df['Dec'].str.replace('B','-1')\n",
    "        df['Dec'] = df['Dec'].str.replace('S','2')\n",
    "        df['Dec'] = df['Dec'].str.replace('H','0')\n",
    "\n",
    "        # Make everything a string before the step below. Don't worry, we'll fix this later on.\n",
    "        # This is because some of our data processing functions require string inputs,\n",
    "        # and our data scraper might accidentally infer some things as numbers.\n",
    "        # We have to do this\n",
    "        df = df.applymap(str)\n",
    "\n",
    "        # Make outs series, convert IP to Outs, then drop IP series\n",
    "        whole = df['IP'].str.split(\".\", expand = True)[0].astype('int')\n",
    "        part = df['IP'].str.split(\".\", expand = True)[1].astype('int')\n",
    "\n",
    "        df['Outs'] = 3*whole + part\n",
    "\n",
    "        df = df.drop(columns = ['IP'])\n",
    "\n",
    "        # Sometimes my DR column gets interpreted as a float, that gets turned into a string,\n",
    "        # that can't be turned directly into an int. But it can be interpreted as a float, from a string,\n",
    "        # so we do that first, and then we can convert it to an int without issue.\n",
    "        df['DR'] = df['DR'].astype('float')\n",
    "\n",
    "        # Cast numerical datatypes as numbers\n",
    "        df = df.astype({\n",
    "            'Dec':'int',\n",
    "            'DR':'int',\n",
    "            'H':'int',\n",
    "            'ER':'int',\n",
    "            'BB':'int',\n",
    "            'SO':'int',\n",
    "            'HR':'int',\n",
    "            'HBP':'int',\n",
    "            'FIP':'float',\n",
    "            'Outs':'int',\n",
    "        })\n",
    "\n",
    "        # Convert date string to date type\n",
    "        df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "        # Calculate fantasy points\n",
    "        df['points'] = 3*df['Dec'] - df['H'] - 2*df['ER'] - df['BB'] + df['SO'] - df['HBP'] + df['Outs']\n",
    "\n",
    "        # Create quality start series QS\n",
    "        for row in range(1,len(df)):\n",
    "            if df.loc[row,'ER']<=3 and df.loc[row,'Outs']>=18: df.loc[row,'QS'] = 1\n",
    "            else: df.loc[row,'QS'] = 0\n",
    "\n",
    "        # Add in pitcher name and code\n",
    "        df['pitcher'] = name\n",
    "        df['code'] = code\n",
    "\n",
    "        # Drop starts following 30+ days rest\n",
    "        df = df[df['DR'] <30]\n",
    "\n",
    "        # Add it to the overall pitcher data df\n",
    "        pitcher_data = pitcher_data.append(df, ignore_index=True)\n",
    "\n",
    "        # Let me know we're done with that player\n",
    "        print(f'Done adding {name} {i}/{len(all_starters)}')\n",
    "\n",
    "        # Wait for 3.2 seconds, b/c baseball-reference has a 20 request/min limit\n",
    "        time.sleep(3.2)\n",
    "    except: pass\n",
    "\n",
    "# Export to csv\n",
    "pitcher_data.to_csv('pitcher_data.csv',index = False)\n",
    "\n",
    "print(\"Done\")\n",
    "\n",
    "pitcher_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc44ef6",
   "metadata": {},
   "source": [
    "### This is the notebook where I take pitcher starting performance, and create a df of \"previous\" performance before each start, for each pitcher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21eaa243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7127 entries, 0 to 7126\n",
      "Data columns (total 15 columns):\n",
      " #   Column    Non-Null Count  Dtype         \n",
      "---  ------    --------------  -----         \n",
      " 0   Dec_1     6778 non-null   float64       \n",
      " 1   DR_1      6778 non-null   float64       \n",
      " 2   H_1       6778 non-null   float64       \n",
      " 3   ER_1      6778 non-null   float64       \n",
      " 4   BB_1      6778 non-null   float64       \n",
      " 5   SO_1      6778 non-null   float64       \n",
      " 6   HR_1      6778 non-null   float64       \n",
      " 7   HBP_1     6778 non-null   float64       \n",
      " 8   FIP_1     6778 non-null   float64       \n",
      " 9   Outs_1    6778 non-null   float64       \n",
      " 10  points_1  6778 non-null   float64       \n",
      " 11  QS_1      6778 non-null   float64       \n",
      " 12  Date      7127 non-null   datetime64[ns]\n",
      " 13  code      7127 non-null   object        \n",
      " 14  bucket_1  6778 non-null   object        \n",
      "dtypes: datetime64[ns](1), float64(12), object(2)\n",
      "memory usage: 835.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pitcher_data\n",
    "\n",
    "# This is me getting a df of how the given pitcher performed\n",
    "# in the outing immediately before the given date\n",
    "df_last = pd.DataFrame()\n",
    "\n",
    "for i in range(len(df)):\n",
    "    # For a given row i, extract the code and date for that row\n",
    "    date = df.loc[i,:].Date\n",
    "    code = df.loc[i,:].code\n",
    "\n",
    "    # Given a code/date, extract the previous game data\n",
    "    df_last1 = df.loc[(df.Date < date) & (df.code == code)].sort_values('Date').tail(1)\n",
    "    \n",
    "    df_last1 = df_last1.drop(columns = ['Date', 'Opp','pitcher','code'])\n",
    "\n",
    "    # Get the average of those 1 rows, find the averages of averageable, transpose it from series to row\n",
    "    df_last1_avg = pd.DataFrame(df_last1.mean(axis=0)).transpose()\n",
    "\n",
    "    # Rename cols to indicate\n",
    "    df_last1_avg.columns = [f\"{col}_1\" for col in df_last1_avg.columns]\n",
    "\n",
    "    # Assign it to the date and code we're working with\n",
    "    df_last1_avg['Date'] = date\n",
    "    df_last1_avg['code'] = code\n",
    "\n",
    "    # Append into the last few games df\n",
    "    df_last = df_last.append(df_last1_avg)\n",
    "\n",
    "# Rest the index so that we can .loc through it\n",
    "df_last = df_last.reset_index(drop=True)\n",
    "\n",
    "# Put in the performance buckets\n",
    "for row in range(1,len(df_last)):\n",
    "    if df_last.loc[row,'points_1']<=-10: df_last.loc[row,'bucket_1'] = '.<=-10'\n",
    "    elif df_last.loc[row,'points_1']<=0: df_last.loc[row,'bucket_1'] = '-10<.<=0'\n",
    "    elif df_last.loc[row,'points_1']<=10: df_last.loc[row,'bucket_1'] = '0<.<=10'\n",
    "    elif df_last.loc[row,'points_1']<=20: df_last.loc[row,'bucket_1'] = '10<.<=20'\n",
    "    elif df_last.loc[row,'points_1']<=30: df_last.loc[row,'bucket_1'] = '20<.<=30'\n",
    "    elif df_last.loc[row,'points_1']>30: df_last.loc[row,'bucket_1'] = '30<.'\n",
    "    else: df_last.loc[row,'bucket_1'] = np.nan\n",
    "\n",
    "df_last.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cc5a2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7127 entries, 0 to 7126\n",
      "Data columns (total 15 columns):\n",
      " #   Column    Non-Null Count  Dtype         \n",
      "---  ------    --------------  -----         \n",
      " 0   Dec_5     6778 non-null   float64       \n",
      " 1   DR_5      6778 non-null   float64       \n",
      " 2   H_5       6778 non-null   float64       \n",
      " 3   ER_5      6778 non-null   float64       \n",
      " 4   BB_5      6778 non-null   float64       \n",
      " 5   SO_5      6778 non-null   float64       \n",
      " 6   HR_5      6778 non-null   float64       \n",
      " 7   HBP_5     6778 non-null   float64       \n",
      " 8   FIP_5     6778 non-null   float64       \n",
      " 9   Outs_5    6778 non-null   float64       \n",
      " 10  points_5  6778 non-null   float64       \n",
      " 11  QS_5      6778 non-null   float64       \n",
      " 12  Date      7127 non-null   datetime64[ns]\n",
      " 13  code      7127 non-null   object        \n",
      " 14  bucket_5  6778 non-null   object        \n",
      "dtypes: datetime64[ns](1), float64(12), object(2)\n",
      "memory usage: 835.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# Variable to determine the length of our rolling average\n",
    "N=5\n",
    "\n",
    "df_lastfew = pd.DataFrame()\n",
    "\n",
    "for i in range(len(df)):\n",
    "    # For a given row i, extract the code and date for that row\n",
    "    date = df.loc[i,:].Date\n",
    "    code = df.loc[i,:].code\n",
    "\n",
    "    # Given a code/date, extract the previous N games of data\n",
    "    df_lastN = df.loc[(df.Date < date) & (df.code == code)].sort_values('Date').tail(N)\n",
    "    \n",
    "    df_lastN = df_lastN.drop(columns = ['Date', 'Opp','pitcher','code'])\n",
    "\n",
    "    # Get the average of those N rows, find the averages of averageable series, transpose it from series to row\n",
    "    df_lastN_avg = pd.DataFrame(df_lastN.mean(axis=0)).transpose()\n",
    "\n",
    "    # Rename cols to indicate what it's the average of, and over how many games\n",
    "    df_lastN_avg.columns = [f\"{col}_{N}\" for col in df_lastN_avg.columns]\n",
    "\n",
    "    # Assign it to the date and code we're working with\n",
    "    df_lastN_avg['Date'] = date\n",
    "    df_lastN_avg['code'] = code\n",
    "\n",
    "    # Append into the last few games df\n",
    "    df_lastfew = df_lastfew.append(df_lastN_avg)\n",
    "\n",
    "# Rest the index so that we can .loc through it\n",
    "df_lastfew = df_lastfew.reset_index(drop=True)\n",
    "\n",
    "# Put in the performance buckets\n",
    "for row in range(1,len(df_lastfew)):\n",
    "    if df_lastfew.loc[row,f'points_{N}']<=-10: df_lastfew.loc[row,f'bucket_{N}'] = '.<=-10'\n",
    "    elif df_lastfew.loc[row,f'points_{N}']<=0: df_lastfew.loc[row,f'bucket_{N}'] = '-10<.<=0'\n",
    "    elif df_lastfew.loc[row,f'points_{N}']<=10: df_lastfew.loc[row,f'bucket_{N}'] = '0<.<=10'\n",
    "    elif df_lastfew.loc[row,f'points_{N}']<=20: df_lastfew.loc[row,f'bucket_{N}'] = '10<.<=20'\n",
    "    elif df_lastfew.loc[row,f'points_{N}']<=30: df_lastfew.loc[row,f'bucket_{N}'] = '20<.<=30'\n",
    "    elif df_lastfew.loc[row,f'points_{N}']>30: df_lastfew.loc[row,f'bucket_{N}'] = '30<.'\n",
    "    else: df_lastfew.loc[row,f'bucket_{N}'] = np.nan\n",
    "\n",
    "df_lastfew.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c270fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7127 entries, 0 to 7126\n",
      "Data columns (total 15 columns):\n",
      " #   Column      Non-Null Count  Dtype         \n",
      "---  ------      --------------  -----         \n",
      " 0   Dec_all     6778 non-null   float64       \n",
      " 1   DR_all      6778 non-null   float64       \n",
      " 2   H_all       6778 non-null   float64       \n",
      " 3   ER_all      6778 non-null   float64       \n",
      " 4   BB_all      6778 non-null   float64       \n",
      " 5   SO_all      6778 non-null   float64       \n",
      " 6   HR_all      6778 non-null   float64       \n",
      " 7   HBP_all     6778 non-null   float64       \n",
      " 8   FIP_all     6778 non-null   float64       \n",
      " 9   Outs_all    6778 non-null   float64       \n",
      " 10  points_all  6778 non-null   float64       \n",
      " 11  QS_all      6778 non-null   float64       \n",
      " 12  Date        7127 non-null   datetime64[ns]\n",
      " 13  code        7127 non-null   object        \n",
      " 14  bucket_all  6778 non-null   object        \n",
      "dtypes: datetime64[ns](1), float64(12), object(2)\n",
      "memory usage: 835.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df_cummulative = pd.DataFrame()\n",
    "\n",
    "for i in range(len(df)):\n",
    "    # For a given row i, extract the code and date for that row\n",
    "    date = df.loc[i,:].Date\n",
    "    code = df.loc[i,:].code\n",
    "\n",
    "    # Given a code/date, extract the previous game data\n",
    "    df_cummu = df.loc[(df.Date < date) & (df.code == code)].sort_values('Date')\n",
    "    \n",
    "    df_cummu = df_cummu.drop(columns = ['Date', 'Opp','pitcher','code'])\n",
    "\n",
    "    # Get the average of all rows, find the averages of averageable, transpose it from series to row\n",
    "    df_cummu_avg = pd.DataFrame(df_cummu.mean(axis=0)).transpose()\n",
    "\n",
    "    # Rename cols to indicate\n",
    "    df_cummu_avg.columns = [f\"{col}_all\" for col in df_cummu_avg.columns]\n",
    "\n",
    "    # Assign it to the date and code we're working with\n",
    "    df_cummu_avg['Date'] = date\n",
    "    df_cummu_avg['code'] = code\n",
    "\n",
    "    # Append into the last few games df\n",
    "    df_cummulative = df_cummulative.append(df_cummu_avg)\n",
    "\n",
    "# Rest the index so that we can .loc through it\n",
    "df_cummulative = df_cummulative.reset_index(drop=True)\n",
    "\n",
    "# Put in the performance buckets\n",
    "for row in range(1,len(df_cummulative)):\n",
    "    if df_cummulative.loc[row,'points_all']<=-10: df_cummulative.loc[row,'bucket_all'] = '.<=-10'\n",
    "    elif df_cummulative.loc[row,'points_all']<=0: df_cummulative.loc[row,'bucket_all'] = '-10<.<=0'\n",
    "    elif df_cummulative.loc[row,'points_all']<=10: df_cummulative.loc[row,'bucket_all'] = '0<.<=10'\n",
    "    elif df_cummulative.loc[row,'points_all']<=20: df_cummulative.loc[row,'bucket_all'] = '10<.<=20'\n",
    "    elif df_cummulative.loc[row,'points_all']<=30: df_cummulative.loc[row,'bucket_all'] = '20<.<=30'\n",
    "    elif df_cummulative.loc[row,'points_all']>30: df_cummulative.loc[row,'bucket_all'] = '30<.'\n",
    "    else: df_cummulative.loc[row,'bucket_all'] = np.nan\n",
    "\n",
    "df_cummulative.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2d22c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6792 entries, 1 to 7140\n",
      "Data columns (total 44 columns):\n",
      " #   Column      Non-Null Count  Dtype         \n",
      "---  ------      --------------  -----         \n",
      " 0   Date        6792 non-null   datetime64[ns]\n",
      " 1   Opp         6792 non-null   object        \n",
      " 2   points      6792 non-null   int64         \n",
      " 3   pitcher     6792 non-null   object        \n",
      " 4   code        6792 non-null   object        \n",
      " 5   Dec_1       6792 non-null   float64       \n",
      " 6   DR_1        6792 non-null   float64       \n",
      " 7   H_1         6792 non-null   float64       \n",
      " 8   ER_1        6792 non-null   float64       \n",
      " 9   BB_1        6792 non-null   float64       \n",
      " 10  SO_1        6792 non-null   float64       \n",
      " 11  HR_1        6792 non-null   float64       \n",
      " 12  HBP_1       6792 non-null   float64       \n",
      " 13  FIP_1       6792 non-null   float64       \n",
      " 14  Outs_1      6792 non-null   float64       \n",
      " 15  points_1    6792 non-null   float64       \n",
      " 16  QS_1        6792 non-null   float64       \n",
      " 17  bucket_1    6792 non-null   object        \n",
      " 18  Dec_5       6792 non-null   float64       \n",
      " 19  DR_5        6792 non-null   float64       \n",
      " 20  H_5         6792 non-null   float64       \n",
      " 21  ER_5        6792 non-null   float64       \n",
      " 22  BB_5        6792 non-null   float64       \n",
      " 23  SO_5        6792 non-null   float64       \n",
      " 24  HR_5        6792 non-null   float64       \n",
      " 25  HBP_5       6792 non-null   float64       \n",
      " 26  FIP_5       6792 non-null   float64       \n",
      " 27  Outs_5      6792 non-null   float64       \n",
      " 28  points_5    6792 non-null   float64       \n",
      " 29  QS_5        6792 non-null   float64       \n",
      " 30  bucket_5    6792 non-null   object        \n",
      " 31  Dec_all     6792 non-null   float64       \n",
      " 32  DR_all      6792 non-null   float64       \n",
      " 33  H_all       6792 non-null   float64       \n",
      " 34  ER_all      6792 non-null   float64       \n",
      " 35  BB_all      6792 non-null   float64       \n",
      " 36  SO_all      6792 non-null   float64       \n",
      " 37  HR_all      6792 non-null   float64       \n",
      " 38  HBP_all     6792 non-null   float64       \n",
      " 39  FIP_all     6792 non-null   float64       \n",
      " 40  Outs_all    6792 non-null   float64       \n",
      " 41  points_all  6792 non-null   float64       \n",
      " 42  QS_all      6792 non-null   float64       \n",
      " 43  bucket_all  6792 non-null   object        \n",
      "dtypes: datetime64[ns](1), float64(36), int64(1), object(6)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# Merge in all those different windows of data\n",
    "\n",
    "# Merge in last 1 game of data\n",
    "compiled_df = pd.merge(df,df_last,\n",
    "                       on = ['Date','code'])\n",
    "\n",
    "# Merge in last N games of data\n",
    "compiled_df = pd.merge(compiled_df,df_lastfew,\n",
    "                       on = ['Date','code'])\n",
    "\n",
    "# Merge in all season games of data\n",
    "compiled_df = pd.merge(compiled_df,df_cummulative,\n",
    "                       on = ['Date','code'])\n",
    "\n",
    "# Drop the data from that day, so we're only training on data that is known at the time before the given date\n",
    "pitcher_perf = compiled_df.drop(columns = [\n",
    "    'Dec', 'DR', 'H', 'ER', 'BB', 'SO',\n",
    "    'HR', 'HBP', 'FIP', 'Outs', 'QS'])\n",
    "\n",
    "# Drop NaN rows\n",
    "# These rows result from asking for performance on the last 1, N games when there have been fewer than 1, N games\n",
    "pitcher_perf = pitcher_perf.dropna()\n",
    "\n",
    "pitcher_perf.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "718b37d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6792 entries, 0 to 6791\n",
      "Data columns (total 45 columns):\n",
      " #   Column      Non-Null Count  Dtype         \n",
      "---  ------      --------------  -----         \n",
      " 0   Date        6792 non-null   datetime64[ns]\n",
      " 1   Opp         6792 non-null   object        \n",
      " 2   points      6792 non-null   int64         \n",
      " 3   pitcher     6792 non-null   object        \n",
      " 4   code        6792 non-null   object        \n",
      " 5   Dec_1       6792 non-null   float64       \n",
      " 6   DR_1        6792 non-null   float64       \n",
      " 7   H_1         6792 non-null   float64       \n",
      " 8   ER_1        6792 non-null   float64       \n",
      " 9   BB_1        6792 non-null   float64       \n",
      " 10  SO_1        6792 non-null   float64       \n",
      " 11  HR_1        6792 non-null   float64       \n",
      " 12  HBP_1       6792 non-null   float64       \n",
      " 13  FIP_1       6792 non-null   float64       \n",
      " 14  Outs_1      6792 non-null   float64       \n",
      " 15  points_1    6792 non-null   float64       \n",
      " 16  QS_1        6792 non-null   float64       \n",
      " 17  bucket_1    6792 non-null   object        \n",
      " 18  Dec_5       6792 non-null   float64       \n",
      " 19  DR_5        6792 non-null   float64       \n",
      " 20  H_5         6792 non-null   float64       \n",
      " 21  ER_5        6792 non-null   float64       \n",
      " 22  BB_5        6792 non-null   float64       \n",
      " 23  SO_5        6792 non-null   float64       \n",
      " 24  HR_5        6792 non-null   float64       \n",
      " 25  HBP_5       6792 non-null   float64       \n",
      " 26  FIP_5       6792 non-null   float64       \n",
      " 27  Outs_5      6792 non-null   float64       \n",
      " 28  points_5    6792 non-null   float64       \n",
      " 29  QS_5        6792 non-null   float64       \n",
      " 30  bucket_5    6792 non-null   object        \n",
      " 31  Dec_all     6792 non-null   float64       \n",
      " 32  DR_all      6792 non-null   float64       \n",
      " 33  H_all       6792 non-null   float64       \n",
      " 34  ER_all      6792 non-null   float64       \n",
      " 35  BB_all      6792 non-null   float64       \n",
      " 36  SO_all      6792 non-null   float64       \n",
      " 37  HR_all      6792 non-null   float64       \n",
      " 38  HBP_all     6792 non-null   float64       \n",
      " 39  FIP_all     6792 non-null   float64       \n",
      " 40  Outs_all    6792 non-null   float64       \n",
      " 41  points_all  6792 non-null   float64       \n",
      " 42  QS_all      6792 non-null   float64       \n",
      " 43  bucket_all  6792 non-null   object        \n",
      " 44  bucket      6791 non-null   object        \n",
      "dtypes: datetime64[ns](1), float64(36), int64(1), object(7)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# Rest the index so that we can .loc through it\n",
    "pitcher_perf = pitcher_perf.reset_index(drop=True)\n",
    "\n",
    "## Put in buckets for actual performance to make the target\n",
    "# Put in the performance buckets\n",
    "for row in range(1,len(pitcher_perf)):\n",
    "    if pitcher_perf.loc[row,'points']<=-10: pitcher_perf.loc[row,'bucket'] = '.<=-10'\n",
    "    elif pitcher_perf.loc[row,'points']<=0: pitcher_perf.loc[row,'bucket'] = '-10<.<=0'\n",
    "    elif pitcher_perf.loc[row,'points']<=10: pitcher_perf.loc[row,'bucket'] = '0<.<=10'\n",
    "    elif pitcher_perf.loc[row,'points']<=20: pitcher_perf.loc[row,'bucket'] = '10<.<=20'\n",
    "    elif pitcher_perf.loc[row,'points_1']<=30: pitcher_perf.loc[row,'bucket'] = '20<.<=30'\n",
    "    elif pitcher_perf.loc[row,'points_1']>30: pitcher_perf.loc[row,'bucket'] = '30<.'\n",
    "    else: pitcher_perf.loc[row,'bucket'] = np.nan\n",
    "\n",
    "# Export to csv\n",
    "pitcher_perf.to_csv('pitcher_previous_perf.csv',index = False)\n",
    "\n",
    "pitcher_perf.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da689a7e",
   "metadata": {},
   "source": [
    "### This is the section where for each team, before a given game, I calculate their previous performance\n",
    "\n",
    "Things it'd be cool to add here:\\\n",
    "In the progress printout, maybe include the number of records in each team?\\\n",
    "\\\n",
    "Some way for me to more easily pick which variables I want to choose. Like maybe have a dictionary with stats as the keys, and booleans as the values, so I can just go through, try out different combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8a0e1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: ARI\n",
      "Done: ATL\n",
      "Done: BAL\n",
      "Done: BOS\n",
      "Done: CHC\n",
      "Done: CHW\n",
      "Done: CIN\n",
      "Done: CLE\n",
      "Done: COL\n",
      "Done: DET\n",
      "Done: HOU\n",
      "Done: KCR\n",
      "Done: LAA\n",
      "Done: LAD\n",
      "Done: MIA\n",
      "Done: MIL\n",
      "Done: MIN\n",
      "Done: NYM\n",
      "Done: NYY\n",
      "Done: OAK\n",
      "Done: PHI\n",
      "Done: PIT\n",
      "Done: SDP\n",
      "Done: SEA\n",
      "Done: SFG\n",
      "Done: STL\n",
      "Done: TBR\n",
      "Done: TEX\n",
      "Done: TOR\n",
      "Done: WSN\n",
      "Done\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4466 entries, 1 to 4495\n",
      "Data columns (total 24 columns):\n",
      " #   Column   Non-Null Count  Dtype         \n",
      "---  ------   --------------  -----         \n",
      " 0   PA_30    4466 non-null   float64       \n",
      " 1   AB_30    4466 non-null   float64       \n",
      " 2   R_30     4466 non-null   float64       \n",
      " 3   H_30     4466 non-null   float64       \n",
      " 4   RBI_30   4466 non-null   float64       \n",
      " 5   BB_30    4466 non-null   float64       \n",
      " 6   SO_30    4466 non-null   float64       \n",
      " 7   BA_30    4466 non-null   float64       \n",
      " 8   OBP_30   4466 non-null   float64       \n",
      " 9   SLG_30   4466 non-null   float64       \n",
      " 10  OPS_30   4466 non-null   float64       \n",
      " 11  Date     4466 non-null   datetime64[ns]\n",
      " 12  Team     4466 non-null   object        \n",
      " 13  PA_all   4466 non-null   float64       \n",
      " 14  AB_all   4466 non-null   float64       \n",
      " 15  R_all    4466 non-null   float64       \n",
      " 16  H_all    4466 non-null   float64       \n",
      " 17  RBI_all  4466 non-null   float64       \n",
      " 18  BB_all   4466 non-null   float64       \n",
      " 19  SO_all   4466 non-null   float64       \n",
      " 20  BA_all   4466 non-null   float64       \n",
      " 21  OBP_all  4466 non-null   float64       \n",
      " 22  SLG_all  4466 non-null   float64       \n",
      " 23  OPS_all  4466 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(22), object(1)\n",
      "memory usage: 872.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# Get team codes\n",
    "team_codes = pd.read_csv('team_codes.csv')\n",
    "codes = team_codes['code'].tolist()\n",
    "\n",
    "## Make last 30 days df\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# For every team in our list of team codes\n",
    "for i in range(round(t*len(codes))):\n",
    "\n",
    "    # Loop through teams\n",
    "    team = codes[i]\n",
    "\n",
    "    # Request setup\n",
    "    url = f'https://www.baseball-reference.com/teams/tgl.cgi?team={team}&t=b&year=2023'\n",
    "\n",
    "    team_df = pd.read_html(url)\n",
    "    team_df = pd.DataFrame((team_df[0]))\n",
    "\n",
    "    # Add team identifier\n",
    "    team_df['Team'] = team\n",
    "\n",
    "    # Append into overall team dataframe\n",
    "    df = df.append(team_df)\n",
    "\n",
    "    # Print status\n",
    "    print(f'Done: {team}')\n",
    "    \n",
    "    # Wait for >3 seconds b/c site limits requests to 20/min\n",
    "    time.sleep(3.2)\n",
    "\n",
    "## Now we clean the data!\n",
    "\n",
    "# Identify key columns\n",
    "keep_cols = ['Team', 'Date','PA', 'AB', 'R', 'H', 'RBI', 'BB', 'SO', 'BA', 'OBP', 'SLG', 'OPS']\n",
    "\n",
    "# Select for those key columns\n",
    "df = df[keep_cols]\n",
    "\n",
    "# Drop rows that contain mid-table row headers\n",
    "df = df[pd.to_numeric(df['PA'], errors='coerce').notnull()]\n",
    "\n",
    "# Now let's make the date column usable\n",
    "# Clean away situations where there's a double-header impacting the date\n",
    "df['Date'] = df['Date'].str.split(\"(\", expand = True).loc[:,0]\n",
    "\n",
    "# Extract day from date\n",
    "days = df['Date'].str.split(n=1,expand = True).loc[:,1]\n",
    "\n",
    "# Extract month from date\n",
    "months = df['Date'].str.split(n=1,expand = True).loc[:,0]\n",
    "\n",
    "# Convert month to numerical month\n",
    "months = months.str.replace('Oct','10')\n",
    "months = months.str.replace('Sep','9')\n",
    "months = months.str.replace('Aug','8')\n",
    "months = months.str.replace('Jul','7')\n",
    "months = months.str.replace('Jun','6')\n",
    "months = months.str.replace('May','5')\n",
    "months = months.str.replace('Apr','4')\n",
    "months = months.str.replace('Mar','3')\n",
    "\n",
    "# Create year series\n",
    "df['years'] = '2023'\n",
    "\n",
    "# Build date string\n",
    "df['Date'] = df['years'] + \"-\" + months + \"-\" + days\n",
    "\n",
    "# Drop year series\n",
    "df = df.drop(columns = ['years'])\n",
    "\n",
    "# Cast series as numeric/datetime\n",
    "df = df.apply(pd.to_numeric, errors = 'ignore')\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "df = df.reset_index(drop = True)\n",
    "\n",
    "##\n",
    "# Variable to determine the length of our rolling average\n",
    "N=30\n",
    "\n",
    "# Now let's make a df showing the average performance over the last N days\n",
    "\n",
    "# Initialize our df\n",
    "df_LN = pd.DataFrame()\n",
    "\n",
    "for i in range(len(df)):\n",
    "\n",
    "    # For a given row i, extract the code and date for that row\n",
    "    date = df.loc[i,:].Date\n",
    "    team = df.loc[i,:].Team\n",
    "\n",
    "    # Given a code/date, extract the previous game data\n",
    "    # WHAT AM I GOING TO DO IF THERE IS NO PREVIOUS GAME DATA?!??!!\n",
    "    df_lastN = df.loc[(df['Date'] < date) & (df['Team'] == team)].sort_values('Date').tail(N)\n",
    "\n",
    "    # Get the average of those N rows, find the averages of averageable, transpose it from series to row\n",
    "    df_lastN_avg = pd.DataFrame(df_lastN.mean(axis=0)).transpose()\n",
    "\n",
    "    # Rename cols to indicate\n",
    "    df_lastN_avg.columns = [f\"{col}_{N}\" for col in df_lastN_avg.columns]\n",
    "\n",
    "    # Assign it to the date and code we're working with\n",
    "    df_lastN_avg['Date'] = date\n",
    "    df_lastN_avg['code'] = team\n",
    "\n",
    "    # Append into the last few games df\n",
    "    df_LN = df_LN.append(df_lastN_avg)\n",
    "\n",
    "# Drop errant team name column\n",
    "df_LN = df_LN.drop(columns = [f'Team_{N}'])\n",
    "\n",
    "# Relabel code column as true team name column\n",
    "df_LN = df_LN.rename(columns={\"code\": \"Team\"})\n",
    "\n",
    "df_LN = df_LN.reset_index(drop=True)\n",
    "\n",
    "##\n",
    "\n",
    "# Now let's make the season running total df\n",
    "df_Lall = pd.DataFrame()\n",
    "\n",
    "for i in range(len(df)):\n",
    "\n",
    "    # For a given row i, extract the code and date for that row\n",
    "    date = df.loc[i,:].Date\n",
    "    team = df.loc[i,:].Team\n",
    "\n",
    "    # Given a code/date, extract the previous game data\n",
    "    df_lastall = df.loc[(df['Date'] < date) & (df['Team'] == team)]\n",
    "\n",
    "    # Get the average of those 5 rows, find the averages of averageable, transpose it from series to row\n",
    "    df_lastall_avg = pd.DataFrame(df_lastall.mean(axis=0)).transpose()\n",
    "\n",
    "    # Rename cols to indicate\n",
    "    df_lastall_avg.columns = [f\"{col}_all\" for col in df_lastall_avg.columns]\n",
    "\n",
    "    # Assign it to the date and code we're working with\n",
    "    df_lastall_avg['Date'] = date\n",
    "    df_lastall_avg['code'] = team\n",
    "\n",
    "    # Append into the last few games df\n",
    "    df_Lall = df_Lall.append(df_lastall_avg)\n",
    "\n",
    "# Drop errant team name column\n",
    "df_Lall = df_Lall.drop(columns = ['Team_all'])\n",
    "\n",
    "# Relabel code column as true team name column\n",
    "df_Lall = df_Lall.rename(columns={\"code\": \"Team\"})\n",
    "\n",
    "df_Lall = df_Lall.reset_index(drop=True)\n",
    "\n",
    "##\n",
    "\n",
    "# Now let's combine these to dataframes to make an overall 'previous performance'\n",
    "opp_prev_perf = df_LN.merge(df_Lall, on = ['Team', 'Date'])\n",
    "\n",
    "# Drop rows that are NaN bc there weren't any previous days of performance to pull (i.e., first day in window)\n",
    "opp_prev_perf = opp_prev_perf.dropna()\n",
    "\n",
    "# Export to csv\n",
    "opp_prev_perf.to_csv('opp_previous_perf.csv', index = False)\n",
    "\n",
    "print('Done')\n",
    "\n",
    "opp_prev_perf.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff7b4eb",
   "metadata": {},
   "source": [
    "This is where we make the combined df of all data to train on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd7362e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7397 entries, 1 to 7397\n",
      "Data columns (total 66 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   bucket          7397 non-null   object        \n",
      " 1   Date            7397 non-null   datetime64[ns]\n",
      " 2   Opp             7397 non-null   object        \n",
      " 3   pitcher         7397 non-null   object        \n",
      " 4   code            7397 non-null   object        \n",
      " 5   Dec_1           7397 non-null   float64       \n",
      " 6   DR_1            7397 non-null   float64       \n",
      " 7   H_1             7397 non-null   float64       \n",
      " 8   ER_1            7397 non-null   float64       \n",
      " 9   BB_1            7397 non-null   float64       \n",
      " 10  SO_1            7397 non-null   float64       \n",
      " 11  HR_1            7397 non-null   float64       \n",
      " 12  HBP_1           7397 non-null   float64       \n",
      " 13  FIP_1           7397 non-null   float64       \n",
      " 14  Outs_1          7397 non-null   float64       \n",
      " 15  points_1        7397 non-null   float64       \n",
      " 16  QS_1            7397 non-null   float64       \n",
      " 17  bucket_1        7397 non-null   object        \n",
      " 18  Dec_5           7397 non-null   float64       \n",
      " 19  DR_5            7397 non-null   float64       \n",
      " 20  H_5             7397 non-null   float64       \n",
      " 21  ER_5            7397 non-null   float64       \n",
      " 22  BB_5            7397 non-null   float64       \n",
      " 23  SO_5            7397 non-null   float64       \n",
      " 24  HR_5            7397 non-null   float64       \n",
      " 25  HBP_5           7397 non-null   float64       \n",
      " 26  FIP_5           7397 non-null   float64       \n",
      " 27  Outs_5          7397 non-null   float64       \n",
      " 28  points_5        7397 non-null   float64       \n",
      " 29  QS_5            7397 non-null   float64       \n",
      " 30  bucket_5        7397 non-null   object        \n",
      " 31  Dec_all         7397 non-null   float64       \n",
      " 32  DR_all          7397 non-null   float64       \n",
      " 33  H_all_pitcher   7397 non-null   float64       \n",
      " 34  ER_all          7397 non-null   float64       \n",
      " 35  BB_all_pitcher  7397 non-null   float64       \n",
      " 36  SO_all_pitcher  7397 non-null   float64       \n",
      " 37  HR_all          7397 non-null   float64       \n",
      " 38  HBP_all         7397 non-null   float64       \n",
      " 39  FIP_all         7397 non-null   float64       \n",
      " 40  Outs_all        7397 non-null   float64       \n",
      " 41  points_all      7397 non-null   float64       \n",
      " 42  QS_all          7397 non-null   float64       \n",
      " 43  bucket_all      7397 non-null   object        \n",
      " 44  PA_30           7397 non-null   float64       \n",
      " 45  AB_30           7397 non-null   float64       \n",
      " 46  R_30            7397 non-null   float64       \n",
      " 47  H_30            7397 non-null   float64       \n",
      " 48  RBI_30          7397 non-null   float64       \n",
      " 49  BB_30           7397 non-null   float64       \n",
      " 50  SO_30           7397 non-null   float64       \n",
      " 51  BA_30           7397 non-null   float64       \n",
      " 52  OBP_30          7397 non-null   float64       \n",
      " 53  SLG_30          7397 non-null   float64       \n",
      " 54  OPS_30          7397 non-null   float64       \n",
      " 55  PA_all          7397 non-null   float64       \n",
      " 56  AB_all          7397 non-null   float64       \n",
      " 57  R_all           7397 non-null   float64       \n",
      " 58  H_all_opp       7397 non-null   float64       \n",
      " 59  RBI_all         7397 non-null   float64       \n",
      " 60  BB_all_opp      7397 non-null   float64       \n",
      " 61  SO_all_opp      7397 non-null   float64       \n",
      " 62  BA_all          7397 non-null   float64       \n",
      " 63  OBP_all         7397 non-null   float64       \n",
      " 64  SLG_all         7397 non-null   float64       \n",
      " 65  OPS_all         7397 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(58), object(7)\n",
      "memory usage: 3.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# # Read in opponent performance\n",
    "# probables_df = probables\n",
    "\n",
    "# Read in opponent performance\n",
    "opp_perf_df = opp_prev_perf\n",
    "\n",
    "# Extract column names\n",
    "cols = opp_perf_df.columns\n",
    "\n",
    "# Rearrange columns to get date/team at front\n",
    "cols = ['Date', 'Team',\n",
    "        'PA_30', 'AB_30', 'R_30', 'H_30', 'RBI_30', 'BB_30',\n",
    "        'SO_30', 'BA_30','OBP_30', 'SLG_30', 'OPS_30',\n",
    "        'PA_all', 'AB_all','R_all', 'H_all', 'RBI_all', 'BB_all',\n",
    "        'SO_all', 'BA_all', 'OBP_all','SLG_all', 'OPS_all']\n",
    "\n",
    "opp_perf_df = opp_perf_df[cols]\n",
    "\n",
    "# Read in pitcher performance\n",
    "pitcher_perf_df = pitcher_perf\n",
    "\n",
    "# Perform merge\n",
    "df = pitcher_perf_df.merge(opp_perf_df,\n",
    "                           left_on = ['Date', 'Opp'], right_on = ['Date', 'Team'],\n",
    "                           suffixes = ('_pitcher', '_opp')\n",
    "                          )\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "# Reorganize columns, drop points since it's a part of the target\n",
    "cols = ['bucket', 'Date', 'Opp', 'pitcher', 'code', 'Dec_1', 'DR_1', 'H_1',\n",
    "       'ER_1', 'BB_1', 'SO_1', 'HR_1', 'HBP_1', 'FIP_1', 'Outs_1', 'points_1',\n",
    "       'QS_1', 'bucket_1', 'Dec_5', 'DR_5', 'H_5', 'ER_5', 'BB_5', 'SO_5',\n",
    "       'HR_5', 'HBP_5', 'FIP_5', 'Outs_5', 'points_5', 'QS_5', 'bucket_5',\n",
    "       'Dec_all', 'DR_all', 'H_all_pitcher', 'ER_all', 'BB_all_pitcher',\n",
    "       'SO_all_pitcher', 'HR_all', 'HBP_all', 'FIP_all', 'Outs_all',\n",
    "       'points_all', 'QS_all', 'bucket_all', 'PA_30',\n",
    "       'AB_30', 'R_30', 'H_30', 'RBI_30', 'BB_30', 'SO_30', 'BA_30', 'OBP_30',\n",
    "       'SLG_30', 'OPS_30', 'PA_all', 'AB_all', 'R_all', 'H_all_opp', 'RBI_all',\n",
    "       'BB_all_opp', 'SO_all_opp', 'BA_all', 'OBP_all', 'SLG_all', 'OPS_all']\n",
    "\n",
    "\n",
    "df = df[cols]\n",
    "\n",
    "df.to_csv('training_data.csv', index=False)\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35be04d0",
   "metadata": {},
   "source": [
    "## This is where we build the prediction input dataset, which cannot be skipped, but is much shorter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3406d32e",
   "metadata": {},
   "source": [
    "This is the section where I pull the list of probable pitchers from b-ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1964f20d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>name</th>\n",
       "      <th>code</th>\n",
       "      <th>for</th>\n",
       "      <th>against</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-09-14 17:43:52.530992</td>\n",
       "      <td>Josiah Gray</td>\n",
       "      <td>grayjo03</td>\n",
       "      <td>WSN</td>\n",
       "      <td>PIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-09-14 17:43:52.531048</td>\n",
       "      <td>Mitch Keller</td>\n",
       "      <td>kellemi03</td>\n",
       "      <td>PIT</td>\n",
       "      <td>WSN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-09-14 17:43:52.535779</td>\n",
       "      <td>Derek Law</td>\n",
       "      <td>lawde01</td>\n",
       "      <td>CIN</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-09-14 17:43:52.535800</td>\n",
       "      <td>Reese Olson</td>\n",
       "      <td>olsonre01</td>\n",
       "      <td>DET</td>\n",
       "      <td>CIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-09-14 17:43:52.539440</td>\n",
       "      <td>Michael King</td>\n",
       "      <td>kingmi01</td>\n",
       "      <td>NYY</td>\n",
       "      <td>BOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-09-14 17:43:52.539458</td>\n",
       "      <td>Tanner Houck</td>\n",
       "      <td>houckta01</td>\n",
       "      <td>BOS</td>\n",
       "      <td>NYY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-09-14 17:43:52.542402</td>\n",
       "      <td>Eury Pérez</td>\n",
       "      <td>perezeu02</td>\n",
       "      <td>MIA</td>\n",
       "      <td>MIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-09-14 17:43:52.542418</td>\n",
       "      <td>Adrian Houser</td>\n",
       "      <td>housead01</td>\n",
       "      <td>MIL</td>\n",
       "      <td>MIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023-09-14 17:43:52.545276</td>\n",
       "      <td>Merrill Kelly</td>\n",
       "      <td>kellyme01</td>\n",
       "      <td>ARI</td>\n",
       "      <td>NYM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023-09-14 17:43:52.545293</td>\n",
       "      <td>Kodai Senga</td>\n",
       "      <td>sengako01</td>\n",
       "      <td>NYM</td>\n",
       "      <td>ARI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2023-09-14 17:43:52.548672</td>\n",
       "      <td>Nathan Eovaldi</td>\n",
       "      <td>eovalna01</td>\n",
       "      <td>TEX</td>\n",
       "      <td>TOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2023-09-14 17:43:52.548692</td>\n",
       "      <td>Kevin Gausman</td>\n",
       "      <td>gausmke01</td>\n",
       "      <td>TOR</td>\n",
       "      <td>TEX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2023-09-14 17:43:52.551330</td>\n",
       "      <td>Aaron Civale</td>\n",
       "      <td>civalaa01</td>\n",
       "      <td>TBR</td>\n",
       "      <td>BAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2023-09-14 17:43:52.551344</td>\n",
       "      <td>Kyle Bradish</td>\n",
       "      <td>bradiky01</td>\n",
       "      <td>BAL</td>\n",
       "      <td>TBR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2023-09-14 17:43:52.553821</td>\n",
       "      <td>Clarke Schmidt</td>\n",
       "      <td>schmicl01</td>\n",
       "      <td>NYY</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2023-09-14 17:43:52.553835</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NYY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2023-09-14 17:43:52.556743</td>\n",
       "      <td>Kenta Maeda</td>\n",
       "      <td>maedake01</td>\n",
       "      <td>MIN</td>\n",
       "      <td>CHW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2023-09-14 17:43:52.556760</td>\n",
       "      <td>José Ureña</td>\n",
       "      <td>urenajo01</td>\n",
       "      <td>CHW</td>\n",
       "      <td>MIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2023-09-14 17:43:52.560090</td>\n",
       "      <td>Logan Webb</td>\n",
       "      <td>webblo01</td>\n",
       "      <td>SFG</td>\n",
       "      <td>COL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2023-09-14 17:43:52.560111</td>\n",
       "      <td>Chase Anderson</td>\n",
       "      <td>anderch01</td>\n",
       "      <td>COL</td>\n",
       "      <td>SFG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         date            name       code  for against\n",
       "0  2023-09-14 17:43:52.530992     Josiah Gray   grayjo03  WSN     PIT\n",
       "1  2023-09-14 17:43:52.531048    Mitch Keller  kellemi03  PIT     WSN\n",
       "2  2023-09-14 17:43:52.535779       Derek Law    lawde01  CIN     DET\n",
       "3  2023-09-14 17:43:52.535800     Reese Olson  olsonre01  DET     CIN\n",
       "4  2023-09-14 17:43:52.539440    Michael King   kingmi01  NYY     BOS\n",
       "5  2023-09-14 17:43:52.539458    Tanner Houck  houckta01  BOS     NYY\n",
       "6  2023-09-14 17:43:52.542402      Eury Pérez  perezeu02  MIA     MIL\n",
       "7  2023-09-14 17:43:52.542418   Adrian Houser  housead01  MIL     MIA\n",
       "8  2023-09-14 17:43:52.545276   Merrill Kelly  kellyme01  ARI     NYM\n",
       "9  2023-09-14 17:43:52.545293     Kodai Senga  sengako01  NYM     ARI\n",
       "10 2023-09-14 17:43:52.548672  Nathan Eovaldi  eovalna01  TEX     TOR\n",
       "11 2023-09-14 17:43:52.548692   Kevin Gausman  gausmke01  TOR     TEX\n",
       "12 2023-09-14 17:43:52.551330    Aaron Civale  civalaa01  TBR     BAL\n",
       "13 2023-09-14 17:43:52.551344    Kyle Bradish  bradiky01  BAL     TBR\n",
       "14 2023-09-14 17:43:52.553821  Clarke Schmidt  schmicl01  NYY     NaN\n",
       "15 2023-09-14 17:43:52.553835             NaN        NaN  NaN     NYY\n",
       "16 2023-09-14 17:43:52.556743     Kenta Maeda  maedake01  MIN     CHW\n",
       "17 2023-09-14 17:43:52.556760      José Ureña  urenajo01  CHW     MIN\n",
       "18 2023-09-14 17:43:52.560090      Logan Webb   webblo01  SFG     COL\n",
       "19 2023-09-14 17:43:52.560111  Chase Anderson  anderch01  COL     SFG"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Request setup\n",
    "url = \"https://www.baseball-reference.com/previews/\"\n",
    "\n",
    "with urllib.request.urlopen(url) as response:\n",
    "    html = response.read()\n",
    "\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# Get the list of probables\n",
    "probables = []\n",
    "probables = pd.DataFrame()\n",
    "\n",
    "# We're going to loop through this list of matchups\n",
    "matchups = soup.find_all('div', class_='game_summary nohover')\n",
    "\n",
    "# For each matchup in the full list of matchups\n",
    "for matchup in matchups:\n",
    "\n",
    "    # Get the first pitcher's name\n",
    "    p1_name = matchup.find_all('a')[3].text\n",
    "\n",
    "    # Get the first pitcher's code\n",
    "    try: p1_code = matchup.find_all('a')[3].get('href').split(\"/\")[5].split(\".\")[0]\n",
    "    except: p1_code = np.nan\n",
    "\n",
    "    # Get the first pitcher's team\n",
    "    team1 = matchup.find_all('strong')[0].text\n",
    "\n",
    "    # Get the second pitcher's name\n",
    "    try: p2_name = matchup.find_all('a')[4].text\n",
    "    except: p2_name = np.nan\n",
    "\n",
    "    # Get the second pitcher's code\n",
    "    try: p2_code = matchup.find_all('a')[4].get('href').split(\"/\")[5].split(\".\")[0]\n",
    "    except: p2_code = np.nan\n",
    "\n",
    "    # Get the second pitcher's team\n",
    "    # Had to add a function that handles if there is a debut in the matchup,\n",
    "    # Which would otherwise change the list of 'strong' divs in the matchup\n",
    "    debut_adj = math.ceil(len(matchup.find_all('strong'))/2)\n",
    "    try: team2 = matchup.find_all('strong')[debut_adj].text\n",
    "    except: team2 = np.nan\n",
    "\n",
    "    # Create a dictionary for the first pitcher and their matchup\n",
    "    pitcher1 = {\n",
    "        'date':date.today(),\n",
    "        'name':p1_name,\n",
    "        'code':p1_code,\n",
    "        'for':team1,\n",
    "        'against':team2\n",
    "    }\n",
    "\n",
    "    # Create a dictionary for the second pitcher and their matchup\n",
    "    pitcher2 = {\n",
    "        'date':date.today(),\n",
    "        'name':p2_name,\n",
    "        'code':p2_code,\n",
    "        'for':team2,\n",
    "        'against':team1\n",
    "    }\n",
    "\n",
    "    # Put both pitchers into a list of probable matchups, separately\n",
    "    probables = probables.append(pitcher1, ignore_index=True)\n",
    "    probables = probables.append(pitcher2, ignore_index=True)\n",
    "\n",
    "# Export to csv\n",
    "probables.to_csv('probables.csv',index = False)\n",
    "\n",
    "probables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be99fba",
   "metadata": {},
   "source": [
    "This is the section where I scrape individual starting pitchers' individual game performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5e98f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done adding Josiah Gray 0/19\n",
      "Done adding Mitch Keller 1/19\n",
      "Done adding Derek Law 2/19\n",
      "Done adding Reese Olson 3/19\n",
      "Done adding Michael King 4/19\n",
      "Done adding Tanner Houck 5/19\n",
      "Done adding Eury Pérez 6/19\n",
      "Done adding Adrian Houser 7/19\n",
      "Done adding Merrill Kelly 8/19\n",
      "Done adding Kodai Senga 9/19\n",
      "Done adding Nathan Eovaldi 10/19\n",
      "Done adding Kevin Gausman 11/19\n",
      "Done adding Aaron Civale 12/19\n",
      "Done adding Kyle Bradish 13/19\n",
      "Done adding Clarke Schmidt 14/19\n",
      "Done adding Kenta Maeda 16/19\n",
      "Done adding José Ureña 17/19\n",
      "Done adding Logan Webb 18/19\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Opp</th>\n",
       "      <th>Dec</th>\n",
       "      <th>DR</th>\n",
       "      <th>H</th>\n",
       "      <th>ER</th>\n",
       "      <th>BB</th>\n",
       "      <th>SO</th>\n",
       "      <th>HR</th>\n",
       "      <th>HBP</th>\n",
       "      <th>FIP</th>\n",
       "      <th>Outs</th>\n",
       "      <th>points</th>\n",
       "      <th>QS</th>\n",
       "      <th>pitcher</th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-04-06</td>\n",
       "      <td>COL</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.80</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Josiah Gray</td>\n",
       "      <td>grayjo03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-04-11</td>\n",
       "      <td>LAA</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6.08</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Josiah Gray</td>\n",
       "      <td>grayjo03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-04-18</td>\n",
       "      <td>BAL</td>\n",
       "      <td>-1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.70</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Josiah Gray</td>\n",
       "      <td>grayjo03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-04-25</td>\n",
       "      <td>NYM</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.63</td>\n",
       "      <td>18</td>\n",
       "      <td>25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Josiah Gray</td>\n",
       "      <td>grayjo03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-04-30</td>\n",
       "      <td>PIT</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.30</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Josiah Gray</td>\n",
       "      <td>grayjo03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>2023-08-19</td>\n",
       "      <td>ATL</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.26</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Logan Webb</td>\n",
       "      <td>webblo01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>2023-08-25</td>\n",
       "      <td>ATL</td>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.34</td>\n",
       "      <td>16</td>\n",
       "      <td>-3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Logan Webb</td>\n",
       "      <td>webblo01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>2023-08-30</td>\n",
       "      <td>CIN</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.27</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Logan Webb</td>\n",
       "      <td>webblo01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>2023-09-04</td>\n",
       "      <td>CHC</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.31</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Logan Webb</td>\n",
       "      <td>webblo01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>2023-09-09</td>\n",
       "      <td>COL</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.28</td>\n",
       "      <td>18</td>\n",
       "      <td>21</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Logan Webb</td>\n",
       "      <td>webblo01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>424 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  Opp  Dec  DR  H  ER  BB  SO  HR  HBP   FIP  Outs  points   QS  \\\n",
       "0   2023-04-06  COL   -1   4  8   1   1   6   0    0  5.80    18      10  1.0   \n",
       "1   2023-04-11  LAA   -1   4  4   2   2   3   1    2  6.08    17       5  0.0   \n",
       "2   2023-04-18  BAL   -1   6  4   1   4   3   0    0  5.70    15       5  0.0   \n",
       "3   2023-04-25  NYM    1   6  4   0   1   9   0    0  4.63    18      25  1.0   \n",
       "4   2023-04-30  PIT    1   4  3   1   3   6   0    0  4.30    18      19  1.0   \n",
       "..         ...  ...  ...  .. ..  ..  ..  ..  ..  ...   ...   ...     ...  ...   \n",
       "419 2023-08-19  ATL    0   5  9   4   0   5   1    0  3.26    18       6  0.0   \n",
       "420 2023-08-25  ATL   -1   5  6   5   1   1   1    0  3.34    16      -3  0.0   \n",
       "421 2023-08-30  CIN   -1   4  7   2   0   6   0    0  3.27    18      10  1.0   \n",
       "422 2023-09-04  CHC   -1   4  5   3   1   4   1    0  3.31    20       9  1.0   \n",
       "423 2023-09-09  COL    1   4  3   0   1   4   0    0  3.28    18      21  1.0   \n",
       "\n",
       "         pitcher      code  \n",
       "0    Josiah Gray  grayjo03  \n",
       "1    Josiah Gray  grayjo03  \n",
       "2    Josiah Gray  grayjo03  \n",
       "3    Josiah Gray  grayjo03  \n",
       "4    Josiah Gray  grayjo03  \n",
       "..           ...       ...  \n",
       "419   Logan Webb  webblo01  \n",
       "420   Logan Webb  webblo01  \n",
       "421   Logan Webb  webblo01  \n",
       "422   Logan Webb  webblo01  \n",
       "423   Logan Webb  webblo01  \n",
       "\n",
       "[424 rows x 16 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is a dataset drawn from the probable pitchers scrape\n",
    "all_starters = probables[['name', 'code']]\n",
    "all_starters = all_starters.dropna()\n",
    "\n",
    "# Initialize df\n",
    "pitcher_data = pd.DataFrame()\n",
    "\n",
    "# For every starter we have\n",
    "for i in range(round(t*len(all_starters))):\n",
    "    try:\n",
    "        code = all_starters.loc[i,'code']\n",
    "        name = all_starters.loc[i,'name']\n",
    "\n",
    "        # Request setup\n",
    "        url = f'https://www.baseball-reference.com/players/gl.fcgi?id={code}&t=p&year=2023'\n",
    "        df = pd.read_html(url)\n",
    "        df = pd.DataFrame(df[0])\n",
    "\n",
    "        # # DATA CLEANING # #\n",
    "\n",
    "        # Drop weird rows\n",
    "        df = df[pd.to_numeric(df['Rk'], errors = 'coerce').notnull()]\n",
    "\n",
    "        # Reset index after dropping some rows\n",
    "        df = df.reset_index()\n",
    "\n",
    "        # Identify desired columns to keep and drop others\n",
    "        keep_cols = ['Date','Opp','Dec', 'DR',\n",
    "                     'IP', 'H', 'ER', 'BB', 'SO', 'HR', 'HBP',\n",
    "                     'FIP']\n",
    "\n",
    "        df = df[keep_cols]\n",
    "\n",
    "        # Now let's make the date column usable\n",
    "        # Clean away situations where there's a double-header impacting the date\n",
    "        df['Date'] = df['Date'].str.split(\"(\", expand = True).loc[:,0]\n",
    "\n",
    "        # Extract day from date\n",
    "        days = df['Date'].str.split(n=1,expand = True).loc[:,1]\n",
    "\n",
    "        # Extract month from date\n",
    "        months = df['Date'].str.split(n=1,expand = True).loc[:,0]\n",
    "\n",
    "        # Convert month to numerical month\n",
    "        months = months.str.replace('Oct','10')\n",
    "        months = months.str.replace('Sep','9')\n",
    "        months = months.str.replace('Aug','8')\n",
    "        months = months.str.replace('Jul','7')\n",
    "        months = months.str.replace('Jun','6')\n",
    "        months = months.str.replace('May','5')\n",
    "        months = months.str.replace('Apr','4')\n",
    "        months = months.str.replace('Mar','3')\n",
    "\n",
    "        # Create year series\n",
    "        df['years'] = '2023'\n",
    "\n",
    "        # Build date string\n",
    "        df['Date'] = df['years'] + \"-\" + months + \"-\" + days\n",
    "\n",
    "        # Drop year series\n",
    "        df = df.drop(columns = ['years'])\n",
    "\n",
    "        # Clean Decision series\n",
    "        df['Dec'] = df['Dec'].str[0]\n",
    "\n",
    "        df['Dec'] = df['Dec'].fillna('0')\n",
    "\n",
    "        df['Dec'] = df['Dec'].str.replace('W','1')\n",
    "        df['Dec'] = df['Dec'].str.replace('L','-1')\n",
    "        df['Dec'] = df['Dec'].str.replace('B','-1')\n",
    "        df['Dec'] = df['Dec'].str.replace('S','2')\n",
    "        df['Dec'] = df['Dec'].str.replace('H','0')\n",
    "\n",
    "        # Make everything a string before the step below. Don't worry, we'll fix this later on.\n",
    "        # This is because some of our data processing functions require string inputs,\n",
    "        # and our data scraper might accidentally infer some things as numbers.\n",
    "        # We have to do this\n",
    "        df = df.applymap(str)\n",
    "\n",
    "        # Make outs series, convert IP to Outs, then drop IP series\n",
    "        whole = df['IP'].str.split(\".\", expand = True)[0].astype('int')\n",
    "        part = df['IP'].str.split(\".\", expand = True)[1].astype('int')\n",
    "\n",
    "        df['Outs'] = 3*whole + part\n",
    "\n",
    "        df = df.drop(columns = ['IP'])\n",
    "\n",
    "        # Sometimes my DR column gets interpreted as a float, that gets turned into a string,\n",
    "        # that can't be turned directly into an int. But it can be interpreted as a float, from a string,\n",
    "        # so we do that first, and then we can convert it to an int without issue.\n",
    "        df['DR'] = df['DR'].astype('float')\n",
    "\n",
    "        # Cast numerical datatypes as numbers\n",
    "        df = df.astype({\n",
    "            'Dec':'int',\n",
    "            'DR':'int',\n",
    "            'H':'int',\n",
    "            'ER':'int',\n",
    "            'BB':'int',\n",
    "            'SO':'int',\n",
    "            'HR':'int',\n",
    "            'HBP':'int',\n",
    "            'FIP':'float',\n",
    "            'Outs':'int',\n",
    "        })\n",
    "\n",
    "        # Convert date string to date type\n",
    "        df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "        # Calculate fantasy points\n",
    "        df['points'] = 3*df['Dec'] - df['H'] - 2*df['ER'] - df['BB'] + df['SO'] - df['HBP'] + df['Outs']\n",
    "\n",
    "        # Create quality start series QS\n",
    "        for row in range(1,len(df)):\n",
    "            if df.loc[row,'ER']<=3 and df.loc[row,'Outs']>=18: df.loc[row,'QS'] = 1\n",
    "            else: df.loc[row,'QS'] = 0\n",
    "\n",
    "        # Add in pitcher name and code\n",
    "        df['pitcher'] = name\n",
    "        df['code'] = code\n",
    "\n",
    "        # Drop starts following 30+ days rest\n",
    "        df = df[df['DR'] <30]\n",
    "\n",
    "        # Add it to the overall pitcher data df\n",
    "        pitcher_data = pitcher_data.append(df, ignore_index=True)\n",
    "\n",
    "        # Let me know we're done with that player\n",
    "        print(f'Done adding {name} {i}/{len(all_starters)}')\n",
    "\n",
    "        # Wait for 3.2 seconds, b/c baseball-reference has a 20 request/min limit\n",
    "        time.sleep(3.2)\n",
    "    except: pass\n",
    "\n",
    "# Export to csv\n",
    "pitcher_data.to_csv('STARTERS_pitcher_data.csv',index = False)\n",
    "\n",
    "print(\"Done\")\n",
    "\n",
    "pitcher_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a2b044",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f13d29b6",
   "metadata": {},
   "source": [
    "This is the notebook where I take pitcher starting performance, and create a df of \"previous\" performance before each start, for each pitcher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba28a616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 424 entries, 0 to 423\n",
      "Data columns (total 15 columns):\n",
      " #   Column    Non-Null Count  Dtype         \n",
      "---  ------    --------------  -----         \n",
      " 0   Dec_1     406 non-null    float64       \n",
      " 1   DR_1      406 non-null    float64       \n",
      " 2   H_1       406 non-null    float64       \n",
      " 3   ER_1      406 non-null    float64       \n",
      " 4   BB_1      406 non-null    float64       \n",
      " 5   SO_1      406 non-null    float64       \n",
      " 6   HR_1      406 non-null    float64       \n",
      " 7   HBP_1     406 non-null    float64       \n",
      " 8   FIP_1     406 non-null    float64       \n",
      " 9   Outs_1    406 non-null    float64       \n",
      " 10  points_1  406 non-null    float64       \n",
      " 11  QS_1      406 non-null    float64       \n",
      " 12  Date      424 non-null    datetime64[ns]\n",
      " 13  code      424 non-null    object        \n",
      " 14  bucket_1  406 non-null    object        \n",
      "dtypes: datetime64[ns](1), float64(12), object(2)\n",
      "memory usage: 49.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pitcher_data\n",
    "\n",
    "# This is me getting a df of how the given pitcher performed\n",
    "# in the outing immediately before the given date\n",
    "df_last = pd.DataFrame()\n",
    "\n",
    "for i in range(len(df)):\n",
    "    # For a given row i, extract the code and date for that row\n",
    "    date = df.loc[i,:].Date\n",
    "    code = df.loc[i,:].code\n",
    "\n",
    "    # Given a code/date, extract the previous game data\n",
    "    df_last1 = df.loc[(df.Date < date) & (df.code == code)].sort_values('Date').tail(1)\n",
    "    \n",
    "    df_last1 = df_last1.drop(columns = ['Date', 'Opp','pitcher','code'])\n",
    "\n",
    "    # Get the average of those 1 rows, find the averages of averageable, transpose it from series to row\n",
    "    df_last1_avg = pd.DataFrame(df_last1.mean(axis=0)).transpose()\n",
    "\n",
    "    # Rename cols to indicate\n",
    "    df_last1_avg.columns = [f\"{col}_1\" for col in df_last1_avg.columns]\n",
    "\n",
    "    # Assign it to the date and code we're working with\n",
    "    df_last1_avg['Date'] = date\n",
    "    df_last1_avg['code'] = code\n",
    "\n",
    "    # Append into the last few games df\n",
    "    df_last = df_last.append(df_last1_avg)\n",
    "\n",
    "# Rest the index so that we can .loc through it\n",
    "df_last = df_last.reset_index(drop=True)\n",
    "\n",
    "# Put in the performance buckets\n",
    "for row in range(1,len(df_last)):\n",
    "    if df_last.loc[row,'points_1']<=-10: df_last.loc[row,'bucket_1'] = '.<=-10'\n",
    "    elif df_last.loc[row,'points_1']<=0: df_last.loc[row,'bucket_1'] = '-10<.<=0'\n",
    "    elif df_last.loc[row,'points_1']<=10: df_last.loc[row,'bucket_1'] = '0<.<=10'\n",
    "    elif df_last.loc[row,'points_1']<=20: df_last.loc[row,'bucket_1'] = '10<.<=20'\n",
    "    elif df_last.loc[row,'points_1']<=30: df_last.loc[row,'bucket_1'] = '20<.<=30'\n",
    "    elif df_last.loc[row,'points_1']>30: df_last.loc[row,'bucket_1'] = '30<.'\n",
    "    else: df_last.loc[row,'bucket_1'] = np.nan\n",
    "\n",
    "df_last.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96825989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 424 entries, 0 to 423\n",
      "Data columns (total 15 columns):\n",
      " #   Column    Non-Null Count  Dtype         \n",
      "---  ------    --------------  -----         \n",
      " 0   Dec_5     406 non-null    float64       \n",
      " 1   DR_5      406 non-null    float64       \n",
      " 2   H_5       406 non-null    float64       \n",
      " 3   ER_5      406 non-null    float64       \n",
      " 4   BB_5      406 non-null    float64       \n",
      " 5   SO_5      406 non-null    float64       \n",
      " 6   HR_5      406 non-null    float64       \n",
      " 7   HBP_5     406 non-null    float64       \n",
      " 8   FIP_5     406 non-null    float64       \n",
      " 9   Outs_5    406 non-null    float64       \n",
      " 10  points_5  406 non-null    float64       \n",
      " 11  QS_5      406 non-null    float64       \n",
      " 12  Date      424 non-null    datetime64[ns]\n",
      " 13  code      424 non-null    object        \n",
      " 14  bucket_5  406 non-null    object        \n",
      "dtypes: datetime64[ns](1), float64(12), object(2)\n",
      "memory usage: 49.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# Variable to determine the length of our rolling average\n",
    "N=5\n",
    "\n",
    "df_lastfew = pd.DataFrame()\n",
    "\n",
    "for i in range(len(df)):\n",
    "    # For a given row i, extract the code and date for that row\n",
    "    date = df.loc[i,:].Date\n",
    "    code = df.loc[i,:].code\n",
    "\n",
    "    # Given a code/date, extract the previous N games of data\n",
    "    df_lastN = df.loc[(df.Date < date) & (df.code == code)].sort_values('Date').tail(N)\n",
    "    \n",
    "    df_lastN = df_lastN.drop(columns = ['Date', 'Opp','pitcher','code'])\n",
    "\n",
    "    # Get the average of those N rows, find the averages of averageable series, transpose it from series to row\n",
    "    df_lastN_avg = pd.DataFrame(df_lastN.mean(axis=0)).transpose()\n",
    "\n",
    "    # Rename cols to indicate what it's the average of, and over how many games\n",
    "    df_lastN_avg.columns = [f\"{col}_{N}\" for col in df_lastN_avg.columns]\n",
    "\n",
    "    # Assign it to the date and code we're working with\n",
    "    df_lastN_avg['Date'] = date\n",
    "    df_lastN_avg['code'] = code\n",
    "\n",
    "    # Append into the last few games df\n",
    "    df_lastfew = df_lastfew.append(df_lastN_avg)\n",
    "\n",
    "# Rest the index so that we can .loc through it\n",
    "df_lastfew = df_lastfew.reset_index(drop=True)\n",
    "\n",
    "# Put in the performance buckets\n",
    "for row in range(1,len(df_lastfew)):\n",
    "    if df_lastfew.loc[row,f'points_{N}']<=-10: df_lastfew.loc[row,f'bucket_{N}'] = '.<=-10'\n",
    "    elif df_lastfew.loc[row,f'points_{N}']<=0: df_lastfew.loc[row,f'bucket_{N}'] = '-10<.<=0'\n",
    "    elif df_lastfew.loc[row,f'points_{N}']<=10: df_lastfew.loc[row,f'bucket_{N}'] = '0<.<=10'\n",
    "    elif df_lastfew.loc[row,f'points_{N}']<=20: df_lastfew.loc[row,f'bucket_{N}'] = '10<.<=20'\n",
    "    elif df_lastfew.loc[row,f'points_{N}']<=30: df_lastfew.loc[row,f'bucket_{N}'] = '20<.<=30'\n",
    "    elif df_lastfew.loc[row,f'points_{N}']>30: df_lastfew.loc[row,f'bucket_{N}'] = '30<.'\n",
    "    else: df_lastfew.loc[row,f'bucket_{N}'] = np.nan\n",
    "\n",
    "df_lastfew.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "761f65bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 424 entries, 0 to 423\n",
      "Data columns (total 15 columns):\n",
      " #   Column      Non-Null Count  Dtype         \n",
      "---  ------      --------------  -----         \n",
      " 0   Dec_all     406 non-null    float64       \n",
      " 1   DR_all      406 non-null    float64       \n",
      " 2   H_all       406 non-null    float64       \n",
      " 3   ER_all      406 non-null    float64       \n",
      " 4   BB_all      406 non-null    float64       \n",
      " 5   SO_all      406 non-null    float64       \n",
      " 6   HR_all      406 non-null    float64       \n",
      " 7   HBP_all     406 non-null    float64       \n",
      " 8   FIP_all     406 non-null    float64       \n",
      " 9   Outs_all    406 non-null    float64       \n",
      " 10  points_all  406 non-null    float64       \n",
      " 11  QS_all      406 non-null    float64       \n",
      " 12  Date        424 non-null    datetime64[ns]\n",
      " 13  code        424 non-null    object        \n",
      " 14  bucket_all  406 non-null    object        \n",
      "dtypes: datetime64[ns](1), float64(12), object(2)\n",
      "memory usage: 49.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df_cummulative = pd.DataFrame()\n",
    "\n",
    "for i in range(len(df)):\n",
    "    # For a given row i, extract the code and date for that row\n",
    "    date = df.loc[i,:].Date\n",
    "    code = df.loc[i,:].code\n",
    "\n",
    "    # Given a code/date, extract the previous game data\n",
    "    df_cummu = df.loc[(df.Date < date) & (df.code == code)].sort_values('Date')\n",
    "    \n",
    "    df_cummu = df_cummu.drop(columns = ['Date', 'Opp','pitcher','code'])\n",
    "\n",
    "    # Get the average of all rows, find the averages of averageable, transpose it from series to row\n",
    "    df_cummu_avg = pd.DataFrame(df_cummu.mean(axis=0)).transpose()\n",
    "\n",
    "    # Rename cols to indicate\n",
    "    df_cummu_avg.columns = [f\"{col}_all\" for col in df_cummu_avg.columns]\n",
    "\n",
    "    # Assign it to the date and code we're working with\n",
    "    df_cummu_avg['Date'] = date\n",
    "    df_cummu_avg['code'] = code\n",
    "\n",
    "    # Append into the last few games df\n",
    "    df_cummulative = df_cummulative.append(df_cummu_avg)\n",
    "\n",
    "# Rest the index so that we can .loc through it\n",
    "df_cummulative = df_cummulative.reset_index(drop=True)\n",
    "\n",
    "# Put in the performance buckets\n",
    "for row in range(1,len(df_cummulative)):\n",
    "    if df_cummulative.loc[row,'points_all']<=-10: df_cummulative.loc[row,'bucket_all'] = '.<=-10'\n",
    "    elif df_cummulative.loc[row,'points_all']<=0: df_cummulative.loc[row,'bucket_all'] = '-10<.<=0'\n",
    "    elif df_cummulative.loc[row,'points_all']<=10: df_cummulative.loc[row,'bucket_all'] = '0<.<=10'\n",
    "    elif df_cummulative.loc[row,'points_all']<=20: df_cummulative.loc[row,'bucket_all'] = '10<.<=20'\n",
    "    elif df_cummulative.loc[row,'points_all']<=30: df_cummulative.loc[row,'bucket_all'] = '20<.<=30'\n",
    "    elif df_cummulative.loc[row,'points_all']>30: df_cummulative.loc[row,'bucket_all'] = '30<.'\n",
    "    else: df_cummulative.loc[row,'bucket_all'] = np.nan\n",
    "\n",
    "df_cummulative.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a9ea591e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 406 entries, 1 to 423\n",
      "Data columns (total 44 columns):\n",
      " #   Column      Non-Null Count  Dtype         \n",
      "---  ------      --------------  -----         \n",
      " 0   Date        406 non-null    datetime64[ns]\n",
      " 1   Opp         406 non-null    object        \n",
      " 2   points      406 non-null    int64         \n",
      " 3   pitcher     406 non-null    object        \n",
      " 4   code        406 non-null    object        \n",
      " 5   Dec_1       406 non-null    float64       \n",
      " 6   DR_1        406 non-null    float64       \n",
      " 7   H_1         406 non-null    float64       \n",
      " 8   ER_1        406 non-null    float64       \n",
      " 9   BB_1        406 non-null    float64       \n",
      " 10  SO_1        406 non-null    float64       \n",
      " 11  HR_1        406 non-null    float64       \n",
      " 12  HBP_1       406 non-null    float64       \n",
      " 13  FIP_1       406 non-null    float64       \n",
      " 14  Outs_1      406 non-null    float64       \n",
      " 15  points_1    406 non-null    float64       \n",
      " 16  QS_1        406 non-null    float64       \n",
      " 17  bucket_1    406 non-null    object        \n",
      " 18  Dec_5       406 non-null    float64       \n",
      " 19  DR_5        406 non-null    float64       \n",
      " 20  H_5         406 non-null    float64       \n",
      " 21  ER_5        406 non-null    float64       \n",
      " 22  BB_5        406 non-null    float64       \n",
      " 23  SO_5        406 non-null    float64       \n",
      " 24  HR_5        406 non-null    float64       \n",
      " 25  HBP_5       406 non-null    float64       \n",
      " 26  FIP_5       406 non-null    float64       \n",
      " 27  Outs_5      406 non-null    float64       \n",
      " 28  points_5    406 non-null    float64       \n",
      " 29  QS_5        406 non-null    float64       \n",
      " 30  bucket_5    406 non-null    object        \n",
      " 31  Dec_all     406 non-null    float64       \n",
      " 32  DR_all      406 non-null    float64       \n",
      " 33  H_all       406 non-null    float64       \n",
      " 34  ER_all      406 non-null    float64       \n",
      " 35  BB_all      406 non-null    float64       \n",
      " 36  SO_all      406 non-null    float64       \n",
      " 37  HR_all      406 non-null    float64       \n",
      " 38  HBP_all     406 non-null    float64       \n",
      " 39  FIP_all     406 non-null    float64       \n",
      " 40  Outs_all    406 non-null    float64       \n",
      " 41  points_all  406 non-null    float64       \n",
      " 42  QS_all      406 non-null    float64       \n",
      " 43  bucket_all  406 non-null    object        \n",
      "dtypes: datetime64[ns](1), float64(36), int64(1), object(6)\n",
      "memory usage: 142.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# Merge in all those different windows of data\n",
    "\n",
    "# Merge in last 1 game of data\n",
    "compiled_df = pd.merge(df,df_last,\n",
    "                       on = ['Date','code'])\n",
    "\n",
    "# Merge in last N games of data\n",
    "compiled_df = pd.merge(compiled_df,df_lastfew,\n",
    "                       on = ['Date','code'])\n",
    "\n",
    "# Merge in all season games of data\n",
    "compiled_df = pd.merge(compiled_df,df_cummulative,\n",
    "                       on = ['Date','code'])\n",
    "\n",
    "# Drop the data from that day, so we're only training on data that is known at the time before the given date\n",
    "pitcher_perf = compiled_df.drop(columns = [\n",
    "    'Dec', 'DR', 'H', 'ER', 'BB', 'SO',\n",
    "    'HR', 'HBP', 'FIP', 'Outs', 'QS'])\n",
    "\n",
    "# Drop NaN rows\n",
    "# These rows result from asking for performance on the last 1, N games when there have been fewer than 1, N games\n",
    "pitcher_perf = pitcher_perf.dropna()\n",
    "\n",
    "pitcher_perf.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f051a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 406 entries, 0 to 405\n",
      "Data columns (total 45 columns):\n",
      " #   Column      Non-Null Count  Dtype         \n",
      "---  ------      --------------  -----         \n",
      " 0   Date        406 non-null    datetime64[ns]\n",
      " 1   Opp         406 non-null    object        \n",
      " 2   points      406 non-null    int64         \n",
      " 3   pitcher     406 non-null    object        \n",
      " 4   code        406 non-null    object        \n",
      " 5   Dec_1       406 non-null    float64       \n",
      " 6   DR_1        406 non-null    float64       \n",
      " 7   H_1         406 non-null    float64       \n",
      " 8   ER_1        406 non-null    float64       \n",
      " 9   BB_1        406 non-null    float64       \n",
      " 10  SO_1        406 non-null    float64       \n",
      " 11  HR_1        406 non-null    float64       \n",
      " 12  HBP_1       406 non-null    float64       \n",
      " 13  FIP_1       406 non-null    float64       \n",
      " 14  Outs_1      406 non-null    float64       \n",
      " 15  points_1    406 non-null    float64       \n",
      " 16  QS_1        406 non-null    float64       \n",
      " 17  bucket_1    406 non-null    object        \n",
      " 18  Dec_5       406 non-null    float64       \n",
      " 19  DR_5        406 non-null    float64       \n",
      " 20  H_5         406 non-null    float64       \n",
      " 21  ER_5        406 non-null    float64       \n",
      " 22  BB_5        406 non-null    float64       \n",
      " 23  SO_5        406 non-null    float64       \n",
      " 24  HR_5        406 non-null    float64       \n",
      " 25  HBP_5       406 non-null    float64       \n",
      " 26  FIP_5       406 non-null    float64       \n",
      " 27  Outs_5      406 non-null    float64       \n",
      " 28  points_5    406 non-null    float64       \n",
      " 29  QS_5        406 non-null    float64       \n",
      " 30  bucket_5    406 non-null    object        \n",
      " 31  Dec_all     406 non-null    float64       \n",
      " 32  DR_all      406 non-null    float64       \n",
      " 33  H_all       406 non-null    float64       \n",
      " 34  ER_all      406 non-null    float64       \n",
      " 35  BB_all      406 non-null    float64       \n",
      " 36  SO_all      406 non-null    float64       \n",
      " 37  HR_all      406 non-null    float64       \n",
      " 38  HBP_all     406 non-null    float64       \n",
      " 39  FIP_all     406 non-null    float64       \n",
      " 40  Outs_all    406 non-null    float64       \n",
      " 41  points_all  406 non-null    float64       \n",
      " 42  QS_all      406 non-null    float64       \n",
      " 43  bucket_all  406 non-null    object        \n",
      " 44  bucket      405 non-null    object        \n",
      "dtypes: datetime64[ns](1), float64(36), int64(1), object(7)\n",
      "memory usage: 142.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# Rest the index so that we can .loc through it\n",
    "pitcher_perf = pitcher_perf.reset_index(drop=True)\n",
    "\n",
    "## Put in buckets for actual performance to make the target\n",
    "# Put in the performance buckets\n",
    "for row in range(1,len(pitcher_perf)):\n",
    "    if pitcher_perf.loc[row,'points']<=-10: pitcher_perf.loc[row,'bucket'] = '.<=-10'\n",
    "    elif pitcher_perf.loc[row,'points']<=0: pitcher_perf.loc[row,'bucket'] = '-10<.<=0'\n",
    "    elif pitcher_perf.loc[row,'points']<=10: pitcher_perf.loc[row,'bucket'] = '0<.<=10'\n",
    "    elif pitcher_perf.loc[row,'points']<=20: pitcher_perf.loc[row,'bucket'] = '10<.<=20'\n",
    "    elif pitcher_perf.loc[row,'points_1']<=30: pitcher_perf.loc[row,'bucket'] = '20<.<=30'\n",
    "    elif pitcher_perf.loc[row,'points_1']>30: pitcher_perf.loc[row,'bucket'] = '30<.'\n",
    "    else: pitcher_perf.loc[row,'bucket'] = np.nan\n",
    "\n",
    "# Export to csv\n",
    "pitcher_perf.to_csv('STARTERS_pitcher_previous_perf.csv',index = False)\n",
    "\n",
    "pitcher_perf.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9417d11",
   "metadata": {},
   "source": [
    "This is the section where for each team, before a given game, I calculate their previous performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8760974b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: ARI\n",
      "Done: ATL\n",
      "Done: BAL\n",
      "Done: BOS\n",
      "Done: CHC\n",
      "Done: CHW\n",
      "Done: CIN\n",
      "Done: CLE\n",
      "Done: COL\n",
      "Done: DET\n",
      "Done: HOU\n",
      "Done: KCR\n",
      "Done: LAA\n",
      "Done: LAD\n",
      "Done: MIA\n",
      "Done: MIL\n",
      "Done: MIN\n",
      "Done: NYM\n",
      "Done: NYY\n",
      "Done: OAK\n",
      "Done: PHI\n",
      "Done: PIT\n",
      "Done: SDP\n",
      "Done: SEA\n",
      "Done: SFG\n",
      "Done: STL\n",
      "Done: TBR\n",
      "Done: TEX\n",
      "Done: TOR\n",
      "Done: WSN\n",
      "Done\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4466 entries, 1 to 4495\n",
      "Data columns (total 24 columns):\n",
      " #   Column   Non-Null Count  Dtype         \n",
      "---  ------   --------------  -----         \n",
      " 0   PA_30    4466 non-null   float64       \n",
      " 1   AB_30    4466 non-null   float64       \n",
      " 2   R_30     4466 non-null   float64       \n",
      " 3   H_30     4466 non-null   float64       \n",
      " 4   RBI_30   4466 non-null   float64       \n",
      " 5   BB_30    4466 non-null   float64       \n",
      " 6   SO_30    4466 non-null   float64       \n",
      " 7   BA_30    4466 non-null   float64       \n",
      " 8   OBP_30   4466 non-null   float64       \n",
      " 9   SLG_30   4466 non-null   float64       \n",
      " 10  OPS_30   4466 non-null   float64       \n",
      " 11  Date     4466 non-null   datetime64[ns]\n",
      " 12  Team     4466 non-null   object        \n",
      " 13  PA_all   4466 non-null   float64       \n",
      " 14  AB_all   4466 non-null   float64       \n",
      " 15  R_all    4466 non-null   float64       \n",
      " 16  H_all    4466 non-null   float64       \n",
      " 17  RBI_all  4466 non-null   float64       \n",
      " 18  BB_all   4466 non-null   float64       \n",
      " 19  SO_all   4466 non-null   float64       \n",
      " 20  BA_all   4466 non-null   float64       \n",
      " 21  OBP_all  4466 non-null   float64       \n",
      " 22  SLG_all  4466 non-null   float64       \n",
      " 23  OPS_all  4466 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(22), object(1)\n",
      "memory usage: 872.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# Get team codes\n",
    "team_codes = pd.read_csv('team_codes.csv')\n",
    "codes = team_codes['code'].tolist()\n",
    "\n",
    "## Make last 30 days df\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# For every team in our list of team codes\n",
    "for i in range(round(t*len(codes))):\n",
    "\n",
    "    # Loop through teams\n",
    "    team = codes[i]\n",
    "\n",
    "    # Request setup\n",
    "    url = f'https://www.baseball-reference.com/teams/tgl.cgi?team={team}&t=b&year=2023'\n",
    "\n",
    "    team_df = pd.read_html(url)\n",
    "    team_df = pd.DataFrame((team_df[0]))\n",
    "\n",
    "    # Add team identifier\n",
    "    team_df['Team'] = team\n",
    "\n",
    "    # Append into overall team dataframe\n",
    "    df = df.append(team_df)\n",
    "\n",
    "    # Print status\n",
    "    print(f'Done: {team}')\n",
    "    \n",
    "    # Wait for >3 seconds b/c site limits requests to 20/min\n",
    "    time.sleep(3.2)\n",
    "\n",
    "## Now we clean the data!\n",
    "\n",
    "# Identify key columns\n",
    "keep_cols = ['Team', 'Date','PA', 'AB', 'R', 'H', 'RBI', 'BB', 'SO', 'BA', 'OBP', 'SLG', 'OPS']\n",
    "\n",
    "# Select for those key columns\n",
    "df = df[keep_cols]\n",
    "\n",
    "# Drop rows that contain mid-table row headers\n",
    "df = df[pd.to_numeric(df['PA'], errors='coerce').notnull()]\n",
    "\n",
    "# Now let's make the date column usable\n",
    "# Clean away situations where there's a double-header impacting the date\n",
    "df['Date'] = df['Date'].str.split(\"(\", expand = True).loc[:,0]\n",
    "\n",
    "# Extract day from date\n",
    "days = df['Date'].str.split(n=1,expand = True).loc[:,1]\n",
    "\n",
    "# Extract month from date\n",
    "months = df['Date'].str.split(n=1,expand = True).loc[:,0]\n",
    "\n",
    "# Convert month to numerical month\n",
    "months = months.str.replace('Oct','10')\n",
    "months = months.str.replace('Sep','9')\n",
    "months = months.str.replace('Aug','8')\n",
    "months = months.str.replace('Jul','7')\n",
    "months = months.str.replace('Jun','6')\n",
    "months = months.str.replace('May','5')\n",
    "months = months.str.replace('Apr','4')\n",
    "months = months.str.replace('Mar','3')\n",
    "\n",
    "# Create year series\n",
    "df['years'] = '2023'\n",
    "\n",
    "# Build date string\n",
    "df['Date'] = df['years'] + \"-\" + months + \"-\" + days\n",
    "\n",
    "# Drop year series\n",
    "df = df.drop(columns = ['years'])\n",
    "\n",
    "# Cast series as numeric/datetime\n",
    "df = df.apply(pd.to_numeric, errors = 'ignore')\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "df = df.reset_index(drop = True)\n",
    "\n",
    "##\n",
    "# Variable to determine the length of our rolling average\n",
    "N=30\n",
    "\n",
    "# Now let's make a df showing the average performance over the last N days\n",
    "\n",
    "# Initialize our df\n",
    "df_LN = pd.DataFrame()\n",
    "\n",
    "for i in range(len(df)):\n",
    "\n",
    "    # For a given row i, extract the code and date for that row\n",
    "    date = df.loc[i,:].Date\n",
    "    team = df.loc[i,:].Team\n",
    "\n",
    "    # Given a code/date, extract the previous game data\n",
    "    # WHAT AM I GOING TO DO IF THERE IS NO PREVIOUS GAME DATA?!??!!\n",
    "    df_lastN = df.loc[(df['Date'] < date) & (df['Team'] == team)].sort_values('Date').tail(N)\n",
    "\n",
    "    # Get the average of those N rows, find the averages of averageable, transpose it from series to row\n",
    "    df_lastN_avg = pd.DataFrame(df_lastN.mean(axis=0)).transpose()\n",
    "\n",
    "    # Rename cols to indicate\n",
    "    df_lastN_avg.columns = [f\"{col}_{N}\" for col in df_lastN_avg.columns]\n",
    "\n",
    "    # Assign it to the date and code we're working with\n",
    "    df_lastN_avg['Date'] = date\n",
    "    df_lastN_avg['code'] = team\n",
    "\n",
    "    # Append into the last few games df\n",
    "    df_LN = df_LN.append(df_lastN_avg)\n",
    "\n",
    "# Drop errant team name column\n",
    "df_LN = df_LN.drop(columns = [f'Team_{N}'])\n",
    "\n",
    "# Relabel code column as true team name column\n",
    "df_LN = df_LN.rename(columns={\"code\": \"Team\"})\n",
    "\n",
    "df_LN = df_LN.reset_index(drop=True)\n",
    "\n",
    "##\n",
    "\n",
    "# Now let's make the season running total df\n",
    "df_Lall = pd.DataFrame()\n",
    "\n",
    "for i in range(len(df)):\n",
    "\n",
    "    # For a given row i, extract the code and date for that row\n",
    "    date = df.loc[i,:].Date\n",
    "    team = df.loc[i,:].Team\n",
    "\n",
    "    # Given a code/date, extract the previous game data\n",
    "    df_lastall = df.loc[(df['Date'] < date) & (df['Team'] == team)]\n",
    "\n",
    "    # Get the average of those 5 rows, find the averages of averageable, transpose it from series to row\n",
    "    df_lastall_avg = pd.DataFrame(df_lastall.mean(axis=0)).transpose()\n",
    "\n",
    "    # Rename cols to indicate\n",
    "    df_lastall_avg.columns = [f\"{col}_all\" for col in df_lastall_avg.columns]\n",
    "\n",
    "    # Assign it to the date and code we're working with\n",
    "    df_lastall_avg['Date'] = date\n",
    "    df_lastall_avg['code'] = team\n",
    "\n",
    "    # Append into the last few games df\n",
    "    df_Lall = df_Lall.append(df_lastall_avg)\n",
    "\n",
    "# Drop errant team name column\n",
    "df_Lall = df_Lall.drop(columns = ['Team_all'])\n",
    "\n",
    "# Relabel code column as true team name column\n",
    "df_Lall = df_Lall.rename(columns={\"code\": \"Team\"})\n",
    "\n",
    "df_Lall = df_Lall.reset_index(drop=True)\n",
    "\n",
    "##\n",
    "\n",
    "# Now let's combine these to dataframes to make an overall 'previous performance'\n",
    "opp_prev_perf = df_LN.merge(df_Lall, on = ['Team', 'Date'])\n",
    "\n",
    "# Drop rows that are NaN bc there weren't any previous days of performance to pull (i.e., first day in window)\n",
    "opp_prev_perf = opp_prev_perf.dropna()\n",
    "\n",
    "# Export to csv\n",
    "opp_prev_perf.to_csv('STARTERS_opp_previous_perf.csv', index = False)\n",
    "\n",
    "print('Done')\n",
    "\n",
    "opp_prev_perf.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eeb53e8",
   "metadata": {},
   "source": [
    "This is where we make the combined df of all data to predict from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3a5a4cb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bucket</th>\n",
       "      <th>points</th>\n",
       "      <th>Date</th>\n",
       "      <th>Opp</th>\n",
       "      <th>pitcher</th>\n",
       "      <th>code</th>\n",
       "      <th>Dec_1</th>\n",
       "      <th>DR_1</th>\n",
       "      <th>H_1</th>\n",
       "      <th>ER_1</th>\n",
       "      <th>...</th>\n",
       "      <th>AB_all</th>\n",
       "      <th>R_all</th>\n",
       "      <th>H_all_opp</th>\n",
       "      <th>RBI_all</th>\n",
       "      <th>BB_all_opp</th>\n",
       "      <th>SO_all_opp</th>\n",
       "      <th>BA_all</th>\n",
       "      <th>OBP_all</th>\n",
       "      <th>SLG_all</th>\n",
       "      <th>OPS_all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0&lt;.&lt;=10</td>\n",
       "      <td>5</td>\n",
       "      <td>2023-04-18</td>\n",
       "      <td>BAL</td>\n",
       "      <td>Josiah Gray</td>\n",
       "      <td>grayjo03</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>33.625000</td>\n",
       "      <td>5.875000</td>\n",
       "      <td>8.750000</td>\n",
       "      <td>5.687500</td>\n",
       "      <td>4.875000</td>\n",
       "      <td>9.125000</td>\n",
       "      <td>0.277188</td>\n",
       "      <td>0.370625</td>\n",
       "      <td>0.497375</td>\n",
       "      <td>0.867938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20&lt;.&lt;=30</td>\n",
       "      <td>25</td>\n",
       "      <td>2023-04-25</td>\n",
       "      <td>NYM</td>\n",
       "      <td>Josiah Gray</td>\n",
       "      <td>grayjo03</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>33.304348</td>\n",
       "      <td>4.869565</td>\n",
       "      <td>8.043478</td>\n",
       "      <td>4.695652</td>\n",
       "      <td>4.347826</td>\n",
       "      <td>7.260870</td>\n",
       "      <td>0.222217</td>\n",
       "      <td>0.331652</td>\n",
       "      <td>0.354783</td>\n",
       "      <td>0.686565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10&lt;.&lt;=20</td>\n",
       "      <td>19</td>\n",
       "      <td>2023-04-30</td>\n",
       "      <td>PIT</td>\n",
       "      <td>Josiah Gray</td>\n",
       "      <td>grayjo03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>33.500000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>8.928571</td>\n",
       "      <td>5.214286</td>\n",
       "      <td>3.928571</td>\n",
       "      <td>7.857143</td>\n",
       "      <td>0.237571</td>\n",
       "      <td>0.320643</td>\n",
       "      <td>0.409643</td>\n",
       "      <td>0.730250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0&lt;.&lt;=10</td>\n",
       "      <td>3</td>\n",
       "      <td>2023-05-05</td>\n",
       "      <td>ARI</td>\n",
       "      <td>Josiah Gray</td>\n",
       "      <td>grayjo03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>33.838710</td>\n",
       "      <td>5.193548</td>\n",
       "      <td>8.967742</td>\n",
       "      <td>5.032258</td>\n",
       "      <td>2.548387</td>\n",
       "      <td>7.419355</td>\n",
       "      <td>0.243839</td>\n",
       "      <td>0.287065</td>\n",
       "      <td>0.387097</td>\n",
       "      <td>0.674097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10&lt;.&lt;=20</td>\n",
       "      <td>14</td>\n",
       "      <td>2023-05-10</td>\n",
       "      <td>SFG</td>\n",
       "      <td>Josiah Gray</td>\n",
       "      <td>grayjo03</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>33.971429</td>\n",
       "      <td>4.371429</td>\n",
       "      <td>8.228571</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>3.371429</td>\n",
       "      <td>10.142857</td>\n",
       "      <td>0.238143</td>\n",
       "      <td>0.322943</td>\n",
       "      <td>0.419914</td>\n",
       "      <td>0.742857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>0&lt;.&lt;=10</td>\n",
       "      <td>6</td>\n",
       "      <td>2023-08-19</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Logan Webb</td>\n",
       "      <td>webblo01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>34.239669</td>\n",
       "      <td>5.834711</td>\n",
       "      <td>9.380165</td>\n",
       "      <td>5.636364</td>\n",
       "      <td>3.462810</td>\n",
       "      <td>8.123967</td>\n",
       "      <td>0.266388</td>\n",
       "      <td>0.340215</td>\n",
       "      <td>0.471512</td>\n",
       "      <td>0.811760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>-10&lt;.&lt;=0</td>\n",
       "      <td>-3</td>\n",
       "      <td>2023-08-25</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Logan Webb</td>\n",
       "      <td>webblo01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>34.214286</td>\n",
       "      <td>5.785714</td>\n",
       "      <td>9.380952</td>\n",
       "      <td>5.587302</td>\n",
       "      <td>3.420635</td>\n",
       "      <td>8.142857</td>\n",
       "      <td>0.266683</td>\n",
       "      <td>0.340381</td>\n",
       "      <td>0.472611</td>\n",
       "      <td>0.813016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>0&lt;.&lt;=10</td>\n",
       "      <td>10</td>\n",
       "      <td>2023-08-30</td>\n",
       "      <td>CIN</td>\n",
       "      <td>Logan Webb</td>\n",
       "      <td>webblo01</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>33.873134</td>\n",
       "      <td>4.753731</td>\n",
       "      <td>8.335821</td>\n",
       "      <td>4.537313</td>\n",
       "      <td>3.388060</td>\n",
       "      <td>9.343284</td>\n",
       "      <td>0.249037</td>\n",
       "      <td>0.328485</td>\n",
       "      <td>0.399903</td>\n",
       "      <td>0.728321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>0&lt;.&lt;=10</td>\n",
       "      <td>9</td>\n",
       "      <td>2023-09-04</td>\n",
       "      <td>CHC</td>\n",
       "      <td>Logan Webb</td>\n",
       "      <td>webblo01</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>33.897810</td>\n",
       "      <td>5.051095</td>\n",
       "      <td>8.583942</td>\n",
       "      <td>4.854015</td>\n",
       "      <td>3.518248</td>\n",
       "      <td>8.795620</td>\n",
       "      <td>0.257358</td>\n",
       "      <td>0.332971</td>\n",
       "      <td>0.411942</td>\n",
       "      <td>0.744920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>20&lt;.&lt;=30</td>\n",
       "      <td>21</td>\n",
       "      <td>2023-09-09</td>\n",
       "      <td>COL</td>\n",
       "      <td>Logan Webb</td>\n",
       "      <td>webblo01</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>33.878571</td>\n",
       "      <td>4.421429</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>4.207143</td>\n",
       "      <td>2.764286</td>\n",
       "      <td>9.485714</td>\n",
       "      <td>0.255329</td>\n",
       "      <td>0.314443</td>\n",
       "      <td>0.404000</td>\n",
       "      <td>0.718421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>441 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       bucket  points       Date  Opp      pitcher      code  Dec_1  DR_1  \\\n",
       "1     0<.<=10       5 2023-04-18  BAL  Josiah Gray  grayjo03   -1.0   4.0   \n",
       "2    20<.<=30      25 2023-04-25  NYM  Josiah Gray  grayjo03   -1.0   6.0   \n",
       "3    10<.<=20      19 2023-04-30  PIT  Josiah Gray  grayjo03    1.0   6.0   \n",
       "4     0<.<=10       3 2023-05-05  ARI  Josiah Gray  grayjo03    1.0   4.0   \n",
       "5    10<.<=20      14 2023-05-10  SFG  Josiah Gray  grayjo03   -1.0   4.0   \n",
       "..        ...     ...        ...  ...          ...       ...    ...   ...   \n",
       "437   0<.<=10       6 2023-08-19  ATL   Logan Webb  webblo01    0.0   5.0   \n",
       "438  -10<.<=0      -3 2023-08-25  ATL   Logan Webb  webblo01    0.0   5.0   \n",
       "439   0<.<=10      10 2023-08-30  CIN   Logan Webb  webblo01   -1.0   5.0   \n",
       "440   0<.<=10       9 2023-09-04  CHC   Logan Webb  webblo01   -1.0   4.0   \n",
       "441  20<.<=30      21 2023-09-09  COL   Logan Webb  webblo01   -1.0   4.0   \n",
       "\n",
       "     H_1  ER_1  ...     AB_all     R_all  H_all_opp   RBI_all  BB_all_opp  \\\n",
       "1    4.0   2.0  ...  33.625000  5.875000   8.750000  5.687500    4.875000   \n",
       "2    4.0   1.0  ...  33.304348  4.869565   8.043478  4.695652    4.347826   \n",
       "3    4.0   0.0  ...  33.500000  5.500000   8.928571  5.214286    3.928571   \n",
       "4    3.0   1.0  ...  33.838710  5.193548   8.967742  5.032258    2.548387   \n",
       "5    7.0   3.0  ...  33.971429  4.371429   8.228571  4.285714    3.371429   \n",
       "..   ...   ...  ...        ...       ...        ...       ...         ...   \n",
       "437  6.0   1.0  ...  34.239669  5.834711   9.380165  5.636364    3.462810   \n",
       "438  9.0   4.0  ...  34.214286  5.785714   9.380952  5.587302    3.420635   \n",
       "439  6.0   5.0  ...  33.873134  4.753731   8.335821  4.537313    3.388060   \n",
       "440  7.0   2.0  ...  33.897810  5.051095   8.583942  4.854015    3.518248   \n",
       "441  5.0   3.0  ...  33.878571  4.421429   8.400000  4.207143    2.764286   \n",
       "\n",
       "     SO_all_opp    BA_all   OBP_all   SLG_all   OPS_all  \n",
       "1      9.125000  0.277188  0.370625  0.497375  0.867938  \n",
       "2      7.260870  0.222217  0.331652  0.354783  0.686565  \n",
       "3      7.857143  0.237571  0.320643  0.409643  0.730250  \n",
       "4      7.419355  0.243839  0.287065  0.387097  0.674097  \n",
       "5     10.142857  0.238143  0.322943  0.419914  0.742857  \n",
       "..          ...       ...       ...       ...       ...  \n",
       "437    8.123967  0.266388  0.340215  0.471512  0.811760  \n",
       "438    8.142857  0.266683  0.340381  0.472611  0.813016  \n",
       "439    9.343284  0.249037  0.328485  0.399903  0.728321  \n",
       "440    8.795620  0.257358  0.332971  0.411942  0.744920  \n",
       "441    9.485714  0.255329  0.314443  0.404000  0.718421  \n",
       "\n",
       "[441 rows x 67 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in opponent performance\n",
    "probables_df = probables\n",
    "\n",
    "# Read in opponent performance\n",
    "opp_perf_df = opp_prev_perf\n",
    "\n",
    "# Extract column names\n",
    "cols = opp_perf_df.columns\n",
    "\n",
    "# Rearrange columns to get date/team at front\n",
    "cols = ['Date', 'Team',\n",
    "        'PA_30', 'AB_30', 'R_30', 'H_30', 'RBI_30', 'BB_30',\n",
    "        'SO_30', 'BA_30','OBP_30', 'SLG_30', 'OPS_30',\n",
    "        'PA_all', 'AB_all','R_all', 'H_all', 'RBI_all', 'BB_all',\n",
    "        'SO_all', 'BA_all', 'OBP_all','SLG_all', 'OPS_all']\n",
    "\n",
    "opp_perf_df = opp_perf_df[cols]\n",
    "\n",
    "# Read in pitcher performance\n",
    "pitcher_perf_df = pitcher_perf\n",
    "\n",
    "# Perform merge\n",
    "df = pitcher_perf_df.merge(opp_perf_df,\n",
    "                           left_on = ['Date', 'Opp'], right_on = ['Date', 'Team'],\n",
    "                           suffixes = ('_pitcher', '_opp')\n",
    "                          )\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "# Reorganize columns\n",
    "cols = ['bucket', 'points', 'Date', 'Opp', 'pitcher', 'code', 'Dec_1', 'DR_1', 'H_1',\n",
    "       'ER_1', 'BB_1', 'SO_1', 'HR_1', 'HBP_1', 'FIP_1', 'Outs_1', 'points_1',\n",
    "       'QS_1', 'bucket_1', 'Dec_5', 'DR_5', 'H_5', 'ER_5', 'BB_5', 'SO_5',\n",
    "       'HR_5', 'HBP_5', 'FIP_5', 'Outs_5', 'points_5', 'QS_5', 'bucket_5',\n",
    "       'Dec_all', 'DR_all', 'H_all_pitcher', 'ER_all', 'BB_all_pitcher',\n",
    "       'SO_all_pitcher', 'HR_all', 'HBP_all', 'FIP_all', 'Outs_all',\n",
    "       'points_all', 'QS_all', 'bucket_all', 'PA_30',\n",
    "       'AB_30', 'R_30', 'H_30', 'RBI_30', 'BB_30', 'SO_30', 'BA_30', 'OBP_30',\n",
    "       'SLG_30', 'OPS_30', 'PA_all', 'AB_all', 'R_all', 'H_all_opp', 'RBI_all',\n",
    "       'BB_all_opp', 'SO_all_opp', 'BA_all', 'OBP_all', 'SLG_all', 'OPS_all']\n",
    "\n",
    "\n",
    "df = df[cols]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2b109cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 18 entries, 27 to 441\n",
      "Data columns (total 65 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   Date            18 non-null     datetime64[ns]\n",
      " 1   Opp             18 non-null     object        \n",
      " 2   pitcher         18 non-null     object        \n",
      " 3   code            18 non-null     object        \n",
      " 4   Dec_1           18 non-null     float64       \n",
      " 5   DR_1            18 non-null     float64       \n",
      " 6   H_1             18 non-null     float64       \n",
      " 7   ER_1            18 non-null     float64       \n",
      " 8   BB_1            18 non-null     float64       \n",
      " 9   SO_1            18 non-null     float64       \n",
      " 10  HR_1            18 non-null     float64       \n",
      " 11  HBP_1           18 non-null     float64       \n",
      " 12  FIP_1           18 non-null     float64       \n",
      " 13  Outs_1          18 non-null     float64       \n",
      " 14  points_1        18 non-null     float64       \n",
      " 15  QS_1            18 non-null     float64       \n",
      " 16  bucket_1        18 non-null     object        \n",
      " 17  Dec_5           18 non-null     float64       \n",
      " 18  DR_5            18 non-null     float64       \n",
      " 19  H_5             18 non-null     float64       \n",
      " 20  ER_5            18 non-null     float64       \n",
      " 21  BB_5            18 non-null     float64       \n",
      " 22  SO_5            18 non-null     float64       \n",
      " 23  HR_5            18 non-null     float64       \n",
      " 24  HBP_5           18 non-null     float64       \n",
      " 25  FIP_5           18 non-null     float64       \n",
      " 26  Outs_5          18 non-null     float64       \n",
      " 27  points_5        18 non-null     float64       \n",
      " 28  QS_5            18 non-null     float64       \n",
      " 29  bucket_5        18 non-null     object        \n",
      " 30  Dec_all         18 non-null     float64       \n",
      " 31  DR_all          18 non-null     float64       \n",
      " 32  H_all_pitcher   18 non-null     float64       \n",
      " 33  ER_all          18 non-null     float64       \n",
      " 34  BB_all_pitcher  18 non-null     float64       \n",
      " 35  SO_all_pitcher  18 non-null     float64       \n",
      " 36  HR_all          18 non-null     float64       \n",
      " 37  HBP_all         18 non-null     float64       \n",
      " 38  FIP_all         18 non-null     float64       \n",
      " 39  Outs_all        18 non-null     float64       \n",
      " 40  points_all      18 non-null     float64       \n",
      " 41  QS_all          18 non-null     float64       \n",
      " 42  bucket_all      18 non-null     object        \n",
      " 43  PA_30           18 non-null     float64       \n",
      " 44  AB_30           18 non-null     float64       \n",
      " 45  R_30            18 non-null     float64       \n",
      " 46  H_30            18 non-null     float64       \n",
      " 47  RBI_30          18 non-null     float64       \n",
      " 48  BB_30           18 non-null     float64       \n",
      " 49  SO_30           18 non-null     float64       \n",
      " 50  BA_30           18 non-null     float64       \n",
      " 51  OBP_30          18 non-null     float64       \n",
      " 52  SLG_30          18 non-null     float64       \n",
      " 53  OPS_30          18 non-null     float64       \n",
      " 54  PA_all          18 non-null     float64       \n",
      " 55  AB_all          18 non-null     float64       \n",
      " 56  R_all           18 non-null     float64       \n",
      " 57  H_all_opp       18 non-null     float64       \n",
      " 58  RBI_all         18 non-null     float64       \n",
      " 59  BB_all_opp      18 non-null     float64       \n",
      " 60  SO_all_opp      18 non-null     float64       \n",
      " 61  BA_all          18 non-null     float64       \n",
      " 62  OBP_all         18 non-null     float64       \n",
      " 63  SLG_all         18 non-null     float64       \n",
      " 64  OPS_all         18 non-null     float64       \n",
      "dtypes: datetime64[ns](1), float64(58), object(6)\n",
      "memory usage: 9.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# Initialize df\n",
    "prediction_input = pd.DataFrame()\n",
    "\n",
    "# Extract list of starters from probables df\n",
    "starters = df['code'].unique()\n",
    "\n",
    "# Loop through all starters\n",
    "for starter in starters:\n",
    "    # Get most recent row of data\n",
    "    most_recent = df.loc[df['code'] == starter].sort_values('Date').tail(1)\n",
    "\n",
    "    # Put into df to use as prediciton inputs\n",
    "    prediction_input = prediction_input.append(most_recent)\n",
    "\n",
    "# Drop target columns\n",
    "prediction_input = prediction_input.drop(columns=['bucket', 'points'])\n",
    "\n",
    "prediction_input.to_csv('STARTERS_input_data.csv', index=False)\n",
    "\n",
    "prediction_input.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6831d8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 31.1 minutes ---\n"
     ]
    }
   ],
   "source": [
    "print(\"--- %s minutes ---\" % round((time.time() - start_time)/60,2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
