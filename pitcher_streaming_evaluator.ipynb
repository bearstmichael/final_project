{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4313aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import requests\n",
    "import urllib.request\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "from datetime import date, datetime, timedelta\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import sklearn as skl\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder,LabelBinarizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "\n",
    "start_time = time.time()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b5a36a",
   "metadata": {},
   "source": [
    "# Select your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44260d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How much do you want to scale back this run? Pick a number between 0 (none) and 1 (all)\n",
    "t = 1\n",
    "\n",
    "# Do you want to scrape new data (y/n)? If so, it'll take approx t*30 minutes\n",
    "pit_update = 'n'\n",
    "\n",
    "# Do you want to scrape new data (y/n)? If so, it'll take approx 3 minutes\n",
    "opp_update = 'n'\n",
    "\n",
    "# How wide do you want the predicted performance buckets to be?\n",
    "bucket_width = 12\n",
    "\n",
    "# How many games do you want to include in a pitcher's \"recent performance\" (think, rolling avg)\n",
    "N=5\n",
    "\n",
    "# How many games do you want to include in an opposing team's \"recent performance\" (think, rolling avg)\n",
    "M=30\n",
    "\n",
    "# Which PITCHER stats do you want inlcluded\n",
    "# This is in addition to required stats, which have already been selected\n",
    "# 1 for yes, 0 for no\n",
    "\n",
    "stat_selector = {\n",
    " 'index': 0,\n",
    " 'Rk': 0,\n",
    " 'Gcar': 0,\n",
    " 'Gtm': 0,\n",
    " 'Tm': 0,\n",
    " 'Rslt': 0,\n",
    " 'Inngs': 0,\n",
    " 'R': 0,\n",
    " 'ERA': 0,\n",
    " 'FIP': 1,\n",
    " 'BF': 0,\n",
    " 'Pit': 0,\n",
    " 'Str': 0,\n",
    " 'StL': 0,\n",
    " 'StS': 0,\n",
    " 'GB': 0,\n",
    " 'FB': 0,\n",
    " 'LD': 0,\n",
    " 'PU': 0,\n",
    " 'Unk': 0,\n",
    " 'GSc': 1,\n",
    " 'IR': 0,\n",
    " 'IS': 0,\n",
    " 'SB': 0,\n",
    " 'CS': 0,\n",
    " 'PO': 0,\n",
    " 'AB': 0,\n",
    " '2B': 1,\n",
    " '3B': 0,\n",
    " 'IBB': 0,\n",
    " 'GDP': 0,\n",
    " 'SF': 0,\n",
    " 'ROE': 0,\n",
    " 'aLI': 0,\n",
    " 'WPA': 0,\n",
    " 'acLI': 0,\n",
    " 'cWPA': 0,\n",
    " 'RE24': 0,\n",
    " 'DFS(DK)': 0,\n",
    " 'DFS(FD)': 0,\n",
    " 'Entered': 0,\n",
    " 'Exited': 0,\n",
    " 'Outs': 0}\n",
    "\n",
    "# Which OPPOSING TEAM stats do you want?\n",
    "opp_stat_selector = {'Rk': 0,\n",
    " 'Gtm': 0,\n",
    " 'Opp': 0,\n",
    " 'Rslt': 0,\n",
    " 'AB': 0,\n",
    " 'R': 1,\n",
    " 'H': 1,\n",
    " '2B': 0,\n",
    " '3B': 0,\n",
    " 'HR': 1,\n",
    " 'RBI': 0,\n",
    " 'BB': 1,\n",
    " 'IBB': 0,\n",
    " 'SO': 1,\n",
    " 'HBP': 0,\n",
    " 'SH': 0,\n",
    " 'SF': 0,\n",
    " 'ROE': 0,\n",
    " 'GDP': 0,\n",
    " 'SB': 0,\n",
    " 'CS': 0,\n",
    " 'BA': 0,\n",
    " 'OBP': 1,\n",
    " 'SLG': 1,\n",
    " 'OPS': 0,\n",
    " 'LOB': 1,\n",
    " '#': 0,\n",
    " 'Thr': 0,\n",
    " 'Opp. Starter (GmeSc)': 0}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5898b976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need a full list of datatypes for all potential data selections, so we can assign dtype appropriately\n",
    "pitcher_data_cols_dtypes = {\n",
    " 'index': 'int',\n",
    " 'Rk': 'int',\n",
    " 'Gcar': 'int',\n",
    " 'Gtm': 'int',\n",
    "#  'Date': 'datetime64[ns]', taking out this one b/c dates are weird. Handling elsewhere.\n",
    " 'Tm': 'object',\n",
    " 'Unnamed: 5': 'object',\n",
    " 'Opp': 'object',\n",
    " 'Rslt': 'object',\n",
    " 'Inngs': 'object',\n",
    " 'Dec': 'int',\n",
    " 'DR': 'int',\n",
    " 'H': 'int',\n",
    " 'R': 'int',\n",
    " 'ER': 'int',\n",
    " 'BB': 'int',\n",
    " 'SO': 'int',\n",
    " 'HR': 'int',\n",
    " 'HBP': 'int',\n",
    " 'ERA': 'float',\n",
    " 'FIP': 'float',\n",
    " 'BF': 'int',\n",
    " 'Pit': 'int',\n",
    " 'Str': 'int',\n",
    " 'StL': 'int',\n",
    " 'StS': 'int',\n",
    " 'GB': 'int',\n",
    " 'FB': 'int',\n",
    " 'LD': 'int',\n",
    " 'PU': 'int',\n",
    " 'Unk': 'int',\n",
    " 'GSc': 'int',\n",
    " 'IR': 'int',\n",
    " 'IS': 'int',\n",
    " 'SB': 'int',\n",
    " 'CS': 'int',\n",
    " 'PO': 'int',\n",
    " 'AB': 'int',\n",
    " '2B': 'int',\n",
    " '3B': 'int',\n",
    " 'IBB': 'int',\n",
    " 'GDP': 'int',\n",
    " 'SF': 'int',\n",
    " 'ROE': 'int',\n",
    " 'aLI': 'float',\n",
    " 'WPA': 'float',\n",
    " 'acLI': 'float',\n",
    " 'cWPA': 'float',\n",
    " 'RE24': 'float',\n",
    " 'DFS(DK)': 'float',\n",
    " 'DFS(FD)': 'float',\n",
    " 'Entered': 'object',\n",
    " 'Exited': 'object',\n",
    " 'Outs': 'int'}\n",
    "\n",
    "opp_data_cols_dtypes ={\n",
    " 'Rk': 'int',\n",
    " 'Gtm': 'int',\n",
    "#  'Date': 'int', commenting this out b/c we take care of it later\n",
    " 'Unnamed: 3': 'object',\n",
    " 'Opp': 'object',\n",
    " 'Rslt': 'object',\n",
    " 'PA': 'int',\n",
    " 'AB': 'int',\n",
    " 'R': 'int',\n",
    " 'H': 'int',\n",
    " '2B': 'int',\n",
    " '3B': 'int',\n",
    " 'HR': 'int',\n",
    " 'RBI': 'int',\n",
    " 'BB': 'int',\n",
    " 'IBB': 'int',\n",
    " 'SO': 'int',\n",
    " 'HBP': 'int',\n",
    " 'SH': 'int',\n",
    " 'SF': 'int',\n",
    " 'ROE': 'int',\n",
    " 'GDP': 'int',\n",
    " 'SB': 'int',\n",
    " 'CS': 'int',\n",
    " 'BA': 'float',\n",
    " 'OBP': 'float',\n",
    " 'SLG': 'float',\n",
    " 'OPS': 'float',\n",
    " 'LOB': 'int',\n",
    " '#': 'int',\n",
    " 'Thr': 'object',\n",
    " 'Opp. Starter (GmeSc)': 'object',\n",
    " 'Team': 'object'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8538fd29",
   "metadata": {},
   "source": [
    "### This is the section where I scrape individual starting pitchers' individual game performance\n",
    "\n",
    "#### Things to consider:\n",
    "Add a counter that shows the total number of pitchers logged, compared to the total number fed in, so I can see how much loss there was when we triggered the except/pass code\\\n",
    "\\\n",
    "How valuable is the information we are getting from the guys who are towards the end of the list? The list of pitchers is sorted by number of starts, so cutting the bottom 20% of the list will take away 20% of the run time, but only ~10% of the data. But maybe it's important to have representation for those pitchers with only a few starts? Much of the time, it's those rando pitchers that we're needing to judge the most, b/c they're the most available.\\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a2cbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a dataset drawn manually from b-ref.\n",
    "# There is probably a slick way to scrape this\n",
    "# but this only has to be updated every once in a while, not all the time\n",
    "# So manually works for now.\n",
    "all_starters = pd.read_csv('all_starters.csv')\n",
    "\n",
    "all_starters = pd.read_csv('all_starters.csv')\n",
    "\n",
    "\n",
    "## Identify desired columns to keep and drop others\n",
    "# Build list of wanted stats\n",
    "reqd_cols = ['Date','Opp','Dec', 'DR','IP', 'H', 'ER', 'BB', 'SO', 'HR', 'HBP']\n",
    "\n",
    "wanted_cols = []\n",
    "\n",
    "for key, value in stat_selector.items():\n",
    "    if value == 1: wanted_cols.append(key)\n",
    "\n",
    "# Combine with list of required stats\n",
    "keep_cols = reqd_cols + wanted_cols\n",
    "\n",
    "\n",
    "if pit_update == 'y':\n",
    "    # Initialize df\n",
    "    pitcher_data = pd.DataFrame()\n",
    "\n",
    "    for i in range(round(t*len(all_starters))):\n",
    "        try:\n",
    "            code = all_starters.loc[i,'code']\n",
    "            name = all_starters.loc[i,'name']\n",
    "\n",
    "            # Request setup\n",
    "            url = f'https://www.baseball-reference.com/players/gl.fcgi?id={code}&t=p&year=2023'\n",
    "            df = pd.read_html(url)\n",
    "            df = pd.DataFrame(df[0])\n",
    "\n",
    "            # # DATA CLEANING # #\n",
    "\n",
    "            # Drop rows that are mid-table column names\n",
    "            df = df[pd.to_numeric(df['Rk'], errors = 'coerce').notnull()]\n",
    "\n",
    "            # Reset index after dropping some rows\n",
    "            df = df.reset_index()\n",
    "\n",
    "\n",
    "\n",
    "            # Select for selected cols\n",
    "            df = df[keep_cols]\n",
    "\n",
    "            # Now let's make the date column usable\n",
    "            # Clean away situations where there's a double-header impacting the date\n",
    "            df['Date'] = df['Date'].str.split(\"(\", expand = True).loc[:,0]\n",
    "\n",
    "            # Extract day from date\n",
    "            days = df['Date'].str.split(n=1,expand = True).loc[:,1]\n",
    "\n",
    "            # Extract month from date\n",
    "            months = df['Date'].str.split(n=1,expand = True).loc[:,0]\n",
    "\n",
    "            # Convert month to numerical month\n",
    "            months = months.str.replace('Oct','10')\n",
    "            months = months.str.replace('Sep','9')\n",
    "            months = months.str.replace('Aug','8')\n",
    "            months = months.str.replace('Jul','7')\n",
    "            months = months.str.replace('Jun','6')\n",
    "            months = months.str.replace('May','5')\n",
    "            months = months.str.replace('Apr','4')\n",
    "            months = months.str.replace('Mar','3')\n",
    "\n",
    "            # Create year series\n",
    "            df['years'] = '2023'\n",
    "\n",
    "            # Build date string\n",
    "            df['Date'] = df['years'] + \"-\" + months + \"-\" + days\n",
    "\n",
    "            # Drop year series\n",
    "            df = df.drop(columns = ['years'])\n",
    "\n",
    "            # Clean Decision series\n",
    "            df['Dec'] = df['Dec'].str[0]\n",
    "\n",
    "            df['Dec'] = df['Dec'].fillna('0')\n",
    "\n",
    "            df['Dec'] = df['Dec'].str.replace('W','1')\n",
    "            df['Dec'] = df['Dec'].str.replace('L','-1')\n",
    "            df['Dec'] = df['Dec'].str.replace('B','-1')\n",
    "            df['Dec'] = df['Dec'].str.replace('S','2')\n",
    "            df['Dec'] = df['Dec'].str.replace('H','0')\n",
    "\n",
    "            # Make everything a string before the step below. Don't worry, we'll fix this later on.\n",
    "            # This is because some of our data processing functions require string inputs,\n",
    "            # and our data scraper might accidentally infer some things as numbers.\n",
    "            # We have to do this\n",
    "            df = df.applymap(str)\n",
    "\n",
    "            # Make outs series, convert IP to Outs, then drop IP series\n",
    "            whole = df['IP'].str.split(\".\", expand = True)[0].astype('int')\n",
    "            part = df['IP'].str.split(\".\", expand = True)[1].astype('int')\n",
    "\n",
    "            df['Outs'] = 3*whole + part\n",
    "\n",
    "            df = df.drop(columns = ['IP'])\n",
    "\n",
    "            # Sometimes my DR column gets interpreted as a float, that gets turned into a string,\n",
    "            # that can't be turned directly into an int. But it can be interpreted as a float, from a string,\n",
    "            # so we do that first, and then we can convert it to an int without issue.\n",
    "            df['DR'] = df['DR'].astype('float')\n",
    "\n",
    "            # Make a dictionary that will tell me what to cast each type as\n",
    "            dtype_applier = {}\n",
    "            for key, value in pitcher_data_cols_dtypes.items():\n",
    "                if key in keep_cols: dtype_applier[key]=value\n",
    "\n",
    "            # Cast numerical datatypes as numbers\n",
    "            df = df.astype(dtype_applier)\n",
    "\n",
    "            # Convert date string to date type\n",
    "            df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "            # Calculate fantasy points\n",
    "            df['points'] = 3*df['Dec'] - df['H'] - 2*df['ER'] - df['BB'] + df['SO'] - df['HBP'] + df['Outs']\n",
    "\n",
    "            # Create quality start series QS\n",
    "            for row in range(1,len(df)):\n",
    "                if df.loc[row,'ER']<=3 and df.loc[row,'Outs']>=18: df.loc[row,'QS'] = 1\n",
    "                else: df.loc[row,'QS'] = 0\n",
    "\n",
    "            # Add in pitcher name and code\n",
    "            df['pitcher'] = name\n",
    "            df['code'] = code\n",
    "\n",
    "            # Drop starts following 30+ days rest\n",
    "            df = df[df['DR'] <30]\n",
    "\n",
    "            # Add it to the overall pitcher data df\n",
    "            pitcher_data = pitcher_data.append(df, ignore_index=True)\n",
    "\n",
    "            # Let me know we're done with that player\n",
    "            print(f'Done adding {name} {i}/{len(all_starters)}')\n",
    "\n",
    "            # Wait for 3.5 seconds, b/c baseball-reference has a 20 request/min limit\n",
    "            time.sleep(3.5)\n",
    "        except: print(f'ERROR with {name} {i}/{len(all_starters)}')\n",
    "\n",
    "\n",
    "    # Export to csv\n",
    "    pitcher_data.to_csv('pitcher_data.csv',index = False)\n",
    "\n",
    "    print(\"Done\")\n",
    "\n",
    "# If we aren't pulling/updating data, just load whatever we had from the last time we ran it\n",
    "else: pitcher_data = pd.read_csv('pitcher_data.csv')\n",
    "\n",
    "pitcher_data['Date'] = pd.to_datetime(pitcher_data['Date'])\n",
    "\n",
    "pitcher_data.info()\n",
    "\n",
    "pitcher_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc44ef6",
   "metadata": {},
   "source": [
    "### This is the notebook where I take pitcher starting performance, and create a df of \"previous\" performance before each start, for each pitcher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805d5161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate performance buckets\n",
    "N = math.ceil(30/bucket_width)+1\n",
    "th = [bucket_width*n for n in list(range(N+1))]\n",
    "\n",
    "# Build ordered list of bucket labels\n",
    "bucket_labels = ['.<=0']\n",
    "\n",
    "for j in range(len(th)-1):\n",
    "    bucket = f'{th[j]}<.<={th[j+1]}'\n",
    "    bucket_labels.append(bucket)\n",
    "\n",
    "print(bucket_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1bc8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pitcher_data\n",
    "\n",
    "# This is me getting a df of how the given pitcher performed\n",
    "# in the outing immediately before the given date\n",
    "df_last = pd.DataFrame()\n",
    "\n",
    "for i in range(len(df)):\n",
    "    # For a given row i, extract the code and date for that row\n",
    "    date = df.loc[i,:].Date\n",
    "    code = df.loc[i,:].code\n",
    "\n",
    "    # Given a code/date, extract the previous game data\n",
    "    df_last1 = df.loc[(df.Date < date) & (df.code == code)].sort_values('Date').tail(1)\n",
    "    \n",
    "    df_last1 = df_last1.drop(columns = ['Date', 'Opp','pitcher','code'])\n",
    "\n",
    "    # Get the average of those 1 rows, find the averages of averageable, transpose it from series to row\n",
    "    df_last1_avg = pd.DataFrame(df_last1.mean(axis=0)).transpose()\n",
    "\n",
    "    # Rename cols to indicate\n",
    "    df_last1_avg.columns = [f\"{col}_1\" for col in df_last1_avg.columns]\n",
    "\n",
    "    # Assign it to the date and code we're working with\n",
    "    df_last1_avg['Date'] = date\n",
    "    df_last1_avg['code'] = code\n",
    "\n",
    "    # Append into the last few games df\n",
    "    df_last = df_last.append(df_last1_avg)\n",
    "\n",
    "# Rest the index so that we can .loc through it\n",
    "df_last = df_last.reset_index(drop=True)\n",
    "\n",
    "#  Put in the performance buckets\n",
    "for row in range(1,len(df_last)):\n",
    "    for j in range(len(th)-1):\n",
    "        if (df_last.loc[row,'points_1']>th[j]) and (df_last.loc[row,'points_1']<=th[j+1]):\n",
    "            df_last.loc[row,'bucket_1'] = f'{th[j]}<.<={th[j+1]}'\n",
    "        if df_last.loc[row,'points_1']<=0: df_last.loc[row,'bucket_1'] = '.<=0'\n",
    "\n",
    "df_last.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc5a2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lastfew = pd.DataFrame()\n",
    "\n",
    "for i in range(len(df)):\n",
    "    # For a given row i, extract the code and date for that row\n",
    "    date = df.loc[i,:].Date\n",
    "    code = df.loc[i,:].code\n",
    "\n",
    "    # Given a code/date, extract the previous N games of data\n",
    "    df_lastN = df.loc[(df.Date < date) & (df.code == code)].sort_values('Date').tail(N)\n",
    "    \n",
    "    df_lastN = df_lastN.drop(columns = ['Date', 'Opp','pitcher','code'])\n",
    "\n",
    "    # Get the average of those N rows, find the averages of averageable series, transpose it from series to row\n",
    "    df_lastN_avg = pd.DataFrame(df_lastN.mean(axis=0)).transpose()\n",
    "\n",
    "    # Rename cols to indicate what it's the average of, and over how many games\n",
    "    df_lastN_avg.columns = [f'{col}_{N}' for col in df_lastN_avg.columns]\n",
    "\n",
    "    # Assign it to the date and code we're working with\n",
    "    df_lastN_avg['Date'] = date\n",
    "    df_lastN_avg['code'] = code\n",
    "\n",
    "    # Append into the last few games df\n",
    "    df_lastfew = df_lastfew.append(df_lastN_avg)\n",
    "\n",
    "# Rest the index so that we can .loc through it\n",
    "df_lastfew = df_lastfew.reset_index(drop=True)\n",
    "\n",
    "# Put in the performance buckets\n",
    "for row in range(1,len(df_lastfew)):\n",
    "    for j in range(len(th)-1):\n",
    "        if (df_lastfew.loc[row,f'points_{N}']>th[j]) and (df_lastfew.loc[row,f'points_{N}']<=th[j+1]):\n",
    "            df_lastfew.loc[row,f'bucket_{N}'] = f'{th[j]}<.<={th[j+1]}'\n",
    "        if df_lastfew.loc[row,f'points_{N}']<=0: df_lastfew.loc[row,f'bucket_{N}'] = '.<=0'\n",
    "\n",
    "df_lastfew.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cce412",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cummulative = pd.DataFrame()\n",
    "\n",
    "for i in range(len(df)):\n",
    "    # For a given row i, extract the code and date for that row\n",
    "    date = df.loc[i,:].Date\n",
    "    code = df.loc[i,:].code\n",
    "\n",
    "    # Given a code/date, extract the previous game data\n",
    "    df_cummu = df.loc[(df.Date < date) & (df.code == code)].sort_values('Date')\n",
    "    \n",
    "    df_cummu = df_cummu.drop(columns = ['Date', 'Opp','pitcher','code'])\n",
    "\n",
    "    # Get the average of all rows, find the averages of averageable, transpose it from series to row\n",
    "    df_cummu_avg = pd.DataFrame(df_cummu.mean(axis=0)).transpose()\n",
    "\n",
    "    # Rename cols to indicate\n",
    "    df_cummu_avg.columns = [f\"{col}_all\" for col in df_cummu_avg.columns]\n",
    "\n",
    "    # Assign it to the date and code we're working with\n",
    "    df_cummu_avg['Date'] = date\n",
    "    df_cummu_avg['code'] = code\n",
    "\n",
    "    # Append into the last few games df\n",
    "    df_cummulative = df_cummulative.append(df_cummu_avg)\n",
    "\n",
    "# Rest the index so that we can .loc through it\n",
    "df_cummulative = df_cummulative.reset_index(drop=True)\n",
    "\n",
    "# Put in the performance buckets\n",
    "for row in range(1,len(df_cummulative)):\n",
    "    for j in range(len(th)-1):\n",
    "        if (df_cummulative.loc[row,'points_all']>th[j]) and (df_cummulative.loc[row,'points_all']<=th[j+1]):\n",
    "            df_cummulative.loc[row,'bucket_all'] = f'{th[j]}<.<={th[j+1]}'\n",
    "        if df_cummulative.loc[row,'points_all']<=0: df_cummulative.loc[row,'bucket_all'] = '.<=0'\n",
    "\n",
    "df_cummulative.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586aceb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge in all those different windows of data\n",
    "\n",
    "# Merge in last 1 game of data\n",
    "compiled_df = pd.merge(df,df_last,\n",
    "                       on = ['Date','code'])\n",
    "\n",
    "# Merge in last N games of data\n",
    "compiled_df = pd.merge(compiled_df,df_lastfew,\n",
    "                       on = ['Date','code'])\n",
    "\n",
    "# Merge in all season games of data\n",
    "compiled_df = pd.merge(compiled_df,df_cummulative,\n",
    "                       on = ['Date','code'])\n",
    "\n",
    "# Drop the data from that day, so we're only training on data that is known at the time before the given date\n",
    "dont_drop_from_reqs = ['IP','Dec','Date','Opp']\n",
    "reqs_to_drop = [ele for ele in reqd_cols if ele not in dont_drop_from_reqs]\n",
    "drop_cols = ['QS', 'Outs', 'Dec']+wanted_cols+reqs_to_drop\n",
    "\n",
    "pitcher_perf = compiled_df.drop(columns = drop_cols)\n",
    "\n",
    "pitcher_perf.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2931484d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rest the index so that we can .loc through it\n",
    "pitcher_perf = pitcher_perf.reset_index(drop=True)\n",
    "\n",
    "# Put in the performance buckets\n",
    "for row in range(1,len(pitcher_perf)):\n",
    "    for j in range(len(th)-1):\n",
    "        if (pitcher_perf.loc[row,'points']>th[j]) and (pitcher_perf.loc[row,'points']<=th[j+1]):\n",
    "            pitcher_perf.loc[row,'bucket'] = f'{th[j]}<.<={th[j+1]}'\n",
    "        if pitcher_perf.loc[row,'points']<=0: pitcher_perf.loc[row,'bucket'] = '.<=0'\n",
    "\n",
    "# These NaNs from asking for performance on the last 1, N games when there have been fewer than 1, N games\n",
    "pitcher_perf = pitcher_perf.dropna()\n",
    "\n",
    "# Export to csv\n",
    "pitcher_perf.to_csv('pitcher_previous_perf.csv',index = False)\n",
    "\n",
    "pitcher_perf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da689a7e",
   "metadata": {},
   "source": [
    "### This is the section where for each team, before a given game, I calculate their previous performance\n",
    "\n",
    "Things it'd be cool to add here:\\\n",
    "In the progress printout, maybe include the number of records in each team?\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a0e1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get team codes\n",
    "team_codes = pd.read_csv('team_codes.csv')\n",
    "codes = team_codes['code'].tolist()\n",
    "\n",
    "if opp_update == 'y':\n",
    "    ## Make last 30 days df\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    # For every team in our list of team codes\n",
    "    for i in range(round(t*len(codes))):\n",
    "\n",
    "        # Loop through teams\n",
    "        team = codes[i]\n",
    "\n",
    "        # Request setup\n",
    "        url = f'https://www.baseball-reference.com/teams/tgl.cgi?team={team}&t=b&year=2023'\n",
    "\n",
    "        team_df = pd.read_html(url)\n",
    "        team_df = pd.DataFrame((team_df[0]))\n",
    "\n",
    "        # Add team identifier\n",
    "        team_df['Team'] = team\n",
    "\n",
    "        # Append into overall team dataframe\n",
    "        df = df.append(team_df)\n",
    "\n",
    "        # Print status\n",
    "        print(f'Done: {team}')\n",
    "\n",
    "        # Wait for >3 seconds b/c site limits requests to 20/min\n",
    "        time.sleep(4)\n",
    "\n",
    "    ## Now we clean the data!\n",
    "    # Build list of wanted stats\n",
    "    wanted_cols = []\n",
    "\n",
    "    for key, value in opp_stat_selector.items():\n",
    "        if value == 1: wanted_cols.append(key)\n",
    "\n",
    "    reqd_cols = ['Team', 'Date', 'PA']\n",
    "\n",
    "    # Combine with list of required stats\n",
    "    keep_cols = reqd_cols + wanted_cols\n",
    "\n",
    "    # Select for those key columns\n",
    "    df = df[keep_cols]\n",
    "\n",
    "    # Drop rows that contain mid-table row headers\n",
    "    df = df[pd.to_numeric(df['PA'], errors='coerce').notnull()]\n",
    "\n",
    "    # Now let's make the date column usable\n",
    "    # Clean away situations where there's a double-header impacting the date\n",
    "    df['Date'] = df['Date'].str.split(\"(\", expand = True).loc[:,0]\n",
    "\n",
    "    # Extract day from date\n",
    "    days = df['Date'].str.split(n=1,expand = True).loc[:,1]\n",
    "\n",
    "    # Extract month from date\n",
    "    months = df['Date'].str.split(n=1,expand = True).loc[:,0]\n",
    "\n",
    "    # Convert month to numerical month\n",
    "    months = months.str.replace('Oct','10')\n",
    "    months = months.str.replace('Sep','9')\n",
    "    months = months.str.replace('Aug','8')\n",
    "    months = months.str.replace('Jul','7')\n",
    "    months = months.str.replace('Jun','6')\n",
    "    months = months.str.replace('May','5')\n",
    "    months = months.str.replace('Apr','4')\n",
    "    months = months.str.replace('Mar','3')\n",
    "\n",
    "    # Create year series\n",
    "    df['years'] = '2023'\n",
    "\n",
    "    # Build date string\n",
    "    df['Date'] = df['years'] + \"-\" + months + \"-\" + days\n",
    "\n",
    "    # Drop year series\n",
    "    df = df.drop(columns = ['years'])\n",
    "\n",
    "    # Cast series as numeric/datetime\n",
    "    df = df.apply(pd.to_numeric, errors = 'ignore')\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "    df = df.reset_index(drop = True)\n",
    "\n",
    "    ##\n",
    "    # Variable to determine the length of our rolling average\n",
    "    M=30\n",
    "\n",
    "    # Now let's make a df showing the average performance over the last N days\n",
    "\n",
    "    # Initialize our df\n",
    "    df_LM = pd.DataFrame()\n",
    "\n",
    "    for i in range(len(df)):\n",
    "\n",
    "        # For a given row i, extract the code and date for that row\n",
    "        date = df.loc[i,:].Date\n",
    "        team = df.loc[i,:].Team\n",
    "\n",
    "        # Given a code/date, extract the previous game data\n",
    "        # WHAT AM I GOING TO DO IF THERE IS NO PREVIOUS GAME DATA?!??!!\n",
    "        df_lastM = df.loc[(df['Date'] < date) & (df['Team'] == team)].sort_values('Date').tail(M)\n",
    "\n",
    "        # Get the average of those N rows, find the averages of averageable, transpose it from series to row\n",
    "        df_lastM_avg = pd.DataFrame(df_lastM.mean(axis=0)).transpose()\n",
    "\n",
    "        # Rename cols to indicate\n",
    "        df_lastM_avg.columns = [f\"{col}_{M}\" for col in df_lastM_avg.columns]\n",
    "\n",
    "        # Assign it to the date and code we're working with\n",
    "        df_lastM_avg['Date'] = date\n",
    "        df_lastM_avg['code'] = team\n",
    "\n",
    "        # Append into the last few games df\n",
    "        df_LM = df_LM.append(df_lastM_avg)\n",
    "\n",
    "    # Drop errant team name column\n",
    "    df_LM = df_LM.drop(columns = [f'Team_{M}'])\n",
    "\n",
    "    # Relabel code column as true team name column\n",
    "    df_LM = df_LM.rename(columns={\"code\": \"Team\"})\n",
    "\n",
    "    df_LM = df_LM.reset_index(drop=True)\n",
    "\n",
    "    ##\n",
    "\n",
    "    # Now let's make the season running total df\n",
    "    df_Lall = pd.DataFrame()\n",
    "\n",
    "    for i in range(len(df)):\n",
    "\n",
    "        # For a given row i, extract the code and date for that row\n",
    "        date = df.loc[i,:].Date\n",
    "        team = df.loc[i,:].Team\n",
    "\n",
    "        # Given a code/date, extract the previous game data\n",
    "        df_lastall = df.loc[(df['Date'] < date) & (df['Team'] == team)]\n",
    "\n",
    "        # Get the average of those 5 rows, find the averages of averageable, transpose it from series to row\n",
    "        df_lastall_avg = pd.DataFrame(df_lastall.mean(axis=0)).transpose()\n",
    "\n",
    "        # Rename cols to indicate\n",
    "        df_lastall_avg.columns = [f\"{col}_all\" for col in df_lastall_avg.columns]\n",
    "\n",
    "        # Assign it to the date and code we're working with\n",
    "        df_lastall_avg['Date'] = date\n",
    "        df_lastall_avg['code'] = team\n",
    "\n",
    "        # Append into the last few games df\n",
    "        df_Lall = df_Lall.append(df_lastall_avg)\n",
    "\n",
    "    # Drop errant team name column\n",
    "    df_Lall = df_Lall.drop(columns = ['Team_all'])\n",
    "\n",
    "    # Relabel code column as true team name column\n",
    "    df_Lall = df_Lall.rename(columns={\"code\": \"Team\"})\n",
    "\n",
    "    df_Lall = df_Lall.reset_index(drop=True)\n",
    "\n",
    "    ##\n",
    "\n",
    "    # Now let's combine these to dataframes to make an overall 'previous performance'\n",
    "    opp_prev_perf = df_LM.merge(df_Lall, on = ['Team', 'Date'])\n",
    "\n",
    "    # Drop rows that are NaN bc there weren't any previous days of performance to pull (i.e., first day in window)\n",
    "    opp_prev_perf = opp_prev_perf.dropna()\n",
    "\n",
    "    # Export to csv\n",
    "    opp_prev_perf.to_csv('opp_previous_perf.csv', index = False)\n",
    "\n",
    "    print('Done')\n",
    "\n",
    "else: opp_prev_perf = pd.read_csv('opp_previous_perf.csv')\n",
    "\n",
    "opp_prev_perf['Date'] = pd.to_datetime(opp_prev_perf['Date'])\n",
    "\n",
    "opp_prev_perf.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2845d832",
   "metadata": {},
   "source": [
    "This is where we make the combined df of all data to train on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f2109c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in opponent performance\n",
    "opp_perf_df = opp_prev_perf\n",
    "\n",
    "# Extract column names\n",
    "cols = list(opp_perf_df.columns)\n",
    "\n",
    "# Move date and team to front of list\n",
    "cols.remove('Date')\n",
    "cols.insert(0,'Date')\n",
    "cols.remove('Team')\n",
    "cols.insert(0,'Team')\n",
    "opp_perf_df = opp_perf_df[cols]\n",
    "\n",
    "# Read in pitcher performance\n",
    "pitcher_perf_df = pitcher_perf\n",
    "\n",
    "# Perform merge\n",
    "df = pitcher_perf_df.merge(opp_perf_df,\n",
    "                           left_on = ['Date', 'Opp'], right_on = ['Date', 'Team'],\n",
    "                           suffixes = ('_pitcher', '_opp')\n",
    "                          )\n",
    "# Drop weird rows\n",
    "df = df.dropna()\n",
    "\n",
    "# Move 'bucket' column to front\n",
    "cols = list(df.columns)\n",
    "cols.remove('bucket')\n",
    "cols.insert(0,'bucket')\n",
    "\n",
    "# Drop 'points' column\n",
    "cols.remove('points')\n",
    "\n",
    "# Rearrange columns\n",
    "df = df[cols]\n",
    "\n",
    "training_df = df\n",
    "\n",
    "# Export to csv\n",
    "training_df.to_csv('training_data.csv', index=False)\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed083b9a",
   "metadata": {},
   "source": [
    "## This is where we build the prediction input dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50270f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Request setup\n",
    "url = \"https://www.baseball-reference.com/previews/\"\n",
    "\n",
    "with urllib.request.urlopen(url) as response:\n",
    "    html = response.read()\n",
    "\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# Get the list of probables\n",
    "probables = []\n",
    "probables = pd.DataFrame()\n",
    "\n",
    "# We're going to loop through this list of matchups\n",
    "matchups = soup.find_all('div', class_='game_summary nohover')\n",
    "\n",
    "# For each matchup in the full list of matchups\n",
    "for matchup in matchups:\n",
    "\n",
    "    # Get the first pitcher's name\n",
    "    p1_name = matchup.find_all('a')[3].text\n",
    "\n",
    "    # Get the first pitcher's code\n",
    "    try: p1_code = matchup.find_all('a')[3].get('href').split(\"/\")[5].split(\".\")[0]\n",
    "    except: p1_code = np.nan\n",
    "\n",
    "    # Get the first pitcher's team\n",
    "    team1 = matchup.find_all('strong')[0].text\n",
    "\n",
    "    # Get the second pitcher's name\n",
    "    try: p2_name = matchup.find_all('a')[4].text\n",
    "    except: p2_name = np.nan\n",
    "\n",
    "    # Get the second pitcher's code\n",
    "    try: p2_code = matchup.find_all('a')[4].get('href').split(\"/\")[5].split(\".\")[0]\n",
    "    except: p2_code = np.nan\n",
    "\n",
    "    # Get the second pitcher's team\n",
    "    # Had to add a function that handles if there is a debut in the matchup,\n",
    "    # Which would otherwise change the list of 'strong' divs in the matchup\n",
    "    debut_adj = math.ceil(len(matchup.find_all('strong'))/2)\n",
    "    try: team2 = matchup.find_all('strong')[debut_adj].text\n",
    "    except: team2 = np.nan\n",
    "\n",
    "    # Create a dictionary for the first pitcher and their matchup\n",
    "    pitcher1 = {\n",
    "        'date':date.today(),\n",
    "        'name':p1_name,\n",
    "        'code':p1_code,\n",
    "        'for':team1,\n",
    "        'against':team2\n",
    "    }\n",
    "\n",
    "    # Create a dictionary for the second pitcher and their matchup\n",
    "    pitcher2 = {\n",
    "        'date':date.today(),\n",
    "        'name':p2_name,\n",
    "        'code':p2_code,\n",
    "        'for':team2,\n",
    "        'against':team1\n",
    "    }\n",
    "\n",
    "    # Put both pitchers into a list of probable matchups, separately\n",
    "    probables = probables.append(pitcher1, ignore_index=True)\n",
    "    probables = probables.append(pitcher2, ignore_index=True)\n",
    "\n",
    "# Export to csv\n",
    "probables.to_csv('probables.csv',index = False)\n",
    "\n",
    "# NOTE: NaN usually means the pitcher hasn't been posted on b-ref yet\n",
    "\n",
    "probables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728c5d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in opponent performance\n",
    "probables_df = probables\n",
    "\n",
    "# This is is the data for just the starting pitchers, to be used for predictions\n",
    "all_starters = probables_df['code']\n",
    "pitcher_data = pitcher_perf[pitcher_perf['code'].isin(list(all_starters))]\n",
    "\n",
    "# This is is the data for just the starting pitchers, to be used for predictions\n",
    "all_opps = probables_df['against']\n",
    "all_opps = opp_prev_perf[opp_prev_perf['Team'].isin(list(all_opps))]\n",
    "\n",
    "# Perform merge\n",
    "df = pitcher_data.merge(all_opps,\n",
    "                           left_on = ['Date', 'Opp'], right_on = ['Date', 'Team'],\n",
    "                           suffixes = ('_pitcher', '_opp')\n",
    "                          )\n",
    "\n",
    "df_cols = list(df.columns)\n",
    "df_cols.remove('code')\n",
    "df_cols.insert(0,'code')\n",
    "\n",
    "df_cols.remove('pitcher')\n",
    "df_cols.insert(0,'pitcher')\n",
    "\n",
    "df_cols.remove('Opp')\n",
    "df_cols.insert(0,'Opp')\n",
    "\n",
    "df_cols.remove('Date')\n",
    "df_cols.insert(0,'Date')\n",
    "\n",
    "df_cols.remove('points')\n",
    "df_cols.insert(0,'points')\n",
    "\n",
    "df_cols.remove('bucket')\n",
    "df_cols.insert(0,'bucket')\n",
    "\n",
    "df = df[df_cols]\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ca75fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize df\n",
    "prediction_input = pd.DataFrame()\n",
    "\n",
    "# Extract list of starters from probables df\n",
    "starters = df['code'].unique()\n",
    "\n",
    "# Loop through all starters\n",
    "for starter in starters:\n",
    "    # Get most recent row of data\n",
    "    most_recent = df.loc[df['code'] == starter].sort_values('Date').tail(1)\n",
    "\n",
    "    # Put into df to use as prediciton inputs\n",
    "    prediction_input = prediction_input.append(most_recent)\n",
    "\n",
    "# Drop target columns\n",
    "prediction_input = prediction_input.drop(columns=['bucket', 'points'])\n",
    "\n",
    "prediction_input.to_csv('STARTERS_input_data.csv', index=False)\n",
    "\n",
    "prediction_input.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cf4253",
   "metadata": {},
   "source": [
    "# This is where we actually run the actual model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4446ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDICTION INPUT DATA PREP\n",
    "\n",
    "# Read in input data\n",
    "input_df = prediction_input\n",
    "\n",
    "# Take out columns that we'll need in order to read our predictions\n",
    "id_info = input_df[['pitcher','code']]\n",
    "\n",
    "# Drop columns that will not be included in training\n",
    "input_df = input_df.drop(columns = ['Date','pitcher','code'])\n",
    "\n",
    "# Dropping this column separately just b/c I maybe want to come back to considering NOT dropping it\n",
    "# Yeah, the opponent performance is still here, but sometimes it's just the TEAM itself that seems\n",
    "# to make a difference for some teams/pitchers (i.e., Devers vs. NYY)\n",
    "input_df = input_df.drop(columns = 'Opp')\n",
    "\n",
    "# Separate target as y and features as X\n",
    "Xp = input_df\n",
    "\n",
    "# Get list of non-numerical columns\n",
    "Xp_cat = Xp.dtypes[Xp.dtypes == 'object'].index.tolist()\n",
    "\n",
    "# Get dummies for those columns\n",
    "one_hot = pd.get_dummies(Xp[Xp_cat])\n",
    "\n",
    "# Drop the original non-numerical columns\n",
    "Xp = Xp.drop(columns = Xp_cat)\n",
    "\n",
    "# Put in ALL the possible buckets\n",
    "bucket1 = [f'bucket_1_{label}' for label in bucket_labels]\n",
    "bucketN = [f'bucket_{N}_{label}' for label in bucket_labels]\n",
    "bucketall = [f'bucket_all_{label}' for label in bucket_labels]\n",
    "\n",
    "buckets = bucket1 + bucketN + bucketall\n",
    "\n",
    "Xp[buckets] = 0\n",
    "\n",
    "# update the bucket columns with the numerical dummies for those non-numerical columns\n",
    "Xp.update(one_hot)\n",
    "\n",
    "# This is officially the data we're going to put into our predictor\n",
    "Xp.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afe92d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TESTING DATA PREP\n",
    "\n",
    "# Drop columns that will not be included in training\n",
    "training_df = training_df.drop(columns = ['Date','pitcher','code'])\n",
    "\n",
    "# Dropping this column separately just b/c I maybe want to come back to considering NOT dropping it\n",
    "# Yeah, the opponent performance is still here, but sometimes it's just the TEAM itself that seems\n",
    "# to make a difference for some teams/pitchers (i.e., Devers vs. NYY)\n",
    "training_df = training_df.drop(columns = 'Opp')\n",
    "\n",
    "\n",
    "# Separate target as y and features as X\n",
    "y = training_df['bucket']\n",
    "X = training_df.drop(columns = 'bucket')\n",
    "\n",
    "# Get list of non-numerical columns\n",
    "X_cat = X.dtypes[X.dtypes == 'object'].index.tolist()\n",
    "\n",
    "# Get dummies for those columns\n",
    "one_hot = pd.get_dummies(X[X_cat])\n",
    "\n",
    "# Drop the original non-numerical columns\n",
    "X = X.drop(columns = X_cat)\n",
    "\n",
    "# Put in ALL the possible buckets\n",
    "bucket1 = [f'bucket_1_{label}' for label in bucket_labels]\n",
    "bucketN = [f'bucket_{N}_{label}' for label in bucket_labels]\n",
    "bucketall = [f'bucket_all_{label}' for label in bucket_labels]\n",
    "\n",
    "buckets = bucket1 + bucketN + bucketall\n",
    "\n",
    "X[buckets] = 0\n",
    "\n",
    "# update the bucket columns with the numerical dummies for those non-numerical columns\n",
    "X.update(one_hot)\n",
    "\n",
    "# This is officially the data we're going to put into our predictor\n",
    "X.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebba6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is us converting one vector of 6 distinct classes into basically get-dummies\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "outcomes = bucket_labels\n",
    "\n",
    "y_factors = to_categorical(pd.Categorical(y,categories = outcomes).codes,len(bucket_labels))\n",
    "\n",
    "\n",
    "# Split training/test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_factors, random_state=42)\n",
    "\n",
    "## Preprocess numerical data for neural network\n",
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516c51b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the deep learning model \n",
    "nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "p=0\n",
    "nn_model.add(tf.keras.layers.Dense(units=round(0.6*len(list(X.columns))),\n",
    "                                   activation=\"relu\", input_dim = X_train.shape[1]))\n",
    "nn_model.add(tf.keras.layers.Dense(units=round(0.75*0.6*len(list(X.columns))+0.25*len(bucket_labels)),\n",
    "                                   activation=\"tanh\"))\n",
    "nn_model.add(tf.keras.layers.Dense(units=round(0.50*0.6*len(list(X.columns))+0.50*len(bucket_labels)),\n",
    "                                   activation=\"relu\"))\n",
    "nn_model.add(tf.keras.layers.Dense(units=round(0.25*0.6*len(list(X.columns))+0.75*len(bucket_labels)),\n",
    "                                   activation=\"tanh\"))\n",
    "nn_model.add(tf.keras.layers.Dense(units=len(bucket_labels),\n",
    "                                   activation=\"softmax\"))\n",
    "\n",
    "\n",
    "# Compile the Sequential model together and customize metrics\n",
    "nn_model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "fit_model = nn_model.fit(X_train_scaled, y_train, epochs=50)\n",
    "\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42a9497",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_perf = nn_model.predict(Xp)\n",
    "predicted_perf = pd.DataFrame(predicted_perf)\n",
    "predicted_perf.columns = outcomes\n",
    "predicted_perf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1fed08",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_perf = predicted_perf.round(1)\n",
    "\n",
    "predicted_perf\n",
    "\n",
    "id_info = id_info.reset_index(drop=True)\n",
    "\n",
    "output = id_info.join(predicted_perf)\n",
    "output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6831d8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- %s minutes ---\" % round((time.time() - start_time)/60,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f64b0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea1b3a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
